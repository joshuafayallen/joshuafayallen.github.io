{
  "hash": "47b79f996b4f4b1877459bd387f23bb3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Receiving TDs Model\nformat: html\nengine: knitr\nauthor: Josh Allen\ndate: last-modified\nexecute: \n  warning: false\n  message: false\nfilters:\n  - webr\nwebr: \n  packages: \n    - ggplot2\n    - dplyr\n    - tidyr \n    - stringr\n    - forcats\n    - ggdist\n    - arrow\n    - glue\n    - vctrs\n\n---\n\n\n## Introduction\n\nI love watching football and learning about football, with most of my working time spent listening to various NFL podcasts and the *Learning Bayesian Stats* podcast.^[As a disclaimer, I am a huge 49ers fan, so a lot of examples will be 49ers-centric.] For the last few years,  I have had an inherent fascination with Bayesian stats. One of the great things about Bayesian stats is that we can talk about uncertainty in a more intuitive way, and because of the mechanics of using Bayesian models, we can get some awesome-looking plots.^[For fun, I just try to do things in both `matplotlib` and `ggplot2`. I personally prefer working with posteriors in `ggplot2` because `ggdist` has a lot of great uncertainty features and produces less busy plots.] So combining these two interests would make for an interesting blog post. \n\nI got interested in [Alex Andora and Maximilian Göbel's Soccer Factor Model](https://arxiv.org/abs/2412.05911).^[I am American, so I will just call it Soccer and call American Football Football.] They extend a common model in asset pricing called the factor model to assess player skill. The general idea behind the factor model is that there are lots of macroeconomic variables that affect an asset. To assess the asset or the skill of the broker, we can assess the value of the asset or the broker by adjusting for these variables. Once we have adjusted for these variables, we can just look at the intercept and get our estimand of interest. Alex and Max extend this idea to soccer, where we are adjusting for macro-factors that affect the team. Whatever remains is attributable to a player's individual skill. They focus on goal scoring as a measurable aspect of a player's latent skill. \n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Touchdowns v.s. Goals](index_files/figure-html/fig-goals-tds-comparision-1.png){#fig-goals-tds-comparision fig-pos='H' width=672}\n:::\n:::\n\n\nAfter reading through the example notebooks and the paper, I thought that this was not only an interesting idea, but it would probably have a strong crossover with touchdowns in football. In @fig-goals-tds-comparision I plot a comparison of receiving touchdowns in `nflreadr` versus goals in the author's data. The data that are used in the goals plot are a subset of the data that they use in their Sloan analytics paper. From my very limited knowledge of Soccer most o,f these guys seem pretty good, so we are likely to see more players with one goal.  Whereas in the NFL play-by-play data, we have a full accounting of every touchdown scored from 2002-2024.^[Technically, the play-by-play data goes from 1999-2024 but some of the data that are used for building the model are missing. Therefore I elect to use the 2002-2024 seasons.]\n\n## Touchdowns and Factors \n\n\nWhy touchdowns? Outside of being a fun exercise to see how a model designed for soccer translates to football, I think there is at least a reasonable football story for why we can use touchdowns as an outcome and why this is a useful exercise. A lot of people play fantasy football including myself, and want to know who has some scoring upside.  Touchdowns in Fantasy Football act as mouthwash for fantasy scoring. I am in a Half Points per Reception league, meaning that a reception is worth 0.5 points, each receiving yard is worth 0.1 points, and a receiving touchdown is worth six points. So, for a league average receiving performance with no touchdowns, this is worth 5.77 fantasy points. A touchdown, or two, turns a baddish fantasy football performance into a relatively good one.\n\nOutside of my pretend team, TDs could also serve to tap a pass catcher's latent ability. To be a good pass catcher in the NFL, you have to combine being a good route runner, athleticism, and the ability to catch the ball. You could argue that being a good pass catcher becomes more difficult when a team gets closer to the endzone. If we use some real player [tracking data provided by the NFL](https://github.com/nfl-football-ops/Big-Data-Bowl?tab=readme-ov-file) we can see some of the difficulties of being a receiver in the endzone. If we look at the person who actually catches the touchdown, there are three defenders in the area if we count the corner playing Tyreek Hill. If we turn our attention to the outlet pass (number 35 in red) there are three defenders in the area when he slips out to make himself available. \n![](kc_ne.gif){fig.pos='H'}\n\n\n::: {.cell}\n\n:::\n\n\nUndoubtedly, the probability of scoring increases as the offense gets closer to the endzone, but you have less room to get open. There is a pretty good case that as we start to shrink the field you have to be a crisper route runner and a good pass catcher since space is more limited. During a scramble drill you have to have a feel for where the defense is and your QB's arm strength. If your QB is slightly off you are likely going to have to make a contested catch because everybody is a lot of closer. One small caveat is that I don't understand all the nuances of play design and designing an offense, but you could imagine that it matters. As a play designer, you need to think about how to keep defenders where you want them. In the play above, Charcandrick West (number 35) likely has two duties. I would imagine that he is the answer if nobody is open, and he is likely tasked with occupying the linebackers so they do not sink into coverage, closing the window for number 84. \n\nEven with an explosive play at the edge of the redzone space is still at a premium. Let’s look at this touchdown pass to Tyreek Hill where his skill as a receiver is on display. If we look at the highlight of this play the corner  tries to disrupt the route by jamming Hill at the line. Hill avoids the jam and uses his speed to outrun Shields and catches the ball even with Shields right in his face. This is to say, even though there is a higher probability of scoring, your skills as a receiver are extenuated because of the tight quarters.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n![](la_kc.gif){fig.pos='H'}\n\nObviously, we measure wide receiver production in a lot of different ways. Some of the most obvious alternative measurements are efficiency metrics like yards per route run, usage statistics like target share or targets per route run, or just modeling production whether this is receiving yards or yards after catch. In fairness to the `nflreadr` team they do have this data. Another potential alternative is trying to estimate separation score to measure how they are developing as a route runner. You could totally model this data using offensive personnel as one of the groups, then model your yards metric of choice. However, in my wildest dreams, I would like to use this model throughout the season to inform fantasy football decisions. The participation data that is provided is fantastic, but you must wait till the end of the season. This is likely going to be a future exercise for me.\n\n\nTo fit the model, I want we are going to have to leverage information we have before the game. Mainly, some measure of the receiver's passing offense, how good the defense they are playing is, how fresh the player is, some measure of form, their aging curve, weather, and what kind of game we think it is going to be. In essence, we are adjusting for factors that are going to affect the receiver and the probability of touchdowns. The covariates I use in the model are:\n\n- A difference between the defensive team's passing EPA and the pass catcher's team EPA.\n- The rest differential between the receiver's team and the opposition.\n- Air yards per pass \n- Weather: Mainly wind and temperature.\n- Total line: a combination of both teams' projected points according to Vegas\n- Four binary indicators: Whether the receiver is playing a home game, whether the game is played inside, a division game, or if it is post-2018\n\nI use the total line as a proxy for what kind of game Vegas thinks it is going to be. Effectively I am trying to tap what we think the game script is going to be going into the game. If we think it is going to be a high-scoring game, then this forces one or both teams to rely on a more run-heavy script to keep the opposing offense off the field. I include the difference between the defensive team's passing EPA per game and the pass catcher team's passing EPA per game. Effectively I am trying to adjust for how much better the opposing team's defense is playing going into the matchup. I also include weather and surface as potential confounders. If it is windy and rainy and it is outdoors we are probably not going to see a ton of passes because the ball is harder to throw and catch. I also include whether it is a division game to capture a team's familiarity with each other. \n\nThe post-2018 indicator probably deserves a little more exposition. In 2018, the NFL introduced a series of new rules, in part, to promote passing. The big change was a revision to the catch rules to try to eliminate some notably controversial calls. A catch happens when a receiver establishes themselves in bounds and performs a \"football move.\" Additionally, the ball is allowed to move if it is in the receiver's control. In the clip below Brandon Aiyuk makes a great catch where the ball moves during the play. Before 2018 this likely would have been ruled an incomplete catch and the 49ers would have likely kicked a field goal.\n\n\n```{=html}\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/NG7LbR6jwe4?si=WRuW3FKrUYnVCasx&amp;start=184\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n```\n\nTo model time, I make use of Hilbert Space Gaussian Processes (HSGP). Most of the textbook definitions of a Gaussian Process (GP) start with the idea that this is a wholly uninformative name. Effectively, a Gaussian process is a collection of random variables where any finite subset has a Gaussian distribution. It is effectively just an infinite vector a.k.a a function where we are going to place a prior over. Generally, Gaussian processes are used to model time or space or both. Mathematically, this involves a lot of matrix inversion to get the posterior covariance. What this means practically is that the execution is $O(n^3)$ to get a sense of what that means, I plotted how long it would take to fit a single Gaussian process. Game level NFL data is not necessarily all that big but there are about 2080 games in the `nflreadr` database, without including the play-by-play data where we are including data from just about every wide receiver to take a snap. To get around having to wait 30+ hours to fit a model we can use a lower level approximation of GP known as a HSGP. We are using an approximation of a GP where we use basis to capture the wiggliness of the function while basically converting everything from a matrix inversion to matrix multiplication which is a much faster operation.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/hsgp-approx-time-1.png){fig-pos='H' width=672}\n:::\n:::\n\n\n\nWe are interested in modeling two different time components that don't have an obvious functional form. The first is modeling how well a player is playing in a particular season. They could be having an awesome season, and that is carrying over from game to game because they are being used more appropriately in the scheme or their usage has changed. More critically, we are interested in how experience impacts ability. In the most optimistic case you get a 21-year-old rookie into your building and in year one, they are at or above league average, but have some maturing to do with the finer aspects of being a pass catcher. By the time they get to their second contract, they may not be as fast as they were coming out of college, but they are an overall better pass catcher. Then, towards the end of their career they dip back to where they were as a rookie because they have taken a step back athletically. \n\nThis is a linearish story of receiver ability and a player's ability in general is one that fanbases, GMs, and coaches would sign up for immediately, but it rarely ever happens. Tight End has a big jump from college to the NFL for a variety of reasons. George Kittle is a great example of the diversity of responsibilities that an elite tight end has in the NFL. Part of what makes him elite is that he is an awesome blocker who can be used at the point of attack. Sometimes this includes blocking a team's best edge rusher, which is a difficult task for elite tackles, never mind a Tight End. To alleviate some of the difficulty, Shanahan uses a lot of motion to try and create advantageous angles and head starts. The rub is that how the motion and blocking look on a run play should look the same as when he is used on play action. As you can imagine, this is difficult, especially when you are just getting used to the size and speed of an NFL defender and the complexity of the NFL. \n\nTravis Kelce is another great example of the difficulty of being a pass catcher in the NFL. Over the years, Kelce has built a big reputation for his improvisation in route running.^[Taylor Swift lyric intended.] A lot of the plays that get dialed up for him are choice routes where he can decide on what route to run based on the coverage. You can run what is known as \"pause and bounce,\" where the pass catcher \"misses the count\" where you are deliberately a tick slow. To combat under-center play, action defenses will change the picture after the snap or switch coverage. By delaying your route, you can get more information about the coverage to run your route. This takes a lot of preparation and experience to execute. This maturation process is likely not linear and is not going to have the same effect on every player. At the same time, we don't really expect a mostly blocking tight end to suddenly catch fire as a scoring threat. \n\n\n\n## The Fun Stuff: Modeling the Data\n\nI fit an Ordered logit for each player for each player *i* in game *g* within each season *s*. The rough sketch of the model takes this form. For a more detailed look at the data collection, data cleaning, and modeling files, I will point you towards the files in the script folder. The sandbox folder is really a way for me to play around the various aspects of tuning the model.\n$$\n\\begin{aligned}\n\\ell_{experience},\\ell_{form} \\sim InverseGamma(\\alpha, \\beta) \\\\\n\\sigma_{experience}, \\sigma_{form} \\sim Exponential(\\lambda) \\\\\n\\beta_{factor} \\sim \\mathcal{N}(\\mu_{factors}, \\sigma_{factor}^{2}), k = 1, \\ldots, p \\\\\n\\sigma_{player} \\sim Exponential(1) \\\\\n\\sigma_{baseline} \\sim \\sqrt{\\sigma^2_{player} + \\frac{\\sigma^2_{cutpoints}}{J}} \\\\\n\\beta_{0} ~ \\mathcal{N}(0, \\sigma^2_{baseline}) \\\\\n\\alpha_j = \\beta_{0} + alpha_{j}^{raw}, where \\sum^j_{j=1}\\alpha^{raw}_i=0, \\alpha^[raw]_{j} \\sim \\mathcal{N}(0, \\sigma^2_{i}) \\\\\nf_{experience}(s) \\sim \\mathcal{GP}(0, \\sigma^2_{experience} \\cdot K_{Matérn}(\\cdot, \\cdot;\\ell_{experience})) \\\\\nf_{performance}(g) \\sim \\mathcal{GP}(0, \\sigma^2_{performance} \\cdot K_{Matérn}(\\cdot, \\cdot;\\ell_{performance})) \\\\\nN_i = \\alpha_i + f_{experience}(s_i) + f_{performance}(g_i) + \\mathcal{X}^{\\top}_{i}\\beta \\\\\nTouchdowns_{i} \\sim \\text{Ordered Logit}(N_{i}, \\mathcal{c}_{i})\n\\end{aligned}\n$$\n\n### Setting Priors\n\n\nAn ordered categorical likelihood seems kind of like a weird fit since we are really just using counts. However, we don't have a ton of mass in the 3+ touchdown range. Even in the 2+ touchdown range, we are working with even less mass than the goal scoring data that Max and Alex are using. I would imagine if they included attacking midfielders then the counts would look a little more similar. We could use what I like to call \"you must be this tall to ride the ride\" approach, meaning we could throw out any pass catcher without enough games played or enough targets. However, we may be getting rid of some interesting comparative information when we want to go and calculate replacement-level stats. \n\n\n\n::: {#tbl-total_tds .cell}\n\n```{.r .cell-code}\nempirical_dat |>\n  group_by(rec_tds_game) |>\n  summarise(`Total Touchdowns` = n()) |>\n  tinytable::tt()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<!-- preamble start -->\n\n    <script src=\"https://cdn.jsdelivr.net/gh/vincentarelbundock/tinytable@main/inst/tinytable.js\"></script>\n\n    <script>\n      // Create table-specific functions using external factory\n      const tableFns_alv2ujf934sy5v5jcs1h = TinyTable.createTableFunctions(\"tinytable_alv2ujf934sy5v5jcs1h\");\n      // tinytable span after\n      window.addEventListener('load', function () {\n          var cellsToStyle = [\n            // tinytable style arrays after\n          { positions: [ { i: '6', j: 1 }, { i: '6', j: 2 } ], css_id: 'tinytable_css_lop2mjgyvggbabt1c2ks',}, \n          { positions: [ { i: '0', j: 1 }, { i: '0', j: 2 } ], css_id: 'tinytable_css_3jvytu965jvuyzs9n2yz',}, \n          ];\n\n          // Loop over the arrays to style the cells\n          cellsToStyle.forEach(function (group) {\n              group.positions.forEach(function (cell) {\n                  tableFns_alv2ujf934sy5v5jcs1h.styleCell(cell.i, cell.j, group.css_id);\n              });\n          });\n      });\n    </script>\n\n    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/gh/vincentarelbundock/tinytable@main/inst/tinytable.css\">\n    <style>\n    /* tinytable css entries after */\n    #tinytable_alv2ujf934sy5v5jcs1h td.tinytable_css_lop2mjgyvggbabt1c2ks, #tinytable_alv2ujf934sy5v5jcs1h th.tinytable_css_lop2mjgyvggbabt1c2ks {  position: relative; --border-bottom: 1; --border-left: 0; --border-right: 0; --border-top: 0; --line-color-bottom: black; --line-color-left: black; --line-color-right: black; --line-color-top: black; --line-width-bottom: 0.1em; --line-width-left: 0.1em; --line-width-right: 0.1em; --line-width-top: 0.1em; --trim-bottom-left: 0%; --trim-bottom-right: 0%; --trim-left-bottom: 0%; --trim-left-top: 0%; --trim-right-bottom: 0%; --trim-right-top: 0%; --trim-top-left: 0%; --trim-top-right: 0%;  }\n    #tinytable_alv2ujf934sy5v5jcs1h td.tinytable_css_3jvytu965jvuyzs9n2yz, #tinytable_alv2ujf934sy5v5jcs1h th.tinytable_css_3jvytu965jvuyzs9n2yz {  position: relative; --border-bottom: 1; --border-left: 0; --border-right: 0; --border-top: 1; --line-color-bottom: black; --line-color-left: black; --line-color-right: black; --line-color-top: black; --line-width-bottom: 0.05em; --line-width-left: 0.1em; --line-width-right: 0.1em; --line-width-top: 0.1em; --trim-bottom-left: 0%; --trim-bottom-right: 0%; --trim-left-bottom: 0%; --trim-left-top: 0%; --trim-right-bottom: 0%; --trim-right-top: 0%; --trim-top-left: 0%; --trim-top-right: 0%;  }\n    </style>\n    <div class=\"container\">\n      <table class=\"tinytable\" id=\"tinytable_alv2ujf934sy5v5jcs1h\" style=\"width: auto; margin-left: auto; margin-right: auto;\" data-quarto-disable-processing='true'>\n        \n        <thead>\n              <tr>\n                <th scope=\"col\" data-row=\"0\" data-col=\"1\">rec_tds_game</th>\n                <th scope=\"col\" data-row=\"0\" data-col=\"2\">Total Touchdowns</th>\n              </tr>\n        </thead>\n        \n        <tbody>\n                <tr>\n                  <td data-row=\"1\" data-col=\"1\">0</td>\n                  <td data-row=\"1\" data-col=\"2\">54862</td>\n                </tr>\n                <tr>\n                  <td data-row=\"2\" data-col=\"1\">1</td>\n                  <td data-row=\"2\" data-col=\"2\">11057</td>\n                </tr>\n                <tr>\n                  <td data-row=\"3\" data-col=\"1\">2</td>\n                  <td data-row=\"3\" data-col=\"2\">1477</td>\n                </tr>\n                <tr>\n                  <td data-row=\"4\" data-col=\"1\">3</td>\n                  <td data-row=\"4\" data-col=\"2\">147</td>\n                </tr>\n                <tr>\n                  <td data-row=\"5\" data-col=\"1\">4</td>\n                  <td data-row=\"5\" data-col=\"2\">15</td>\n                </tr>\n                <tr>\n                  <td data-row=\"6\" data-col=\"1\">6</td>\n                  <td data-row=\"6\" data-col=\"2\">1</td>\n                </tr>\n        </tbody>\n      </table>\n    </div>\n<!-- hack to avoid NA insertion in last line -->\n```\n\n:::\n:::\n\n\nAdditionally, while there is no technical upper bound to the number of touchdowns you could score in a game or a season there are some practical bounds on the total number of touchdowns. The current single-season record is held by Randy Moss with 23, a record that is 18 years old, which broke Jerry Rice's single-season record of 22, which was 20. The current single-game record is a three-way tie between Kellen Winslow, Bob Shaw, and Jerry Rice, with each player having 5 receiving touchdowns in a single game. No receiver since Jerry Rice in 1990 has had 5 receiving touchdowns in a game.^[I am currently toying with using an [Ordered Beta to see if this does a better job](https://www.robertkubinec.com/ordbetareg).] \n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist_dat = empirical_dat |>\n  mutate(binary = ifelse(rec_tds >= 1, 1, 0)) |>\n  pivot_longer(c(rec_tds, rec_tds_game, binary)) |>\n  mutate(\n    name = case_when(\n      name == 'rec_tds_game' ~ 'Observed TDs',\n      name == 'rec_tds' ~ 'Lumped TDs',\n      name == 'binary' ~ 'Indicator TDs'\n    )\n  )\n\nggplot(hist_dat, aes(x = value, fill = name)) +\n  geom_bar(alpha = 0.5, position = 'dodge') +\n  labs(x = 'Touchdowns', y = 'Count', fill = NULL) +\n  MetBrewer::scale_fill_met_d(name = 'Lakota') +\n  scale_y_continuous(labels = scales::comma)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-lumped-tds-1.png){#fig-lumped-tds fig-pos='H' width=672}\n:::\n:::\n\n\nInstead of using the full observed range, I am just going to lump together 3 touchdowns and 4 touchdowns together. Functionally, nothing really changes because 3 touchdowns are still a relatively rare occurrence. Even when we create a simple binary indicator, we are not really changing things too much. I decided to use an ordered logit because a two or three-touchdown game is still useful for understanding how much better a pass catcher is than league average. Generally, the great pass catchers have multiple touchdown games. There are some games where a semi-random pass catcher may have a multiple TD game, but these are few and far between. Kyle Juszczyk has been an excellent receiving fullback in his career. However, he is not necessarily a major scoring threat, with only one game where he has scored multiple receiving touchdowns. \n\n\nThe biggest difference that I found when changing the goal scoring model to the touchdown scoring model was dealing with time. The soccer season is considerably longer than the football schedule, with 38 matchdays, while the length of the football season ranges from 14-17 games over the course of NFL games. Fitting two GPs into one season is feasible but a little bit overkill. Careers in the NFL also tend to be a bit shorter than in European high-level soccer. In general, an NFL career is 3ish years whereas the career lengths in European high-level soccer are longer because there are more avenues available to develop a player.\n\n\nTechnically, when you are talking about a lengthscale in general, we are talking about setting the priors over how quickly the correlations between function values decay. One of the nice things about the `PyMC` universe is that they have made setting the priors and hyperparameters of an HSGP more intuitive. So, while thinking about the prior for the variable may technically be a bit wrong in practice, it was helpful to do it when setting priors for the in-season HSGP and the experience HSGP. \n\nFor the in-season prior I started by thinking about how much carryover we would expect from game to game. For my mental model I found it easier to just lop off the last week of the season, since players may not be playing because of injuries or because playoff seeding is more or less set by then, so they are not playing. My intuition about how a player is playing carries over for a max of 5 or 6 games, while their performance from the last two weeks is going to tell us a bit more about how they are going to do in their next game. As the seasons evolve good to good-to-goodish teams tend to start to find answers to their problems. Mentally, I think this is kind of saying half of the season is going to tell you how a player will perform in that half of the season. \n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# | echo: false\n# | message: false\n# | warning: false\n# | label: fig-short-term-form-prior\n\nshort_term_form, ax = pz.maxent(pz.InverseGamma(), lower=2, upper=5)\nlg = ax.legend()\nax.set_xlim(0, 18);\n\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){fig-pos='H' width=662}\n:::\n:::\n\n\nFor the season’s GP, this was a bit more of a challenge because you don't need to be a consistent scoring threat to be an important player in the offense. Because I am not sub-setting the data to exclude players with a certain number of targets, I end up also including some blocking TEs and Fullbacks that could probably be dropped. Intuitively, this means that we probably have some players who pull the average career length down. Partially because teams may be looking for more juice at these positions and are more likely to move on from veterans. I\n\nI try to put the center of the distribution around 3-8 seasons. For the most part NFL careers are about 3 years long, so the first 1-3 years are probably going to be pretty informative. In general, good wide receivers get a new contract around their $4^{th}$ or $5^{th}$ year due to how the collective bargaining agreement works. By their second contract they are around 25-26, and the team and the league know what they are as a pass catcher. \n\n\n\n::: {#tbl-avg-career-age .cell}\n::: {.cell-output-display}\n\n```{=html}\n<!-- preamble start -->\n\n    <script src=\"https://cdn.jsdelivr.net/gh/vincentarelbundock/tinytable@main/inst/tinytable.js\"></script>\n\n    <script>\n      // Create table-specific functions using external factory\n      const tableFns_3awpkbskmitv7vb7r8pa = TinyTable.createTableFunctions(\"tinytable_3awpkbskmitv7vb7r8pa\");\n      // tinytable span after\n      window.addEventListener('load', function () {\n          var cellsToStyle = [\n            // tinytable style arrays after\n          { positions: [ { i: '3', j: 1 }, { i: '3', j: 2 } ], css_id: 'tinytable_css_ln1use58jl14wpq6w7jm',}, \n          { positions: [ { i: '0', j: 1 }, { i: '0', j: 2 } ], css_id: 'tinytable_css_k5kvwadqg6vfszgti8hx',}, \n          ];\n\n          // Loop over the arrays to style the cells\n          cellsToStyle.forEach(function (group) {\n              group.positions.forEach(function (cell) {\n                  tableFns_3awpkbskmitv7vb7r8pa.styleCell(cell.i, cell.j, group.css_id);\n              });\n          });\n      });\n    </script>\n\n    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/gh/vincentarelbundock/tinytable@main/inst/tinytable.css\">\n    <style>\n    /* tinytable css entries after */\n    #tinytable_3awpkbskmitv7vb7r8pa td.tinytable_css_ln1use58jl14wpq6w7jm, #tinytable_3awpkbskmitv7vb7r8pa th.tinytable_css_ln1use58jl14wpq6w7jm {  position: relative; --border-bottom: 1; --border-left: 0; --border-right: 0; --border-top: 0; --line-color-bottom: black; --line-color-left: black; --line-color-right: black; --line-color-top: black; --line-width-bottom: 0.1em; --line-width-left: 0.1em; --line-width-right: 0.1em; --line-width-top: 0.1em; --trim-bottom-left: 0%; --trim-bottom-right: 0%; --trim-left-bottom: 0%; --trim-left-top: 0%; --trim-right-bottom: 0%; --trim-right-top: 0%; --trim-top-left: 0%; --trim-top-right: 0%;  }\n    #tinytable_3awpkbskmitv7vb7r8pa td.tinytable_css_k5kvwadqg6vfszgti8hx, #tinytable_3awpkbskmitv7vb7r8pa th.tinytable_css_k5kvwadqg6vfszgti8hx {  position: relative; --border-bottom: 1; --border-left: 0; --border-right: 0; --border-top: 1; --line-color-bottom: black; --line-color-left: black; --line-color-right: black; --line-color-top: black; --line-width-bottom: 0.05em; --line-width-left: 0.1em; --line-width-right: 0.1em; --line-width-top: 0.1em; --trim-bottom-left: 0%; --trim-bottom-right: 0%; --trim-left-bottom: 0%; --trim-left-top: 0%; --trim-right-bottom: 0%; --trim-right-top: 0%; --trim-top-left: 0%; --trim-top-right: 0%;  }\n    </style>\n    <div class=\"container\">\n      <table class=\"tinytable\" id=\"tinytable_3awpkbskmitv7vb7r8pa\" style=\"width: auto; margin-left: auto; margin-right: auto;\" data-quarto-disable-processing='true'>\n        <caption>Average Age When Drafted</caption>\n        <thead>\n              <tr>\n                <th scope=\"col\" data-row=\"0\" data-col=\"1\">Receiver Position</th>\n                <th scope=\"col\" data-row=\"0\" data-col=\"2\">Average Age</th>\n              </tr>\n        </thead>\n        \n        <tbody>\n                <tr>\n                  <td data-row=\"1\" data-col=\"1\">WR</td>\n                  <td data-row=\"1\" data-col=\"2\">22.52</td>\n                </tr>\n                <tr>\n                  <td data-row=\"2\" data-col=\"1\">RB</td>\n                  <td data-row=\"2\" data-col=\"2\">22.46</td>\n                </tr>\n                <tr>\n                  <td data-row=\"3\" data-col=\"1\">TE</td>\n                  <td data-row=\"3\" data-col=\"2\">22.79</td>\n                </tr>\n        </tbody>\n      </table>\n    </div>\n<!-- hack to avoid NA insertion in last line -->\n```\n\n:::\n:::\n\n\n\nBy their third contract they are not only expensive but they are starting to decline athletically so what the first half of their may not be as informative. Players like Mike Evans, Larry Fitzgerald, and Davante Adams who relied on their route running to be dominant may have a longer tail because they can remain productive on a third contract. What this amounts to is a prior that looks like this. \n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n(0.0, 18.0)\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){fig-pos='H' width=662}\n:::\n:::\n\n\nThe next prior we need to set is how much ability varies from player to player. Admittedly this is a little bit more difficult for me to conceptualize. The difference between a league-average receiver and the best receiver in the NFL is pretty big. Where I struggled was mostly because initially I was setting it at a season level, so the difference between say WR1 and WR2 is probably closer to 2 or 3 touchdowns. However, this is being set at the game’s level so realistically, the difference is probably closer to a touchdown. So the prior level differences are going to look closer to something like this. \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-3.png){fig-pos='H' width=662}\n:::\n:::\n\n\nThe variance for the HSGPs are set by really looking at the observed proportions of TDs. I set it by looking at the proportion of 2-touchdown games. So, roughly what is the proportion of two-touchdown games we would expect to observe? In the actual data, there is about a 2% chance of a player having a two-touchdown game. However, during the model-building process, I found that setting the prior at 2% or 2.1% was causing the model to struggle sampling a bit. I ended up setting the prior to 3% and that seemed to help with sampling. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nempirical_dat |>\n  summarise(tds = n(), .by = rec_tds) |>\n  mutate(\n    `Observed Receiving TD Proportion` = round(tds / sum(tds), 3),\n    rec_tds = as.character(rec_tds),\n    rec_tds = ifelse(rec_tds == '3', '3+', rec_tds)\n  ) |>\n  arrange(rec_tds) |>\n  select(\n    `Receiving Touchdowns` = rec_tds,\n    `Observed Receiving TD Proportion`\n  ) |>\n  tinytable::tt()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<!-- preamble start -->\n\n    <script src=\"https://cdn.jsdelivr.net/gh/vincentarelbundock/tinytable@main/inst/tinytable.js\"></script>\n\n    <script>\n      // Create table-specific functions using external factory\n      const tableFns_3a8q90rref1zpl1xky29 = TinyTable.createTableFunctions(\"tinytable_3a8q90rref1zpl1xky29\");\n      // tinytable span after\n      window.addEventListener('load', function () {\n          var cellsToStyle = [\n            // tinytable style arrays after\n          { positions: [ { i: '4', j: 1 }, { i: '4', j: 2 } ], css_id: 'tinytable_css_m4ts5yv7lpv85il9tkf7',}, \n          { positions: [ { i: '0', j: 1 }, { i: '0', j: 2 } ], css_id: 'tinytable_css_o66kxpiddulthevw5nj9',}, \n          ];\n\n          // Loop over the arrays to style the cells\n          cellsToStyle.forEach(function (group) {\n              group.positions.forEach(function (cell) {\n                  tableFns_3a8q90rref1zpl1xky29.styleCell(cell.i, cell.j, group.css_id);\n              });\n          });\n      });\n    </script>\n\n    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/gh/vincentarelbundock/tinytable@main/inst/tinytable.css\">\n    <style>\n    /* tinytable css entries after */\n    #tinytable_3a8q90rref1zpl1xky29 td.tinytable_css_m4ts5yv7lpv85il9tkf7, #tinytable_3a8q90rref1zpl1xky29 th.tinytable_css_m4ts5yv7lpv85il9tkf7 {  position: relative; --border-bottom: 1; --border-left: 0; --border-right: 0; --border-top: 0; --line-color-bottom: black; --line-color-left: black; --line-color-right: black; --line-color-top: black; --line-width-bottom: 0.1em; --line-width-left: 0.1em; --line-width-right: 0.1em; --line-width-top: 0.1em; --trim-bottom-left: 0%; --trim-bottom-right: 0%; --trim-left-bottom: 0%; --trim-left-top: 0%; --trim-right-bottom: 0%; --trim-right-top: 0%; --trim-top-left: 0%; --trim-top-right: 0%;  }\n    #tinytable_3a8q90rref1zpl1xky29 td.tinytable_css_o66kxpiddulthevw5nj9, #tinytable_3a8q90rref1zpl1xky29 th.tinytable_css_o66kxpiddulthevw5nj9 {  position: relative; --border-bottom: 1; --border-left: 0; --border-right: 0; --border-top: 1; --line-color-bottom: black; --line-color-left: black; --line-color-right: black; --line-color-top: black; --line-width-bottom: 0.05em; --line-width-left: 0.1em; --line-width-right: 0.1em; --line-width-top: 0.1em; --trim-bottom-left: 0%; --trim-bottom-right: 0%; --trim-left-bottom: 0%; --trim-left-top: 0%; --trim-right-bottom: 0%; --trim-right-top: 0%; --trim-top-left: 0%; --trim-top-right: 0%;  }\n    </style>\n    <div class=\"container\">\n      <table class=\"tinytable\" id=\"tinytable_3a8q90rref1zpl1xky29\" style=\"width: auto; margin-left: auto; margin-right: auto;\" data-quarto-disable-processing='true'>\n        \n        <thead>\n              <tr>\n                <th scope=\"col\" data-row=\"0\" data-col=\"1\">Receiving Touchdowns</th>\n                <th scope=\"col\" data-row=\"0\" data-col=\"2\">Observed Receiving TD Proportion</th>\n              </tr>\n        </thead>\n        \n        <tbody>\n                <tr>\n                  <td data-row=\"1\" data-col=\"1\">0</td>\n                  <td data-row=\"1\" data-col=\"2\">0.812</td>\n                </tr>\n                <tr>\n                  <td data-row=\"2\" data-col=\"1\">1</td>\n                  <td data-row=\"2\" data-col=\"2\">0.164</td>\n                </tr>\n                <tr>\n                  <td data-row=\"3\" data-col=\"1\">2</td>\n                  <td data-row=\"3\" data-col=\"2\">0.022</td>\n                </tr>\n                <tr>\n                  <td data-row=\"4\" data-col=\"1\">3+</td>\n                  <td data-row=\"4\" data-col=\"2\">0.002</td>\n                </tr>\n        </tbody>\n      </table>\n    </div>\n<!-- hack to avoid NA insertion in last line -->\n```\n\n:::\n:::\n\n\n\n### Prior Predictive simulations \n\nBefore we introduce our model to the data lets go and look at what our predictions from the model will look like.^[Thanks to the `from_dataframe` feature in polars getting the data to plot in `ggplot` was a synch.]\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\ncumulative_stats = pl.read_parquet(\"writeup-dat/cleaned-data.parquet\")\n\nfactors_numeric = [\n    \"player_rest_diff\",\n    \"def_epa_diff\",\n    \"wind\",\n    \"temp\",\n    \"total_line\",\n    \"air_yards_per_pass_attempt\",\n]\n\nfactors = factors_numeric + [\"div_game\", \"home_game\", \"is_indoors\", \"era\"]\n\nfactors_numeric_train = cumulative_stats.select(pl.col(factors))\n\nmeans = factors_numeric_train.select(\n    [pl.col(c).mean().alias(c) for c in factors_numeric]\n)\nsds = factors_numeric_train.select([pl.col(c).std().alias(c) for c in factors_numeric])\n\nfactors_numeric_sdz = factors_numeric_train.with_columns(\n    [((pl.col(c) - means[0, c]) / sds[0, c]).alias(c) for c in factors_numeric]\n).with_columns(\n    pl.Series(\"home_game\", cumulative_stats[\"home_game\"]),\n    pl.Series(\"div_game\", cumulative_stats[\"div_game\"]),\n    pl.Series(\"is_indoors\", cumulative_stats[\"is_indoors\"]),\n    pl.Series(\"era\", cumulative_stats[\"era\"]),\n)\n\ncumulative_stats_pd = cumulative_stats.to_pandas()\n\n\nunique_games = cumulative_stats_pd[\"games_played\"].sort_values().unique()\nunique_seasons = cumulative_stats_pd[\"number_of_seasons_played\"].sort_values().unique()\n\noff_play_caller = cumulative_stats_pd[\"off_play_caller\"].sort_values().unique()\ndef_play_caller = cumulative_stats_pd[\"def_play_caller\"].sort_values().unique()\n\nunique_players = cumulative_stats_pd[\"receiver_full_name\"].sort_values().unique()\n\n\nplayer_idx = pd.Categorical(\n    cumulative_stats_pd[\"receiver_full_name\"], categories=unique_players\n).codes\n\nseasons_idx = pd.Categorical(\n    cumulative_stats_pd[\"number_of_seasons_played\"], categories=unique_seasons\n).codes\n\ngames_idx = pd.Categorical(\n    cumulative_stats_pd[\"games_played\"], categories=unique_games\n).codes\n\noff_play_caller_idx = pd.Categorical(\n    cumulative_stats_pd[\"off_play_caller\"], categories=off_play_caller\n).codes\n\ndef_play_caller_idx = pd.Categorical(\n    cumulative_stats_pd[\"def_play_caller\"], categories=def_play_caller\n).codes\n\ncoords = {\n    \"factors\": factors,\n    \"gameday\": unique_games,\n    \"seasons\": unique_seasons,\n    \"obs_id\": cumulative_stats_pd.index,\n    \"player\": unique_players,\n    \"off_play_caller\": off_play_caller,\n    \"def_play_caller\": def_play_caller,\n    \"time_scale\": [\"games\", \"season\"],\n}\n\nempirical_probs = cumulative_stats_pd[\"rec_tds\"].value_counts(normalize=True).to_numpy()\n\ncumulative_probs = empirical_probs.cumsum()[:-1]\n\ncutpoints_standard = norm.ppf(cumulative_probs)\n\ndelta_prior = np.diff(cutpoints_standard)\n\nseasons_m, seasons_c = pm.gp.hsgp_approx.approx_hsgp_hyperparams(\n    x_range=[\n        0,\n        cumulative_stats.select(pl.col(\"number_of_seasons_played\").max()).to_series()[\n            0\n        ],\n    ],\n    lengthscale_range=[2, 6],\n    cov_func=\"matern52\",\n)\n\n\nshort_term_form, _ = pz.maxent(pz.InverseGamma(), lower=2, upper=5)\n\n\nwithin_m, within_c = pm.gp.hsgp_approx.approx_hsgp_hyperparams(\n    x_range=[\n        0,\n        cumulative_stats.select(pl.col(\"games_played\").max()).to_series()[0],\n    ],\n    lengthscale_range=[2, 5],\n    cov_func=\"matern52\",\n)\n\n\nwith pm.Model(coords=coords) as rec_tds_era_adjusted:\n    factor_data = pm.Data(\"factor_data\", factors_numeric_sdz, dims=(\"obs_id\", \"factor\"))\n    games_id = pm.Data(\"games_id\", games_idx, dims=\"obs_id\")\n    player_id = pm.Data(\"player_id\", player_idx, dims=\"obs_id\")\n    season_id = pm.Data(\n        \"season_id\",\n        seasons_idx,\n        dims=\"obs_id\",\n    )\n\n    rec_tds_obs = pm.Data(\n        \"rec_tds_obs\", cumulative_stats[\"rec_tds\"].to_numpy(), dims=\"obs_id\"\n    )\n\n    x_gamedays = pm.Data(\"x_gamedays\", unique_games, dims=\"gameday\")[:, None]\n    x_seasons = pm.Data(\"x_seasons\", unique_seasons, dims=\"seasons\")[:, None]\n\n    # ref notebook sets it at the max of goals scored of the games so we are going to do the same\n    intercept_sigma = 4\n    sd = touchdown_dist.to_pymc(\"touchdown_sd\")\n\n    baseline_sigma = pt.sqrt(intercept_sigma**2 + sd**2 / len(coords[\"player\"]))\n\n    baseline = baseline_sigma * pm.Normal(\"baseline\")\n\n    player_effect = pm.Deterministic(\n        \"player_effect\",\n        baseline + pm.ZeroSumNormal(\"player_effect_raw\", sigma=sd, dims=\"player\"),\n        dims=\"player\",\n    )\n\n    # bumbing this up a bit\n    alpha_scale, upper_scale = 0.03, 2.0\n    gps_sigma = pm.Exponential(\n        \"gps_sigma\", lam=-np.log(alpha_scale) / upper_scale, dims=\"time_scale\"\n    )\n\n    ls = pm.InverseGamma(\n        \"ls\",\n        alpha=np.array([short_term_form.alpha, seasons_gp_prior.alpha]),\n        beta=np.array([short_term_form.beta, seasons_gp_prior.beta]),\n        dims=\"time_scale\",\n    )\n\n    cov_games = gps_sigma[0] ** 2 * pm.gp.cov.Matern52(input_dim=1, ls=ls[0])\n    cov_seasons = gps_sigma[1] ** 2 * pm.gp.cov.Matern52(input_dim=1, ls=ls[1])\n\n    gp_games = pm.gp.HSGP(m=[within_m], c=within_c, cov_func=cov_games)\n    gp_season = pm.gp.HSGP(m=[seasons_m], c=seasons_c, cov_func=cov_seasons)\n\n    basis_vectors_game, sqrt_psd_game = gp_games.prior_linearized(X=x_gamedays)\n\n    basis_coeffs_games = pm.Normal(\"basis_coeffs_games\", shape=gp_games.n_basis_vectors)\n\n    f_games = pm.Deterministic(\n        \"f_games\",\n        basis_vectors_game @ (basis_coeffs_games * sqrt_psd_game),\n        dims=\"gameday\",\n    )\n\n    basis_vectors_season, sqrt_psd_season = gp_season.prior_linearized(X=x_seasons)\n\n    basis_coeffs_season = pm.Normal(\n        \"basis_coeffs_season\", shape=gp_season.n_basis_vectors\n    )\n\n    f_season = pm.Deterministic(\n        \"f_season\",\n        basis_vectors_season @ (basis_coeffs_season * sqrt_psd_season),\n        dims=\"seasons\",\n    )\n\n    alpha = pm.Deterministic(\n        \"alpha\",\n        player_effect[player_id] + f_season[season_id] + f_games[games_id],\n        dims=\"obs_id\",\n    )\n    slope = pm.Normal(\"slope\", sigma=0.5, dims=\"factors\")\n\n    eta = pm.Deterministic(\n        \"eta\", alpha + pm.math.dot(factor_data, slope), dims=\"obs_id\"\n    )\n    cutpoints_off = 4\n\n    delta_mean = pm.Normal(\n        \"delta_mean\", mu=delta_prior * cutpoints_off, sigma=1, shape=2\n    )\n\n    delta_sig = pm.Exponential(\"delta_sig\", 1, shape=2)\n\n    player_delta = delta_mean + delta_sig * pm.Normal(\n        \"player_delta\", shape=(len(coords[\"player\"]), 2)\n    )\n\n    cutpoints = pm.Deterministic(\n        \"cutpoints\",\n        pt.concatenate(\n            [\n                pt.full((player_effect.shape[0], 1), cutpoints_off),\n                pt.cumsum(pt.softplus(player_delta), axis=-1) + cutpoints_off,\n            ],\n            axis=-1,\n        ),\n    )\n\n    pm.OrderedLogistic(\n        \"tds_scored\",\n        cutpoints=cutpoints[player_id],\n        eta=eta,\n        observed=rec_tds_obs,\n        dims=\"obs_id\",\n    )\n\n\nwith rec_tds_era_adjusted:\n    idata = pm.sample_prior_predictive()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){fig-pos='H' width=662}\n:::\n:::\n\n\n\nLet’s check how the HSGPs are looking. Admittedly, we do get some pretty wonky-looking lines, but most of them are in the High Density intervals. It would be nice to see less wonky-looking lines from the simulations. \n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\nf_within_prior = idata.prior[\"f_games\"]\nf_long_prior = idata.prior[\"f_season\"]\n\nindex = pd.MultiIndex.from_product(\n    [unique_seasons, unique_games],\n    names=[\"season_nbr\", \"gameday\"],\n)\nunique_combinations = pd.DataFrame(index=index).reset_index()\n\nf_long_prior_aligned = f_long_prior.sel(\n    seasons=unique_combinations[\"season_nbr\"].to_numpy()\n).rename({\"seasons\": \"timestamp\"})\nf_long_prior_aligned[\"timestamp\"] = unique_combinations.index\n\nf_within_prior_aligned = f_within_prior.sel(\n    gameday=unique_combinations[\"gameday\"].to_numpy()\n).rename({\"gameday\": \"timestamp\"})\nf_within_prior_aligned[\"timestamp\"] = unique_combinations.index\n\nf_total_prior = f_long_prior_aligned + f_within_prior_aligned\n\nsome_draws = rng.choice(f_total_prior.draw, size=20, replace=True)\n\n_, axes = plt.subplot_mosaic(\n    \"\"\"\n    AB\n    CC\n    \"\"\",\n    figsize=(12, 7.5),\n    layout=\"constrained\",\n)\n\naxes[\"A\"].plot(\n    f_within_prior.gameday,\n    az.extract(f_within_prior)[\"f_games\"].isel(sample=0),\n    color=\"#70133A\",\n    alpha=0.3,\n    lw=1.5,\n    label=\"random draws\",\n)\naxes[\"A\"].plot(\n    f_within_prior.gameday,\n    az.extract(f_within_prior)[\"f_games\"].isel(sample=some_draws),\n    color=\"#70133A\",\n    alpha=0.3,\n    lw=1.5,\n)\naz.plot_hdi(\n    x=f_within_prior.gameday,\n    y=f_within_prior,\n    hdi_prob=0.83,\n    color=\"#AAC4E6\",\n    fill_kwargs={\"alpha\": 0.9, \"label\": r\"$83\\%$ HDI\"},\n    ax=axes[\"A\"],\n    smooth=False,\n)\naxes[\"A\"].plot(\n    f_within_prior.gameday,\n    f_within_prior.mean((\"chain\", \"draw\")),\n    color=\"#FBE64D\",\n    lw=2.5,\n    label=\"Mean\",\n)\naxes[\"A\"].set(\n    xlabel=\"Gameday\", ylabel=\"Nbr TDs\", title=\"Within season variation\\nForm GP\"\n)\naxes[\"A\"].legend(fontsize=10, frameon=True, ncols=3)\n\naxes[\"B\"].plot(\n    f_long_prior.seasons,\n    az.extract(f_long_prior)[\"f_season\"].isel(sample=some_draws),\n    color=\"#70133A\",\n    alpha=0.3,\n    lw=1.5,\n)\naz.plot_hdi(\n    x=f_long_prior.seasons,\n    y=f_long_prior,\n    hdi_prob=0.83,\n    color=\"#AAC4E6\",\n    fill_kwargs={\"alpha\": 0.9},\n    ax=axes[\"B\"],\n    smooth=False,\n)\naxes[\"B\"].plot(\n    f_long_prior.seasons,\n    f_long_prior.mean((\"chain\", \"draw\")),\n    color=\"#FBE64D\",\n    lw=2.5,\n)\naxes[\"B\"].set(\n    xlabel=\"Season\", ylabel=\"Nbr TDs\", title=\"Across seasons variation\\nAging curve\"\n)\n\naxes[\"C\"].plot(\n    f_total_prior.timestamp,\n    az.extract(f_total_prior)[\"x\"].isel(sample=some_draws),\n    color=\"#70133A\",\n    alpha=0.3,\n    lw=1.5,\n)\naz.plot_hdi(\n    x=f_total_prior.timestamp,\n    y=f_total_prior,\n    hdi_prob=0.83,\n    color=\"#AAC4E6\",\n    fill_kwargs={\"alpha\": 0.9},\n    ax=axes[\"C\"],\n    smooth=False,\n)\naxes[\"C\"].plot(\n    f_total_prior.timestamp,\n    f_total_prior.mean((\"chain\", \"draw\")),\n    color=\"#FBE64D\",\n    lw=2.5,\n)\naxes[\"C\"].set(xlabel=\"Timestamp\", ylabel=\"Nbr TDS\", title=\"Total GP\")\nplt.suptitle(\"Prior GPs\", fontsize=18)\n\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-3.png){fig-pos='H' width=1163}\n:::\n:::\n\n\n\n\nLet’s go and look at the implied predictions from the model. The model is a little bit more optimistic about players scoring 3 or more touchdowns than we actually observe in the real world. However, it looks like it does a pretty good job of projecting zeros and ones. This good because this is where most of the action is in the data, so I am overall pretty happy about that. \n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\nimplied_cats = az.extract(idata.prior_predictive, var_names='tds_scored')\n\n\nfig, axes = plt.subplots(ncols=2)\n\naxes[0] = (\n    implied_cats.isel(obs_id=0)\n    .to_pandas()\n    .reset_index(drop=True)\n    .value_counts(normalize=True)\n    .sort_index()\n    .plot(kind=\"bar\", rot=0, alpha=0.8, ax=axes[0])\n)\naxes[0].set(\n    xlabel=\"Touchdowns\",\n    ylabel=\"Proportion\",\n    title=\"Prior allocation of \\n TDs for Observation 0\",\n)\n\naxes[1] = (\n    cumulative_stats_pd[\"rec_tds\"]\n    .value_counts(normalize=True)\n    .sort_index()\n    .plot(kind=\"bar\", rot=0, alpha=0.8, ax=axes[1])\n)\n\naxes[1].set(\n    xlabel=\"Touchdowns\", ylabel=\"Proportion\", title=\"Observed TDs for Observation 0\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-5.png){fig-pos='H' width=662}\n:::\n:::\n\n\n\nWe can see that a little bit more clearly when we visualize the prior predictive distribution. The model underpredicts zero by a bit, while it gets one touchdown pretty close to dead on. Overall, I think the model looks acceptable. We could try and dial everything in a whole lot more, but that feels like playing with fire. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-7.png){fig-pos='H' width=662}\n:::\n:::\n\n\nNow lets look at the GPs to make sure they are \n\n### Diagnostics \n\nUnfortunately even with some pretty permissive sampling setting we still get 3 divergences which is not the end of the world but it is not zero. \n\n::: {.cell}\n\n```{.python .cell-code}\nidata = az.from_netcdf(\n    'models/idata_compelete.nc'\n)\n\nidata.sample_stats.diverging.sum().data\n\n```\n:::\n\n\nMost if not all of our proposals were accepted which is goo! \n\n\n::: {.cell}\n\n```{.python .cell-code}\nidata.sample_stats.acceptance_rate.mean().data.round(2)\n```\n:::\n\n\n\n\nThe Rhats for our HSGPs are at or really close to one, indicating that they are sampling pretty well!  \n\n\n\n::: {.cell}\n\n```{.python .cell-code}\naz.rhat(\n    idata, var_names=[\"basis_coeffs_season\", \"basis_coeffs_games\"]\n).max().to_pandas().round(2)\n\n```\n:::\n\n\nPersonally, I would have really liked everybody to be above 1,000. The sigma for the touchdown’s parameter is pretty small ESS of 519, but we are still a bit above the threshold where `PyMC` will yell at you.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ness = read_parquet('writeup-dat/ess.parquet') |>\n  mutate(\n    Variable = str_replace_all(Variable, '_', ' '),\n    Variable = str_remove(Variable, 'basis'),\n    Variable = str_to_title(Variable),\n    Variable = case_when(\n      Variable == 'F Games' ~ 'HSGP Games',\n      Variable == 'F Season' ~ 'HSGP Season',\n      Variable == 'Ls' ~ 'Length Scale',\n      .default = Variable\n    )\n  )\n\n\nggplot(\n  ess,\n  aes(x = ess, y = fct_reorder(Variable, ess, .fun = max), label = ess)\n) +\n  geom_col() +\n  geom_text(hjust = -0.1) +\n  labs(x = 'Effective Sample Size', y = NULL)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-9.png){fig-pos='H' width=672}\n:::\n:::\n\n\n\nWorking with the posteriors from this model is not necessarily difficult but because there are 2265 with 1,000 draws across four chains and a few parameters that are indexed by player, this can take a while. To speed up compilation of the graphs, I do make some quick and dirty trace plots by taking a random sample of values for each variable across each chain. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nposteriors_dat = open_dataset(\n  'trace-plot-data'\n) |>\n  filter(\n    param %in%\n      c(\n        'alpha',\n        'f_season',\n        'f_games',\n        'cutpoint',\n        'eta',\n        'tds_scored_probs',\n        'slope',\n        'player_delta',\n        'player_effect',\n        'slope'\n      )\n  ) |>\n  collect() |>\n  mutate(\n    param = str_replace_all(param, '_', ' '),\n    param = str_to_title(param),\n    param = case_match(\n      param,\n      'F Season' ~ 'HSGP Season',\n      'F Games' ~ 'HSGP Games',\n      .default = param\n    )\n  )\n\n\nggplot(\n  posteriors_dat,\n  aes(x = .iteration, y = value, color = as.factor(.chain))\n) +\n  # drawing points is faster than connecting lines\n  geom_line(alpha = 0.3) +\n  facet_wrap(vars(param), scales = 'free_y', labeller = label_wrap_gen(2)) +\n  MetBrewer::scale_colour_met_d(name = 'Lakota') +\n  theme(\n    legend.position = 'none'\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){fig-pos='H' width=672}\n:::\n:::\n\n\nFor the most part these look pretty good everything looks wiggly and jumbled, which is generally a good sign for how well the sampler is doing. The slopes and HSGPs are a little less like a jumply mess. For the most part things are looking pretty good. \n\n\nMoving on if we look at the posterior predictive distribution, the model does well capturing the observed data. The posterior predictive mean is a little lower than the observed rate of 0's and 1's, but you kind of have to squint to be able to tell. The other encouraging sign is that all the posterior predictive draws are clustered right on or at least right near the observed values, and we are not getting some wild, implausible predictions. \n\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\nidata = az.from_netcdf('models/idata_compelete.nc')\n\nwith rec_tds_era_adjusted:\n    idata.extend(\n        pm.sample_posterior_predictive(idata, compile_kwargs={\"mode\":'NUMBA'})\n    )\n\naz.plot_ppc(idata, num_pp_samples=100)\n\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){fig-pos='H' width=662}\n:::\n:::\n\n\n\nNow when we go to look at the posteriors for the GPs we do get a few odd random draws but for the most part all three of the GPs do a good job over their respective ranges which is good! \n\n:::{.panel-tabset}\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\nf_within_posterior = idata.posterior[\"f_games\"]\nf_long_posterior = idata.posterior[\"f_season\"]\n\n#check = f_within_posterior.to_dataframe().reset_index()\n#\n#check2 = f_long_posterior.to_dataframe().reset_index()\n#\n#games_hsgp = pl.from_dataframe(check)\n#\n#games_hsgp.write_parquet('writeup-dat/games-hsgp.parquet')\n\n\nindex = pd.MultiIndex.from_product(\n    [unique_seasons, unique_games],\n    names=[\"season_nbr\", \"gameday\"],\n)\nunique_combinations = pd.DataFrame(index=index).reset_index()\n\nf_long_posterior_aligned = f_long_posterior.sel(\n    seasons=unique_combinations[\"season_nbr\"].to_numpy()\n).rename({\"seasons\": \"timestamp\"})\n\nf_long_posterior_aligned[\"timestamp\"] = unique_combinations.index\n\nf_within_posterior_aligned = f_within_posterior.sel(\n    gameday=unique_combinations[\"gameday\"].to_numpy()\n).rename({\"gameday\": \"timestamp\"})\n\nf_within_posterior_aligned[\"timestamp\"] = unique_combinations.index\n\n\nf_total_posterior = f_long_posterior_aligned + f_within_posterior_aligned\n\n\n\n#total_post = pl.from_dataframe(f_total_posterior.to_dataframe().reset_index()\n#total_post.write_parquet('writeup-dat/total_hsgp.parquet')\n\nsome_draws = rng.choice(f_total_posterior.draw, size=100, replace=True)\n\n_, axes = plt.subplot_mosaic(\n    \"\"\"\n    AB\n    CC\n    \"\"\",\n    figsize=(12, 7.5),\n    layout=\"constrained\",\n)\n\naxes[\"A\"].plot(\n    f_within_posterior.gameday,\n    az.extract(f_within_posterior)[\"f_games\"].isel(sample=0),\n    color=\"#70133A\",\n    alpha=0.3,\n    lw=1.5,\n    label=\"random draws\",\n)\n\n\naxes[\"A\"].plot(\n    f_within_posterior.gameday,\n    az.extract(f_within_posterior)[\"f_games\"].isel(sample=some_draws),\n    color=\"#70133A\",\n    alpha=0.3,\n    lw=1.5,\n)\naz.plot_hdi(\n    x=f_within_posterior.gameday,\n    y=f_within_posterior,\n    hdi_prob=0.83,\n    color=\"#AAC4E6\",\n    fill_kwargs={\"alpha\": 0.9, \"label\": r\"$83\\%$ HDI\"},\n    ax=axes[\"A\"],\n    smooth=False,\n)\naxes[\"A\"].plot(\n    f_within_posterior.gameday,\n    f_within_posterior.mean((\"chain\", \"draw\")),\n    color=\"#FBE64D\",\n    lw=2.5,\n    label=\"Mean\",\n)\naxes[\"A\"].set(\n    xlabel=\"Gameday\", ylabel=\"Nbr TDs\", title=\"Within season variation\\nShort GP\"\n)\naxes[\"A\"].legend(fontsize=10, frameon=True, ncols=3)\n\naxes[\"B\"].plot(\n    f_long_posterior.seasons,\n    az.extract(f_long_posterior)[\"f_season\"].isel(sample=some_draws),\n    color=\"#70133A\",\n    alpha=0.3,\n    lw=1.5,\n)\naz.plot_hdi(\n    x=f_long_posterior.seasons,\n    y=f_long_posterior,\n    hdi_prob=0.83,\n    color=\"#AAC4E6\",\n    fill_kwargs={\"alpha\": 0.9},\n    ax=axes[\"B\"],\n    smooth=False,\n)\naxes[\"B\"].plot(\n    f_long_posterior.seasons,\n    f_long_posterior.mean((\"chain\", \"draw\")),\n    color=\"#FBE64D\",\n    lw=2.5,\n)\naxes[\"B\"].set(\n    xlabel=\"Season\", ylabel=\"Nbr TDs\", title=\"Across seasons variation\\nAging curve\"\n)\n\naxes[\"C\"].plot(\n    f_total_posterior.timestamp,\n    az.extract(f_total_posterior)[\"x\"].isel(sample=some_draws),\n    color=\"#70133A\",\n    alpha=0.3,\n    lw=1.5,\n)\naz.plot_hdi(\n    x=f_total_posterior.timestamp,\n    y=f_total_posterior,\n    hdi_prob=0.83,\n    color=\"#AAC4E6\",\n    fill_kwargs={\"alpha\": 0.9},\n    ax=axes[\"C\"],\n    smooth=False,\n)\naxes[\"C\"].plot(\n    f_total_posterior.timestamp,\n    f_total_posterior.mean((\"chain\", \"draw\")),\n    color=\"#FBE64D\",\n    lw=2.5,\n)\naxes[\"C\"].set(xlabel=\"Timestamp\", ylabel=\"Nbr TDS\", title=\"Total GP\")\nplt.suptitle(\"Posterior GPs\", fontsize=18)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/posterior-hsgp-check-3.png){fig-pos='H' width=1163}\n:::\n:::\n\n\n## R \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# this is just to please ggdist\n\nseasons_hsgp = read_parquet('writeup-dat/seasons-hsgp.parquet') |>\n  rename(.chain = chain, .iteration = draw) |>\n  mutate(.draw = row_number()) |>\n  slice_sample(n = 50, by = .draw)\n\ngames_hsgp = read_parquet('writeup-dat/games-hsgp.parquet') |>\n  rename(.chain = chain, .iteration = draw) |>\n  mutate(.draw = row_number())\n\n\ntotal_hsgp = read_parquet('writeup-dat/total_hsgp.parquet') |>\n  rename(.chain = chain, .iteration = draw)\n\nclrs = met.brewer(name = 'Lakota')\n\ng = ggplot(games_hsgp, aes(x = gameday, y = f_games)) +\n  geom_smooth(\n    aes(group = .iteration),\n    se = FALSE,\n    alpha = 0.3,\n    color = clrs[3],\n    linewidth = 0.5\n  ) +\n  stat_lineribbon(.width = (0.89), alpha = 0.4, fill = clrs[1]) +\n  labs(x = 'Weeks', y = 'Number of TDs')\n\n\ns = ggplot(seasons_hsgp, aes(x = seasons, y = f_season)) +\n  geom_smooth(\n    aes(group = .iteration),\n    se = FALSE,\n    alpha = 0.3,\n    color = clrs[3],\n    linewidth = 0.5\n  ) +\n  stat_lineribbon(.width = (0.89), alpha = 0.4, fill = clrs[1]) +\n  labs(x = 'Number of Seasons Played', y = 'Number of TDs')\n\nt = ggplot(total_hsgp, aes(x = timestamp, y = x)) +\n  geom_smooth(\n    aes(group = .iteration),\n    se = FALSE,\n    alpha = 0.3,\n    color = clrs[3],\n    linewidth = 0.5\n  ) +\n  stat_lineribbon(.width = (0.89), alpha = 0.4, fill = clrs[1]) +\n  labs(x = 'Timestamp', y = 'Number of TDs')\n\n(g + s) / t\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-5.png){fig-pos='H' width=672}\n:::\n:::\n\n\n\n:::\n\n\nOverall, the model looks pretty good! The next avenues for exploration for modeling would be to nest players within their positions, so players are pulled closer to their position means rather than the mean of all pass catchers. I could see the argument either way that WRs are being penalized by RBs and TEs or the argument that RBs and TEs are being lifted by the WRs. Personally, I think that the estimates are probably biased downwards, where WR 2/3, TEs, and RBs are likely pulling better scoring threats downward rather than the other way around. \n\nThis has some utility if we think that we are underestimating a pass catcher’s true ability. Meaning that if our model predicts that they are better than league average, then we may be underestimating their ability by a little bit. This is nice for player evaluation because if we predict that a FB is a little bit worse of a pass catcher than we initially thought, then that’s not actually that big of a deal because we are using them as a battery ram. For a RB, than we are kind of just hoping they are a scoring threat as a runner and any additional production as a pass catcher is a nice to have.^[It would be interesting to see if there is a viable RDD for RBs on screens since the pass air yards on the pass is probably clustered in and around -1 to 1 air yards.]\n\n### Posterior Estimates \n\nNow to the fun part, plotting the data. When constructing the list of elite players, I tried to keep it simple by choosing the top 5 touchdown scorers for each position group. Then for the replacement level players, I just went with a host of players who scored 0 receiving touchdowns. I chose the 2023 season mostly because the 49ers’ offense was healthy and a juggernaut. \n\nLet’s first look at the season-level information about play above replacement. What is genuinely interesting to me is that, as a receiving scoring threat, Christian McCaffrey is mostly replaceable despite scoring 7 receiving touchdowns, which was a career high. Interestingly, we don't have a ton of TEs that are super valuable despite a lot of LaPorta's fantasy production coming from TDs in his rookie season. Interestingly, the RBs all have their Performance Above replacement, like right on the line. I think that this may just be telling us that as pass catchers, there probably isn't a ton of additional value. \n\n::: {.panel-tabset}\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\nmindex_coords = xr.Coordinates.from_pandas_multiindex(\n    cumulative_stats_pd.set_index(\n        [\n            \"receiver_full_name\",\n            \"number_of_seasons_played\",\n            \"games_played\",\n            \"season\",\n            \"receiver_position\"\n        ]\n    ).index,\n    \"obs_id\",\n)\nidata.posterior = idata.posterior.assign_coords(mindex_coords)\nidata.posterior_predictive = idata.posterior_predictive.assign_coords(mindex_coords)\n\n\nreplacement_list = (\n    cumulative_stats.unique([\"receiver_full_name\", \"season\"])\n    .with_columns(\n        pl.col(\"rec_tds_season\")\n        .rank(method=\"ordinal\")\n        .over([\"receiver_position\", \"season\"])\n        .alias(\"position_rank\")\n    )\n    .filter((pl.col(\"position_rank\") <= 5) & (pl.col(\"season\") == 2023))[\n        \"receiver_full_name\"\n    ]\n)\n\nelite_list = (\n    cumulative_stats.unique([\"receiver_full_name\", \"season\"])\n    .with_columns(\n        pl.col(\"rec_tds_season\")\n        .rank(method=\"ordinal\", descending=True)\n        .over([\"receiver_position\", \"season\"])\n        .alias(\"position_rank\")\n    )\n    .filter((pl.col(\"position_rank\") <= 5) & (pl.col(\"season\") == 2023))\n    .sort([\"receiver_position\", \"position_rank\"])[\"receiver_full_name\"]\n)\n\n\n\npost_preds = idata.posterior_predictive.reset_index('obs_id')\n\n#df = pl.from_dataframe(post_preds.to_dataframe())\n#\n#df.write_parquet('writeup-dat/posterior-predicitive.parquet')\n\nrpl_pef = post_preds[\"tds_scored\"].where(\n    (\n        (post_preds[\"receiver_full_name\"].isin(replacement_list))\n        & (post_preds[\"season\"] == 2023)\n    ),\n    drop=True,\n)\n\nelite_perf = post_preds[\"tds_scored\"].where(\n    (\n        (post_preds[\"receiver_full_name\"].isin(elite_list))\n        & (post_preds[\"season\"] == 2023)\n    ),\n    drop=True,\n)\n\n\n# Calculate PAR\nPAR = (\n    elite_perf.groupby([\"receiver_full_name\"]).mean(\"obs_id\") - rpl_pef.mean(\"obs_id\")\n).rename(\"PAR\")\n\n\nplayer_positions = (\n    cumulative_stats\n    .unique([\"receiver_full_name\", \"receiver_position\"])\n    .sort(\"receiver_position\")\n)\n\n\nposition_map = dict(zip(\n    player_positions[\"receiver_full_name\"],\n    player_positions[\"receiver_position\"]\n))\n\n\npar_df = PAR.to_dataframe().reset_index()\npar_df['position'] = par_df['receiver_full_name'].map(position_map)\n\n\npar_df = par_df.sort_values(['position', 'PAR'], ascending=[True, False])\n\n\nsorted_names = par_df['receiver_full_name'].tolist()\n\n\nPAR_sorted = PAR.sel(receiver_full_name=sorted_names)\n\n\naz.plot_forest(PAR_sorted, combined=True, colors=\"#6c1d0e\", figsize=(8, 12))\nax = plt.gca()\n\n\nlabs = [item.get_text() for item in ax.get_yticklabels()]\ncleaned_labs = []\nfor i in labs:\n    clean = i.replace(\"PAR[\", \"\").replace(\"]\", \"\").replace(\"[\", \"\")\n    cleaned_labs.append(clean)\n\nax.set_yticklabels(cleaned_labs)\n\n\nposition_counts = par_df.groupby('position').size()\ny_pos = 0\nfor pos in par_df['position'].unique():\n    count = position_counts[pos]\n    y_pos += count\n    if y_pos < len(sorted_names):  \n        ax.axhline(y=y_pos - 0.5, color='gray', linestyle=':', alpha=0.3)\n\nax.axvline(c=\"k\", ls=\"--\", alpha=0.8)\nax.set(title=\"Performance Above Replacement\", xlabel=\"Receiving Touchdown\")\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){fig-pos='H' width=758}\n:::\n:::\n\n\n## R \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nplayers_stats = load_player_stats(seasons = c(2002:2024))\n\nelite = players_stats |>\n  filter(position_group %in% c('RB', 'WR', 'TE')) |>\n  mutate(\n    rec_tds_season = sum(receiving_tds),\n    .by = c(season, player_display_name)\n  ) |>\n  group_by(season) |>\n  distinct(player_display_name, .keep_all = TRUE) |>\n  ungroup() |>\n  mutate(\n    pos_rank = rank(-rec_tds_season, ties.method = 'first'),\n    .by = c(position_group, season)\n  ) |>\n  filter(pos_rank %in% c(1:5), season == 2023) |>\n  pull(player_display_name)\n\nreplacement = players_stats |>\n  filter(position_group %in% c('RB', 'WR', 'TE')) |>\n  mutate(\n    rec_tds_season = sum(receiving_tds),\n    .by = c(season, player_display_name)\n  ) |>\n  group_by(season) |>\n  distinct(player_display_name, .keep_all = TRUE) |>\n  ungroup() |>\n  mutate(\n    pos_rank = rank(rec_tds_season, ties.method = 'first'),\n    .by = c(position_group, season)\n  ) |>\n  filter(pos_rank %in% c(1:5), season == 2023) |>\n  pull(player_display_name)\n\n\nposterior_predictive = open_dataset('writeup-dat/posterior-predicitive.parquet')\n\nelite_df = posterior_predictive |>\n  filter(receiver_full_name %in% elite, season == 2023) |>\n  summarise(\n    rec_td_probs = mean(tds_scored),\n    .by = c(receiver_full_name, draw)\n  ) |>\n  collect()\n\nreplacement_df = posterior_predictive |>\n  filter(receiver_full_name %in% replacement, season == 2023) |>\n  summarise(\n    rep_td_probs = mean(tds_scored),\n    .by = c(receiver_full_name, draw)\n  ) |>\n  collect() |>\n  select(-receiver_full_name)\n\npar_df = elite_df |>\n  left_join(\n    replacement_df,\n    join_by(draw)\n  ) |>\n  mutate(par = rec_td_probs - rep_td_probs) |>\n  left_join(\n    players_stats |>\n      filter(season == 2023) |>\n      select(player_display_name, position_group),\n    join_by(receiver_full_name == player_display_name)\n  ) |>\n  mutate(pos_num = case_match(position_group, 'RB' ~ 1, 'TE' ~ 2, 'WR' ~ 3))\n\n\nggplot(\n  par_df,\n  aes(x = par, y = fct_reorder(receiver_full_name, pos_num)),\n  fill = position_group\n) +\n  stat_halfeye() +\n  scale_fill_met_d(name = 'Lakota') +\n  geom_vline(xintercept = 0, linetype = 'dashed') +\n  labs(y = NULL, x = 'Play Above Replacement') +\n  theme(legend.position = 'none')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-3.png){fig-pos='H' width=672}\n:::\n:::\n\n\n:::\n\n\nWhat happens when we disregard the season-specific parameter? We do see some big jumps in value for almost everybody! This definitely makes more sense since Christian McCaffrey is generally regarded as a really good pass catcher, but especially at his position. Sam LaPorta has a bit more volatility than Hunter Henry and George Kittle, since, in the data, he is only a 2nd year player, so we just have less information about him. \n\n::: {.panel-tabset}\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\nrpl_pef = post_preds[\"tds_scored\"].where(\n    (\n        (post_preds[\"receiver_full_name\"].isin(replacement_list))\n        #& (post_preds[\"season\"] == 2023)\n    ),\n    drop=True,\n)\n\nelite_perf = post_preds[\"tds_scored\"].where(\n    (\n        (post_preds[\"receiver_full_name\"].isin(elite_list))\n        #& (post_preds[\"season\"] == 2023)\n    ),\n    drop=True,\n)\n\n# Calculate PAR\nPAR = (\n    elite_perf.groupby([\"receiver_full_name\"]).mean(\"obs_id\") - rpl_pef.mean(\"obs_id\")\n).rename(\"PAR\")\n\n\nplayer_positions = (\n    cumulative_stats\n    .unique([\"receiver_full_name\", \"receiver_position\"])\n    .sort(\"receiver_position\")\n)\n\n\nposition_map = dict(zip(\n    player_positions[\"receiver_full_name\"],\n    player_positions[\"receiver_position\"]\n))\n\n\npar_df = PAR.to_dataframe().reset_index()\npar_df['position'] = par_df['receiver_full_name'].map(position_map)\n\n\npar_df = par_df.sort_values(['position', 'PAR'], ascending=[True, False])\n\n\nsorted_names = par_df['receiver_full_name'].tolist()\n\n\nPAR_sorted = PAR.sel(receiver_full_name=sorted_names)\n\n\naz.plot_forest(PAR_sorted, combined=True, colors=\"#6c1d0e\", figsize=(8, 12))\nax = plt.gca()\n\n\nlabs = [item.get_text() for item in ax.get_yticklabels()]\ncleaned_labs = []\nfor i in labs:\n    clean = i.replace(\"PAR[\", \"\").replace(\"]\", \"\").replace(\"[\", \"\")\n    cleaned_labs.append(clean)\n\nax.set_yticklabels(cleaned_labs)\n\n\n\nax.axvline(c=\"k\", ls=\"--\", alpha=0.8)\nax.set(title=\"Performance Above Replacement\", xlabel=\"Receiving Touchdown\")\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){fig-pos='H' width=758}\n:::\n:::\n\n\n## R \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nelite_df = posterior_predictive |>\n  filter(receiver_full_name %in% elite) |>\n  summarise(\n    rec_td_probs = mean(tds_scored),\n    .by = c(receiver_full_name, draw)\n  ) |>\n  collect()\n\nreplacement_df = posterior_predictive |>\n  filter(receiver_full_name %in% replacement) |>\n  summarise(\n    rep_td_probs = mean(tds_scored),\n    .by = c(receiver_full_name, draw)\n  ) |>\n  collect() |>\n  select(-receiver_full_name)\n\npar_df = elite_df |>\n  left_join(\n    replacement_df,\n    join_by(draw)\n  ) |>\n  mutate(par = rec_td_probs - rep_td_probs) |>\n  left_join(\n    players_stats |>\n      filter(season == 2023) |>\n      select(player_display_name, position_group),\n    join_by(receiver_full_name == player_display_name)\n  ) |>\n  mutate(pos_num = case_match(position_group, 'RB' ~ 1, 'TE' ~ 2, 'WR' ~ 3))\n\n\nggplot(\n  par_df,\n  aes(\n    x = par,\n    y = fct_reorder(receiver_full_name, pos_num),\n    fill = position_group\n  )\n) +\n  stat_halfeye() +\n  scale_fill_met_d(name = 'Lakota') +\n  geom_vline(xintercept = 0, linetype = 'dashed') +\n  labs(y = NULL, x = 'Play Above Replacement') +\n  theme(legend.position = 'none')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-3.png){fig-pos='H' width=672}\n:::\n:::\n\n\n:::\n\nPerhaps potentially one of the most interesting non-49ers comparison to make would be to look a the evolution of the Lion's offense over Dan Campbell's tenure as head coach. For a clean comparison, we are just going to use the 2022 Lions since Ben Johnson started his tenure as offensive coordinator that year. Over his tenure as offensive coordinator, the Lions went from a plucky team doing interesting things to one of the league's best offenses. \n\nTo do this we are just going to take the posterior contrasts. I am particularly interested in two comparisons. The first is just how much better the offense is overall due to the maturation of Ben Johnson as a play caller and due to their investments into the offense. The Lions invested a fair amount of draft capital in the offense, 4 picks in the top 100 from 2021 to 2024.  The second is looking at where the offense is getting more juice. My suspicion is just that part of the story is that they are just getting more juice from the RBs and maybe a touch more juice from the TE. \n\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\nplayers_2022 = cumulative_stats.filter(\n    (pl.col('posteam') == 'DET') & (pl.col('season') == 2022)\n).select(\n    pl.col('receiver_full_name').unique()\n)['receiver_full_name'].to_list()\n\nplayers_2024 = cumulative_stats.filter(\n    (pl.col('posteam') == 'DET') & (pl.col('season') == 2024)\n).select(\n    pl.col('receiver_full_name').unique()\n)['receiver_full_name'].to_list()\n\n\nperf_2022 = post_preds['tds_scored'].where(\n    (\n        (post_preds['receiver_full_name'].isin(players_2022))\n        & (post_preds['season'] == 2022)\n    ), drop = True\n)\n\nperf_2024 = post_preds['tds_scored'].where(\n    (\n        (post_preds['receiver_full_name'].isin(players_2024))\n        & (post_preds['season'] == 2024)\n    ), drop = True\n)\n\n\n\nleague_2022 = post_preds['tds_scored'].where(\n    (\n        (post_preds['season'] == 2022) &\n        (~post_preds['receiver_full_name'].isin(players_2022))\n    ), drop = True\n)\n\n\nleague_2024 = post_preds['tds_scored'].where(\n    (\n        (post_preds['season'] == 2024) &\n        (~post_preds['receiver_full_name'].isin(players_2024))\n    ), drop = True\n)\n\nteam_avg_2022 = perf_2022.mean('obs_id')\nteam_avg_2024 = perf_2024.mean('obs_id')\n\nleague_avg_2022 = league_2022.mean(\"obs_id\")\nleague_avg_2024 = league_2024.mean('obs_id')\n\n\nleague_pos_avg_2022 = league_2022.groupby([\"receiver_position\"]).mean('obs_id') \nleague_pos_avg_2024 = league_2022.groupby(['receiver_position']).mean('obs_id')\n\nlions_pos_avg_2022 = perf_2022.groupby([\"receiver_position\"]).mean('obs_id')\nlions_pos_avg_2024 = perf_2024.groupby(['receiver_position']).mean(\"obs_id\")\n\npos_contrast_2022 = (lions_pos_avg_2022 - league_pos_avg_2022).rename('PAR')\npos_contrast_2024 = (lions_pos_avg_2024 - league_pos_avg_2024).rename('PAR')\n\n\n\nLions_League_2022 = (team_avg_2022 - league_avg_2022).rename('Lions TDs Avg - League Avg')\nLions_League_2024 = (team_avg_2024 - league_avg_2024).rename('Lions TDs Avg - League Avg')\n\n\n\n_,(right, left) = plt.subplots(1,2)\n\n\naz.plot_forest([Lions_League_2022, Lions_League_2024],\n                model_names = ['Lions v League 2022', 'Lions v League 2024'],\n                combined = True,\n                ax = right)\naz.plot_forest([pos_contrast_2022, pos_contrast_2024],\n                model_names = ['Lions v League 2022', 'Lions v League 2024'],\n                combined = True,\n                ax = left\n                )\n\nright.set(\n    title = 'Difference in Performance Between \\n 2022 Lions and 2024 Lions'\n)\nleft.set(\n    title = 'Performance by Position'\n)\nright.axvline(c = 'k', ls = '--', alpha = 0.4)\nleft.axvline(c = 'k', ls = '--', alpha = 0.4)\nleft.get_legend().remove()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){fig-pos='H' width=662}\n:::\n:::\n\n\nIt is clear that the Lion’s offense got better from Ben Johnson's first year as a play caller to his last year as a play caller in Detroit. When we break down the differences by position, we see some interesting trends. Both the WRs and TEs improve between 2022 and 2024 if only slightly. Interestingly, the RB position is kind of the same. This is a bit puzzling, as Jahmyr Gibbs is a pretty good pass catcher as a running back. \n\nI guess that the part of the reason we see improvements for the pass catchers is not only due to maturation of Amon-Ra St. Brown and upgrades at WR and TE.^[This is not a slight to T.J. Hockenson, who is an excellent TE.] Part of this improvement is likely due to how well the Lions run the ball. Part of their success running the ball is that their pass catchers are good to excellent blockers, and their O-Line is good. What this means is that they are able to run and pass the ball out of the same formations. This puts a lot of stress on a defense as Linebackers and Safeties are forced to either come forward to defend the run or the defense puts bigger bodies on the field to defend the run. This opens up opportunities in the passing games to hit explosive plays or take additional defenders in the red zone, so other pass catchers can get open.\n\nIf we want to see the evolution of a pass catcher's ability, we can just plot the probabilities over the number of games they played for each season. What we see is that the probability that Amon-Ra scores a touchdown or doesn't score a touchdown starts to be in the same neighborhood. Which is crazy! This speaks to not only his maturation as a pass catcher, but also the maturation of the system that he is in.  \n\n::: {.panel-tabset}\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\n\n# this looks pretty gross so I am just going to do this in ggplot\nplayer = \"Amon-Ra St. Brown\"\nidata.posterior = idata.posterior.rename({\"tds_scored_probs_dim_1\": \"event\"})\n\n\nimplied_probs = (\n    idata.posterior[\"tds_scored_probs\"]\n    .rename({\"tds_scored_probs_dim_0\": \"obs_id\"})\n    .assign_coords(mindex_coords)\n)\n\n\nplayer_probs_post = implied_probs.sel(receiver_full_name=player)\ncolors = plt.cm.viridis(np.linspace(0.05, 0.95, 4))\n\ncols = 2\nunique_seasons = np.unique(player_probs_post.season)\nnum_seasons = len(unique_seasons)\nrows = (num_seasons + cols - 1) // cols\n\nfig, axes = plt.subplots(\n    rows, cols, figsize=(12, 2.5 * rows), layout=\"constrained\", sharey=True\n)\n\naxes = axes.flatten()\n\n\nplayer_probs_post_df = player_probs_post.to_dataframe()\n\nfor season, (i, ax) in zip(unique_seasons, enumerate(axes)):\n    dates = player_probs_post.sel(season=season)[\"games_played\"]\n    y_plot = player_probs_post.sel(season=season)\n\n    for event in player_probs_post.event.to_numpy():\n        az.plot_hdi(\n            x=dates,\n            y=y_plot.sel(event=event),\n            hdi_prob=0.89,\n            color=colors[event],\n            fill_kwargs={\"alpha\": 0.4},\n            ax=ax,\n            smooth=False,\n        )\n        ax.plot(\n            dates,\n            y_plot.sel(event=event).mean((\"chain\", \"draw\")),\n            lw=2,\n            ls=\"--\",\n            label=f\"{event}\",\n            color=colors[event],\n            alpha=0.9,\n        )\n\n    ax.set(xlabel=\"Day\", ylabel=\"Probability\", title=f\"{season}\")\n    sns.despine()\n    if i == 0:\n        ax.legend(fontsize=10, frameon=True, title=\"TDs\", ncols=4)\n\n# remove any unused subplots\nfor j in range(i + 1, len(axes)):\n    fig.delaxes(axes[j])\n\nplt.suptitle(f\"{player.title()}\\nTDs Probabilities per Season\", fontsize=18)\n\n\n# df = pl.from_dataframe(implied_probs.to_dataframe())\n#\n#\n# df.write_parquet('writeup-dat/implied_probs.parquet')\n# \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-3.png){fig-pos='H' width=1163}\n:::\n:::\n\n\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nimplied_probs_data = open_dataset('writeup-dat/implied_probs.parquet') |>\n  rename(\n    #n_tds = tds_scored_probs_dim_1,\n    .chain = chain,\n    .iteration = draw\n  ) |>\n  select(-(contains('index_level')))\n\namon_ra = implied_probs_data |>\n  filter(receiver_full_name == 'Amon-Ra St. Brown') |>\n  collect() |>\n  mutate(.draw = row_number(), n_tds = as.factor(event))\n\n\nggplot(amon_ra, aes(x = games_played, y = tds_scored_probs, fill = n_tds)) +\n  stat_lineribbon(aes(fill_ramp = after_stat(level))) +\n  scale_fill_met_d(name = 'Troy') +\n  facet_wrap(vars(season)) +\n  labs(\n    y = 'TD Scoring Probabilities',\n    fill = 'Number of TDs',\n    x = 'Week',\n    fill_ramp = 'Level'\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-5.png){fig-pos='H' width=672}\n:::\n:::\n\n\n:::\n\n\n\nOne of the downsides the `nflreadr` data is that we do not have prime Jerry Rice in there. They do have his last 2 years as a Niner and his time as a Raider and Seahawk in there, but he was in years 14 to 19. Compared to prime Jerry Rice he had declined significantly, with his last double-digit touchdown season coming during the 1995 season. So instead, we will just look at some of the most dominant pass catchers in NFL from 2002-2024 and some of their younger contemporaries. \n\nPlayers kind towards the end of their careers and at the beginning get short changed a bit but it is pretty to cool to see just how good some of these guys are. It is crazy to think that for some players that by the act of showing up they are pretty likely to score a touchdown! What is interesting is that for good pass-catching backs generally just increase their probability to about 25%. Which seems small but you are getting a touch more juice from a fantasy RB spot if they catch a touchdown and rush for a touchdown.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nactive_player = c(\n  'Travis Kelce',\n  'George Kittle', \n  'Davante Adams',\n  'Mike Evans',\n  'Justin Jefferson', \n  \"Ja'Marr Chase\",\n  'Christian McCaffrey',\n  'Austin Ekeler',\n  'Alvin Kamara',\n  'Saquon Barkley'\n)\n\n\nall_timers = c(\n  'Jimmy Graham',\n  'Rob Gronkowski',\n  'Tony Gonzalez',\n  'Jason Witten',\n  'Terrel Owens', \n  'Antonio Gates',\n  'Randy Moss',\n  'Larry Fitzgerald', \n  'Julio Jones',\n  'Calvin Johnson', \n  \"Marshall Faulk\"\n  )\nplayers_interested_in = c(all_timers, active_player)\n\n\njoin_these = players_stats |>\n  filter(player_display_name %in% players_interested_in, position_group %in% c('RB', 'WR', 'TE')) |>\n  distinct(player_display_name, .keep_all = TRUE) |>\n  select(receiver_full_name = player_display_name, position_group)\n\nplot_data = implied_probs_data |>\n  filter(receiver_full_name %in% players_interested_in) |>\n  collect() |>\n  left_join(join_these) |>\n  mutate(\n    n_tds = as.factor(event),\n    pos_num = case_match(position_group, 'RB' ~ 1, 'TE' ~ 2, 'WR' ~ 3),\n    active = ifelse(receiver_full_name %in% active_player, 'Active Player', 'Retired Player')\n  )\n\nactive_p = ggplot(\n  data = filter(plot_data, active == 'Active Player'),\n  aes(\n      x = tds_scored_probs,\n      y = fct_reorder(receiver_full_name, pos_num),\n      color = n_tds\n   )\n) +\n    stat_pointinterval(linewidth = 0.5, size = 0.5) +\n    scale_color_met_d(name = 'Lakota') +\n    labs(x = 'TD Scoring Probabilities',\n        title = 'Active Players',\n        y = NULL,\n        color = 'Number of TDs')\n\nretired_p = ggplot(\n  data = filter(plot_data, active == 'Retired Player'),\n  aes(\n      x = tds_scored_probs,\n      y = fct_reorder(receiver_full_name, pos_num),\n      color = n_tds\n)\n) +\n    stat_pointinterval(linewidth = 0.5, size = 0.5) +\n    scale_color_met_d(name = 'Lakota') +\n    labs(x = 'TD Scoring Probabilities',\n        y = NULL, color = 'Number of TDs',\n        title = 'Retired Players')\n\nactive_p / retired_p + plot_layout(axis_titles = 'collect', guides = 'collect')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){fig-pos='H' width=672}\n:::\n:::\n\n\n\nIf there are a group of players that you are interested feel free to play around with the data in the web-r code block! \n\n\n```{webr-r}\nlibrary(ggdist)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(ggdist)\nlibrary(tidyr)\n\nlibrary(dplyr)\nlink_builder = \\(season){\n  link = glue::glue(\"https://github.com/joshuafayallen/joshuafayallen.github.io/releases/download/latest/implied-probs-{season}-season.parquet\")\n  return(link)\n}\n\ndownload_data = \\(season){\n  links_to_read = link_builder(season = season)\n\n  td_data = vctrs::list_unchop(lapply(links_to_read, \\(x) read_parquet(x)))\n\n}\n\nexample_season = download_data(season = 2023)\n\n\n\n\n```",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}