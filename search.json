[
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "Introduction to American Government \n                \n            \n            \n                Pols 1101 | \n                Georgia State University\n                \n            \n            Introduction to American Government\n\n            \n                \n                \n                 Fall 2022\n                \n                \n                \n                 Summer 2022\n                \n                \n                \n                 Spring 2022\n                \n                \n            \n        \n    \n    \n    \n        \n            \n            \n            \n        \n        \n            \n                \n                Introduction to Political Science Research \n                \n            \n            \n                Pols 3800 | \n                Georgia State University\n                \n            \n            This course serves as an introduction research methods, casual inference, applied statistics, and using R. During the semester we will cover how to develop research questions, theory development, and how to answer questions about political phenomena\n\n            \n                \n                 \n                 Spring 2023\n                \n                \n                 \n                 Summer 2023\n                \n                \n                \n                 Fall 2023\n                \n                \n            \n        \n    \n    \n    \n        \n            \n            \n            \n        \n        \n            \n                \n                R Workshops \n                \n            \n            \n                 | \n                Georgia State University\n                \n            \n            Research Data Services R Workshops\n\n            \n                \n                \n                 Spring 2023\n                \n                \n                 \n                 Fall 2022\n                \n                \n            \n        \n    \n    \n\nNo matching items"
  },
  {
    "objectID": "teaching/index.html#section",
    "href": "teaching/index.html#section",
    "title": "Teaching",
    "section": "",
    "text": "Introduction to American Government \n                \n            \n            \n                Pols 1101 | \n                Georgia State University\n                \n            \n            Introduction to American Government\n\n            \n                \n                \n                 Fall 2022\n                \n                \n                \n                 Summer 2022\n                \n                \n                \n                 Spring 2022\n                \n                \n            \n        \n    \n    \n    \n        \n            \n            \n            \n        \n        \n            \n                \n                Introduction to Political Science Research \n                \n            \n            \n                Pols 3800 | \n                Georgia State University\n                \n            \n            This course serves as an introduction research methods, casual inference, applied statistics, and using R. During the semester we will cover how to develop research questions, theory development, and how to answer questions about political phenomena\n\n            \n                \n                 \n                 Spring 2023\n                \n                \n                 \n                 Summer 2023\n                \n                \n                \n                 Fall 2023\n                \n                \n            \n        \n    \n    \n    \n        \n            \n            \n            \n        \n        \n            \n                \n                R Workshops \n                \n            \n            \n                 | \n                Georgia State University\n                \n            \n            Research Data Services R Workshops\n\n            \n                \n                \n                 Spring 2023\n                \n                \n                 \n                 Fall 2022\n                \n                \n            \n        \n    \n    \n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Josh Allen",
    "section": "",
    "text": "Welcome to my website! My name is Josh Allen and I earned my PhD in the Department of Political Science at Georgia State University. I earned my M.A. at Georgia State and am a proud Sonoma State University alum.\nMy research focuses on the impact of the Holocaust on contemporary political attitudes in Europe using causal inference tools and Large Language Models."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html",
    "title": "Tidyverse to SQL",
    "section": "",
    "text": "Since I am going on the non-academic job market it is high time I learned SQL. I have tried lots of amazing resources but find it hard for me to navigate between notes and various and learning SQL since they are just familiar enough to trip me up and lots of them send you off to various editors. This blog post will serve as my notes and hopefully as a resource for not myself. The general idea is I am just going to work through R4DS and the various dplyr verbs. Then move onto some more advanced SQL stuff like window functions and what not."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#setup",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#setup",
    "title": "Tidyverse to SQL",
    "section": "Setup",
    "text": "Setup\nFor the majority of this palmerpenguins dataset not because you really need to use SQL for a dataset this small but copying over the nyc-taxi dataset is incredibly annoying for blogging purposes.\n\nlibrary(DBI)\nlibrary(arrow)\n\n\nAttaching package: 'arrow'\n\n\nThe following object is masked from 'package:utils':\n\n    timestamp\n\nlibrary(dbplyr)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ lubridate::duration() masks arrow::duration()\n✖ dplyr::filter()       masks stats::filter()\n✖ dplyr::ident()        masks dbplyr::ident()\n✖ dplyr::lag()          masks stats::lag()\n✖ dplyr::sql()          masks dbplyr::sql()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npengs = palmerpenguins::penguins\n\ncon =  src_memdb()\n\npengs = copy_to(con, pengs,\n       overwrite = TRUE)\n\nWe are going to go back and forth using dbplyr and SQL to query the dataset. What impressed me throughout this process was how seamless dbplyr works with dplyr verbs work. With the exception of some string functions it can work as a drop in replacement for SQL. What really helped throughout this process was writing out my queries and using show_query.\n\npengs |&gt;\n    select(species) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT `species`\nFROM `pengs`\n\n\nWhich will give us a SQL query. Obviously this is a pretty simple query but as we get more and more complex this is going to be helpful. For the most part show_query outputs the right query but can be a little bit difficult to debug because of the limitations of showing things in the R console."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#select",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#select",
    "title": "Tidyverse to SQL",
    "section": "Select",
    "text": "Select\nOne convention in SQL which I don’t really get but is a thing is that functions are defined using all caps. Luckily for us the SQL and dplyr versions are pretty much the same one is just shouty. If we wanted all the columns like we may when we are importing the dataset for the first time we are just going to do SELECT * FROM taxis. There is really not like a perfect equivalent in R except for maybe head. But even then it is not a perfect one to one."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#r",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#r",
    "title": "Tidyverse to SQL",
    "section": "R",
    "text": "R\n\nhead(pengs)\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#sql",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#sql",
    "title": "Tidyverse to SQL",
    "section": "SQL",
    "text": "SQL\n\ntbl(con, sql(\"SELECT * FROM pengs\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#filter",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#filter",
    "title": "Tidyverse to SQL",
    "section": "Filter",
    "text": "Filter\nThe first major difference syntactically between dplyr and SQL is with filter statements aka WHERE statements in SQL. So let’s say we want only penguins that are Adelie penguins.\n\nRSQL\n\n\n\npengs |&gt;\n    filter(species == 'Adelie')\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nBecomes.\n\n\n\ntbl(con,sql( \"\n    SELECT * from pengs\n    WHERE species = 'Adelie'\n\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\n\n\n\n\n\nSome flavors of SQL make you end lines with ‘;’\nAs dplyr users will notice the way we specified the equality position uses the = instead of ==. This is going to come up a lot. The same thing goes for negation operations.\n\nRSQL\n\n\n\npengs |&gt;\n    filter(species != 'Adelie')\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           50            16.3               230        5700\n 3 Gentoo  Biscoe           48.7          14.1               210        4450\n 4 Gentoo  Biscoe           50            15.2               218        5700\n 5 Gentoo  Biscoe           47.6          14.5               215        5400\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           45.4          14.6               211        4800\n 8 Gentoo  Biscoe           46.7          15.3               219        5200\n 9 Gentoo  Biscoe           43.3          13.4               209        4400\n10 Gentoo  Biscoe           46.8          15.4               215        5150\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\n\n\n\ntbl(con, sql(\"SELECT * from pengs \n             WHERE NOT species = 'Adelie'\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           50            16.3               230        5700\n 3 Gentoo  Biscoe           48.7          14.1               210        4450\n 4 Gentoo  Biscoe           50            15.2               218        5700\n 5 Gentoo  Biscoe           47.6          14.5               215        5400\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           45.4          14.6               211        4800\n 8 Gentoo  Biscoe           46.7          15.3               219        5200\n 9 Gentoo  Biscoe           43.3          13.4               209        4400\n10 Gentoo  Biscoe           46.8          15.4               215        5150\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\n\n\n\nIf we want multiple conditions in our where statements instead of | or &/, we actually just use the words or and and\n\nRSQL\n\n\n\npengs |&gt;\n    filter(species == 'Chinstrap' | species == 'Adelie')\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nbecomes\n\n\n\ntbl(con, sql(\"SELECT * from pengs \n            WHERE species = 'Adelie' OR species = 'Chinstrap'\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\n\n\n\nYou could easily sub in AND but that feels a bit excessive to continue this process for each possible combination. One thing that I do all the time is use sets to subset my data.\n\nRSQL\n\n\n\npengs |&gt;\n    filter(species %in% c('Chinstrap', \"Gentoo\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           50            16.3               230        5700\n 3 Gentoo  Biscoe           48.7          14.1               210        4450\n 4 Gentoo  Biscoe           50            15.2               218        5700\n 5 Gentoo  Biscoe           47.6          14.5               215        5400\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           45.4          14.6               211        4800\n 8 Gentoo  Biscoe           46.7          15.3               219        5200\n 9 Gentoo  Biscoe           43.3          13.4               209        4400\n10 Gentoo  Biscoe           46.8          15.4               215        5150\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nBecomes\n\n\n\ntbl(con, sql(\"SELECT * from pengs\n            WHERE species IN ('Chinstrap', 'Gentoo')\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           50            16.3               230        5700\n 3 Gentoo  Biscoe           48.7          14.1               210        4450\n 4 Gentoo  Biscoe           50            15.2               218        5700\n 5 Gentoo  Biscoe           47.6          14.5               215        5400\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           45.4          14.6               211        4800\n 8 Gentoo  Biscoe           46.7          15.3               219        5200\n 9 Gentoo  Biscoe           43.3          13.4               209        4400\n10 Gentoo  Biscoe           46.8          15.4               215        5150\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\n\n\n\nin this case we define a set in a similar way. If we wanted to negate this statement all we would do is\n\ntbl(con, sql(\"SELECT * from pengs\n            WHERE NOT species IN ('Chinstrap', 'Gentoo')\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nLets say we want to find penguins that are less than the average body mass in R this is fairly straightforward\n\npengs |&gt;\n    filter(body_mass_g &lt; mean(body_mass_g, na.rm = TRUE))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           34.1          18.1               193        3475\n 8 Adelie  Torgersen           37.8          17.1               186        3300\n 9 Adelie  Torgersen           37.8          17.3               180        3700\n10 Adelie  Torgersen           41.1          17.6               182        3200\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nHowever when we do this in some flavor of SQL it is not as straightforward. These are aggregation functions that where can’t handle because thats not its job. So if we did\n\ntbl(con, \"SELECT * from pengs WHERE body_mass_g &lt; AVG(body_mass_g)\")\n\nError in `db_query_fields.DBIConnection()` at rlang/R/eval.R:96:3:\n! Can't query fields.\nℹ Using SQL: SELECT * FROM `SELECT * from pengs WHERE body_mass_g &lt;\n  AVG(body_mass_g)` AS `q01` WHERE (0 = 1)\nCaused by error:\n! no such table: SELECT * from pengs WHERE body_mass_g &lt; AVG(body_mass_g)\n\n\nWe get an error. If we wanted to use aggregation functions we have to change how we do this\n\npengs |&gt;\n    filter(body_mass_g &lt; mean(body_mass_g, na.rm = TRUE)) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT\n  `species`,\n  `island`,\n  `bill_length_mm`,\n  `bill_depth_mm`,\n  `flipper_length_mm`,\n  `body_mass_g`,\n  `sex`,\n  `year`\nFROM (\n  SELECT `pengs`.*, AVG(`body_mass_g`) OVER () AS `col01`\n  FROM `pengs`\n) AS `q01`\nWHERE (`body_mass_g` &lt; `col01`)\n\n\nWhat is this OVER thing? OVER in SQL is a window function. There is a more technical way to explain this but heuristically when we pass AVG to WHERE we are effectively doing this. So there is not really anything to compare it too.\n\npengs |&gt;\n    summarise(mean(body_mass_g, na.rm = TRUE))\n\n# Source:   SQL [?? x 1]\n# Database: sqlite 3.50.3 [:memory:]\n  `mean(body_mass_g, na.rm = TRUE)`\n                              &lt;dbl&gt;\n1                             4202.\n\n\nIf we wanted to filter penguins that are less than the average body mass we have to prevent this aggregation process by creating a column and then creating a less than statement like this\n\ntbl(con, sql(\"SELECT * FROM(\n              SELECT pengs .*, AVG(body_mass_g) OVER () AS avg\n               FROM pengs)\n              WHERE (body_mass_g &lt; avg)\"))\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           34.1          18.1               193        3475\n 8 Adelie  Torgersen           37.8          17.1               186        3300\n 9 Adelie  Torgersen           37.8          17.3               180        3700\n10 Adelie  Torgersen           41.1          17.6               182        3200\n# ℹ more rows\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, avg &lt;dbl&gt;\n\n\nIt is a little clunky but the tl;dr is that we basically have two FROM statements so if we wanted all penguins between the minimum and the average we could do\n\nRSQL\n\n\n\npalmerpenguins::penguins |&gt;\n    filter(between(body_mass_g, left = min(body_mass_g, na.rm = TRUE), right = mean(body_mass_g, na.rm = TRUE)))\n\n# A tibble: 193 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           34.1          18.1               193        3475\n 8 Adelie  Torgersen           37.8          17.1               186        3300\n 9 Adelie  Torgersen           37.8          17.3               180        3700\n10 Adelie  Torgersen           41.1          17.6               182        3200\n# ℹ 183 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\ntbl(con, sql(\"SELECT * FROM(\n             SELECT pengs .*, AVG(body_mass_g) OVER() AS avg, MIN(body_mass_g) OVER() AS min\n            FROM pengs)\n            WHERE body_mass_g BETWEEN min AND avg\"))\n\n# Source:   SQL [?? x 10]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           34.1          18.1               193        3475\n 8 Adelie  Torgersen           37.8          17.1               186        3300\n 9 Adelie  Torgersen           37.8          17.3               180        3700\n10 Adelie  Torgersen           41.1          17.6               182        3200\n# ℹ more rows\n# ℹ 4 more variables: sex &lt;chr&gt;, year &lt;int&gt;, avg &lt;dbl&gt;, min &lt;int&gt;\n\n\n\n\n\nIf you notice in all our examples, we have lots and lots of missing values. This is one of the most common tasks in like any data science task. Let’s say that we can safely ignore the missing valus. In R we have a lot of options whether we are using filter or drop_na from tidyr. However, in SQL missing values are usually represented by NULL\n\ntbl(con, sql(\"SELECt * FROM pengs \n                WHERE NOT sex IS NULL\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           39.2          19.6               195        4675\n 8 Adelie  Torgersen           41.1          17.6               182        3200\n 9 Adelie  Torgersen           38.6          21.2               191        3800\n10 Adelie  Torgersen           34.6          21.1               198        4400\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#rename",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#rename",
    "title": "Tidyverse to SQL",
    "section": "Rename",
    "text": "Rename\nThe AS function is kind the work horse for the next few sections. The naming convention differs a little bit so instead of new_name = old_name we do SELECT old_name as new_name\n\ntbl(con, sql(\"SELECT species AS kinds_of_penguins\n          FROM pengs\"))\n\n# Source:   SQL [?? x 1]\n# Database: sqlite 3.50.3 [:memory:]\n   kinds_of_penguins\n   &lt;chr&gt;            \n 1 Adelie           \n 2 Adelie           \n 3 Adelie           \n 4 Adelie           \n 5 Adelie           \n 6 Adelie           \n 7 Adelie           \n 8 Adelie           \n 9 Adelie           \n10 Adelie           \n# ℹ more rows"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#mutate",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#mutate",
    "title": "Tidyverse to SQL",
    "section": "Mutate",
    "text": "Mutate\nAs lots of things go we need to be able to create our own variables. So to do this in R we do this\n\npengs |&gt;\n    mutate(sqr_body_mass = body_mass_g^2)\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, sqr_body_mass &lt;dbl&gt;\n\n\nIn SQL to get the equivalent statement we use SELECT transformation AS new_var_name when we need to do things that are not in the dataset. So we basically need to define the column before we do anything.\n\ntbl(con, sql(\"SELECT pengs .*, POWER(body_mass_g,2) AS sqr_body_mass\n            FROM pengs\"))\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, sqr_body_mass &lt;dbl&gt;\n\n\nSo if we needed wanted to make a ratio of bill depth to bill length we would do\n\ntbl(con, sql(\"SELECT pengs .*, bill_depth_mm/bill_length_mm AS ratio \n            FROM pengs\"))\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, ratio &lt;dbl&gt;\n\n\nA very important thing we do all the time is generate indicator variables for treatment status gender etc. Oddly enough if we peep the output of show query we see a familiar face!"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#r-7",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#r-7",
    "title": "Tidyverse to SQL",
    "section": "R",
    "text": "R\n\npengs |&gt;\n    mutate(male = ifelse(sex == 'Male', 1, 0)) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT\n  `pengs`.*,\n  CASE WHEN (`sex` = 'Male') THEN 1.0 WHEN NOT (`sex` = 'Male') THEN 0.0 END AS `male`\nFROM `pengs`\n\n\nSo to make an indicator variable we would just do\n\ntbl(con, sql(\"SELECT pengs.*, CASE WHEN (sex = 'male') THEN 1.0 WHEN not (sex = 'male') THEN 0.0 END AS male\n             FROM pengs\"))\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, male &lt;dbl&gt;\n\n\nLet’s combine our window functions with our friend case_when\n\ntbl(con, sql(\"SELECT * FROM(SELECT pengs .*,\n           AVG(body_mass_g) AS avg, MIN(body_mass_g) AS min, MAX(body_mass_g) AS max,\n            CASE WHEN (body_mass_g = min) THEN 'This penguins is small' WHEN (body_mass_g = avg) THEN 'This is an average sized penguin' WHEN (body_mass_g = max) THEN 'this is a really big penguin' END AS note \n            FROM pengs)\"))\n\nI will spare you the long output of the error message. But needless to say this was wrong. If we translate what I was trying to do into dplyr we get this\n\npengs |&gt;\n    mutate(note = case_when(\n            body_mass_g == min(body_mass_g) ~ 'This is a small peng',\n            body_mass_g == mean(body_mass_g) ~ 'Average sized peng',\n            body_mass_g == max(body_mass_g) ~ 'Big sized peng',\n             .default = 'Penguin is some size')) |&gt;\n        show_query()\n\nWarning: Missing values are always removed in SQL aggregation functions.\nUse `na.rm = TRUE` to silence this warning\nThis warning is displayed once every 8 hours.\n\n\n&lt;SQL&gt;\nSELECT\n  `pengs`.*,\n  CASE\nWHEN (`body_mass_g` = MIN(`body_mass_g`) OVER `win1`) THEN 'This is a small peng'\nWHEN (`body_mass_g` = AVG(`body_mass_g`) OVER `win1`) THEN 'Average sized peng'\nWHEN (`body_mass_g` = MAX(`body_mass_g`) OVER `win1`) THEN 'Big sized peng'\nELSE 'Penguin is some size'\nEND AS `note`\nFROM `pengs`\nWINDOW `win1` AS ()\n\n\nSo it looks like we need to change the window function\n\ncheck = tbl(con, sql(\"SELECT pengs .*,\n              CASE\n            WHEN (body_mass_g &gt;= MIN(body_mass_g) OVER win1) THEN 'this is a small penguin'\n            WHEN (body_mass_g = AVG(body_mass_g) OVER win1) THEN 'this is an average sized penguin'\n            WHEN (body_mass_g = MAX(body_mass_g) OVER win1) THEN 'this is a big penguin'\n            ELSE 'This penguin is not big, small or average'\n            END AS note\n            FROM pengs \n            WINDOW win1 AS ()\")) |&gt;\n                collect()\n\nLets look at this a little closer to make sure this worked. We would probably want to make this a little more robust. So lets go ahead and define a range.\n\ntbl(con, sql(\"SELECT pengs .*,\n              CASE\n            WHEN (body_mass_g &gt;= MIN(body_mass_g) OR body_mass_g &lt; AVG(body_mass_g)  OVER win1) THEN 'this is a small penguin'\n            WHEN (body_mass_g &gt;= AVG(body_mass_g) OR body_mass_g &lt; MAX(body_mass_G) OVER win1) THEN 'this is an average sized penguin'\n            WHEN (body_mass_g &gt;= MAX(body_mass_g) OVER win1) THEN 'this is a big penguin'\n            ELSE 'This penguin is not big, small or average'\n            END AS note\n            FROM pengs \n            WINDOW win1 AS ()\"))\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.50.3 [:memory:]\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Chinstrap Dream            46.9          16.6               192        2700\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, note &lt;chr&gt;"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#group-by-and-summarize",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#group-by-and-summarize",
    "title": "Tidyverse to SQL",
    "section": "Group by and summarize",
    "text": "Group by and summarize\nAs established earlier we can use SQL to summarize like this.\n\ntbl(con, sql('SELECT AVG(bill_depth_mm) AS avg\n           FROM pengs'))\n\n# Source:   SQL [?? x 1]\n# Database: sqlite 3.50.3 [:memory:]\n    avg\n  &lt;dbl&gt;\n1  17.2\n\n\nBut the actual practical utility is somewhat limited. Often we want group specific differences. Oddly enough I expected this to be a window function thing, but we actually delay computing of the mean by different groups to the end. I guess this makes sense if we are dealing with big data\n\ntbl(con, sql(\"SELECT species, AVG(body_mass_g) AS avg_body_mass\n            FROM pengs\n            GROUP BY species\"))\n\n# Source:   SQL [?? x 2]\n# Database: sqlite 3.50.3 [:memory:]\n  species   avg_body_mass\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Adelie            3701.\n2 Chinstrap         3733.\n3 Gentoo            5076.\n\n\nSo if we wanted to count of the species we would do something along this line\n\ntbl(con, sql(\"SELECT species, COUNT(species) AS total\n            FROM pengs \n            GROUP BY species\"))\n\n# Source:   SQL [?? x 2]\n# Database: sqlite 3.50.3 [:memory:]\n  species   total\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nFor multiple grouping variables we would define the grouping variables the same way as we would in dplyr\n\ntbl(con, sql(\"SELECT species, sex, COUNT(species) AS total\n            FROM pengs \n            GROUP BY species, sex\"))\n\n# Source:   SQL [?? x 3]\n# Database: sqlite 3.50.3 [:memory:]\n  species   sex    total\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    &lt;NA&gt;       6\n2 Adelie    female    73\n3 Adelie    male      73\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    &lt;NA&gt;       5\n7 Gentoo    female    58\n8 Gentoo    male      61\n\n\nThe same would go for multiple summary functions\n\ntbl(con, sql(\"SELECT species, COUNT(species) AS total, AVG(bill_depth_mm) AS avg_bill_depth, MEDIAN(bill_depth_mm) AS median_bill_depth\n             FROM pengs \n             GROUP BY sex\"))\n\n# Source:   SQL [?? x 4]\n# Database: sqlite 3.50.3 [:memory:]\n  species total avg_bill_depth median_bill_depth\n  &lt;chr&gt;   &lt;int&gt;          &lt;dbl&gt;             &lt;dbl&gt;\n1 Adelie     11           16.6              17.1\n2 Adelie    165           16.4              17  \n3 Adelie    168           17.9              18.4"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#joinsappending-rows",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#joinsappending-rows",
    "title": "Tidyverse to SQL",
    "section": "Joins/Appending Rows",
    "text": "Joins/Appending Rows\nIn the real world it is rare that we will have all our data in one place. Companies keep information in lots of different places because well it would be bad if we kept credit card information with all the necessary components to make a purchase. Instead of having to figure out three different things malicious actors would just need to access one database. Replacing entire data tables can also skyrocket costs. So instead, it is more efficient to simply insert rows.\n\nApppending Rows\nTo kind of mimic this we are just going to slice this data frame roughly in half. While not entirely realistic the general process will be similar enough\n\n\nCode\npengs_top = palmerpenguins::penguins |&gt;\n    slice(1:172)\n\npengs_bottom = palmerpenguins::penguins |&gt;\n    slice(173:344)\n\ncon2 = src_memdb()\n\ncon3 = src_memdb()\n\npengs_top = copy_to(con2, pengs_top)\n\npengs_bottom = copy_to(con3, pengs_bottom)\n\n\nFor whatever reason show_query is not working with this so we are going to have to consult the interwebs. The SQL equivalent of bind_rows is UNION.\n\ntbl(con2, sql(\"SELECT * FROM pengs_top\n             UNION ALL \n             SELECT * FROM pengs_bottom\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nOne of the key things in this query is ALL which is somewhat new to me. Basically the ALL tells SQL that we don’t really care about duplicates so just add the rows regardless. So if we wanted to exclude duplicates we would do something like this\n\n\nCode\ntbl(con2, sql(\"SELECt * FROM pengs_top \n              UNION \n              SELECT * FROM pengs_top\")) |&gt;\n                collect() |&gt;\n                nrow()\n\n\n[1] 172\n\n\nCode\ntbl(con2,sql(\"SELECT * FROM pengs_top\") ) |&gt;\n    collect() |&gt;\n    nrow()\n\n\n[1] 172\n\n\n\n\nJoins\nLuckily for us the join syntax from dplyr is pretty directly taken SQL so lefts create some dummy data to join.\n\n\nCode\nnational_data &lt;- tribble(\n  ~state, ~year, ~unemployment, ~inflation, ~population,\n  \"GA\",   2018,  5,             2,          100,\n  \"GA\",   2019,  5.3,           1.8,        200,\n  \"GA\",   2020,  5.2,           2.5,        300,\n  \"NC\",   2018,  6.1,           1.8,        350,\n  \"NC\",   2019,  5.9,           1.6,        375,\n  \"NC\",   2020,  5.3,           1.8,        400,\n  \"CO\",   2018,  4.7,           2.7,        200,\n  \"CO\",   2019,  4.4,           2.6,        300,\n  \"CO\",   2020,  5.1,           2.5,        400\n)\n\nnational_libraries &lt;- tribble(\n  ~state, ~year, ~libraries, ~schools,\n  \"CO\",   2018,  230,        470,\n  \"CO\",   2019,  240,        440,\n  \"CO\",   2020,  270,        510,\n  \"NC\",   2018,  200,        610,\n  \"NC\",   2019,  210,        590,\n  \"NC\",   2020,  220,        530,\n)\n\ncon3 = src_memdb()\n\ncon4 = src_memdb()\n\nnational_data = copy_to(con4, national_data, overwrite = TRUE)\n\nnational_libraries = copy_to(con3, national_libraries, overwrite = TRUE)\n\n\nSo we have some fake national level data that we would like to join in to the dataset. We could do something like this but what we notice is that it is going to decide the join keys for us and probably create some headaches for us later on. To solve this we need to use our keys if we expose the underlying logic\n\nnational_data |&gt;\n    left_join(national_libraries, join_by(state, year)) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT `national_data`.*, `libraries`, `schools`\nFROM `national_data`\nLEFT JOIN `national_libraries`\n  ON (\n    `national_data`.`state` = `national_libraries`.`state` AND\n    `national_data`.`year` = `national_libraries`.`year`\n  )\n\n\nWe will notice that join_by is shorthand for equality joins. What changes is that instead of left_key = right_key we have to specify what is coming from what table using .\n\ndb_con = con4$con\n\nquery = \"SELECT *\n             FROM national_data\n             LEFT JOIN national_libraries\n             ON (\n             national_data.state = national_libraries.state AND\n             national_data.year = national_libraries.year\n             )\n             \"\n\ndbGetQuery(db_con, sql(query))       \n\n  state year unemployment inflation population state year libraries schools\n1    GA 2018          5.0       2.0        100  &lt;NA&gt;   NA        NA      NA\n2    GA 2019          5.3       1.8        200  &lt;NA&gt;   NA        NA      NA\n3    GA 2020          5.2       2.5        300  &lt;NA&gt;   NA        NA      NA\n4    NC 2018          6.1       1.8        350    NC 2018       200     610\n5    NC 2019          5.9       1.6        375    NC 2019       210     590\n6    NC 2020          5.3       1.8        400    NC 2020       220     530\n7    CO 2018          4.7       2.7        200    CO 2018       230     470\n8    CO 2019          4.4       2.6        300    CO 2019       240     440\n9    CO 2020          5.1       2.5        400    CO 2020       270     510\n\n\n\n\nFor whatever reason with SQLite gets a little grumpy with the join syntax.\nIf we wanted to do various other joins like inner and anti joins we would do a similar thing.\n\nquery = \"SELECT * \n        FROM national_data\n    INNER JOIN national_libraries \n    ON(\n    national_data.state = national_libraries.state AND\n    national_data.year = national_libraries.year\n    )\n\"\n\ndbGetQuery(db_con, sql(query))\n\n  state year unemployment inflation population state year libraries schools\n1    CO 2018          4.7       2.7        200    CO 2018       230     470\n2    CO 2019          4.4       2.6        300    CO 2019       240     440\n3    CO 2020          5.1       2.5        400    CO 2020       270     510\n4    NC 2018          6.1       1.8        350    NC 2018       200     610\n5    NC 2019          5.9       1.6        375    NC 2019       210     590\n6    NC 2020          5.3       1.8        400    NC 2020       220     530\n\n\n\n\nInequality joins\nConfession I have never really understood how inequality joins work in regular dplyr but I am sure at some point I am going to need them and now when the stakes are so low is a good time to do it. So lets just take the data from the dplyr 1.1.0 announcement to do this since we know what the output should be.\n\ncompanies &lt;- tibble(\n  id = c(\"A\", \"B\", \"B\"),\n  since = c(1973, 2009, 2022),\n  name = c(\"Patagonia\", \"RStudio\", \"Posit\")\n)\n\ntransactions &lt;- tibble(\n  company = c(\"A\", \"A\", \"B\", \"B\"),\n  year = c(2019, 2020, 2021, 2023),\n  revenue = c(50, 4, 10, 12)\n)\n\ncompanies = copy_to(con3, companies, overwrite = TRUE)\n\ntransactions = copy_to(con4, transactions, overwrite = TRUE)\n\ndb_con = con3$con\n\nSo the main idea of an inequality join is that we can join by a key in this case company but only keep records from a certain date. The blog post kind of equates it with a filter/WHERE that happens during the join phase. So we would see something like this\n\ntransactions |&gt;\n  inner_join(companies, join_by(company == id, year &gt;= since)) \n\n# Source:   SQL [?? x 5]\n# Database: sqlite 3.50.3 [:memory:]\n  company  year revenue since name     \n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    \n1 A        2019      50  1973 Patagonia\n2 A        2020       4  1973 Patagonia\n3 B        2021      10  2009 RStudio  \n4 B        2023      12  2009 RStudio  \n5 B        2023      12  2022 Posit    \n\n\nInstead of two equality statements we would effectively use the same syntax just swapping out the = with &gt;=\n\nquery = \"\n      SELECT * FROM transactions\n      INNER JOIN companies \n      ON(\n      transactions.company = companies.id AND\n      transactions.year &gt;= companies.since\n      )\n\n\"\n\ndbGetQuery(db_con, sql(query))\n\n  company year revenue id since      name\n1       A 2019      50  A  1973 Patagonia\n2       A 2020       4  A  1973 Patagonia\n3       B 2021      10  B  2009   RStudio\n4       B 2023      12  B  2009   RStudio\n5       B 2023      12  B  2022     Posit"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#pivots",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#pivots",
    "title": "Tidyverse to SQL",
    "section": "Pivots",
    "text": "Pivots\nIn tidyverse parlance we use pivots to change the “shape of the data.” If you are unfamiliar with this idea consider the religion and income data below. You will notice that we have a column for each income bracket or what is sometimes called “wide” data. This may be useful for some question but generally if we want to plot things or do things it will be easier if they are “long” data.\n\n\nCode\ncon5 = src_memdb()\n\nrelig = copy_to(con5, relig_income, overwrite = TRUE)\n\nhead(relig_income, n = 2)\n\n\n# A tibble: 2 × 11\n  religion `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 Agnostic      27        34        60        81        76       137        122\n2 Atheist       12        27        37        52        35        70         73\n# ℹ 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;,\n#   `Don't know/refused` &lt;dbl&gt;\n\n\nTo make our data “long” we use pivot_longer and to make data “wide” we use pivot_wider each has their own quirks but the general idea is that we have to tell these functions where to put the old names/where to get the new names and where to put the old values/where to get the new values. So if we wanted to make our data longer we would do something like this.\n\nlong = relig_income |&gt;\n    pivot_longer(-religion,\n                names_to = 'income_bracket',\n                values_to = 'income')\n\nhead(long, n = 2)\n\n# A tibble: 2 × 3\n  religion income_bracket income\n  &lt;chr&gt;    &lt;chr&gt;           &lt;dbl&gt;\n1 Agnostic &lt;$10k              27\n2 Agnostic $10-20k            34\n\n\nIf we wanted to make this wide again all we would do is reverse this with pivot_wider\n\nwide = long |&gt;\n    pivot_wider(names_from = income_bracket, values_from = income)\n\n\n\nThere are ton of additional functionality that will not be covered like dealing with not uniquely identified columns.\nTo get a sense of how to do this let’s consult our old friend show_query\n\nrelig |&gt;\n    pivot_longer(-religion,\n                names_to = 'income_bracket',\n                values_to = 'income') |&gt;\n                    show_query()\n\nWe are not going to actually show the results because it is quite the query. The summary of what is happening is that SQLite doesn’t have a perfect equivalent of pivot_longer. Basically, what you need to do is to keep appending smaller and smaller data frames to each other until you get to a long data frame. In other flavors of SQL this process is a lot more humane with explicit PIVOT and UNPIVOT but I am not in one of those flavors. To spare myself a bit I am just going to do two columns\n\ntbl(con5, sql(\"\n    SELECT religion, '&lt;$10k' AS income_bracket, '&lt;$10k' AS income\n    FROM relig_income \n\n    UNION ALL\n\n    SELECT religion, '$10-20k' AS income_bracket, '$10-20k' AS income\n    FROM relig_income\n\n    UNION ALL\n\n    SELECT religion, '$20-30k' AS income_bracket, '$20-30k' AS income\n    FROM relig_income\n\n    \n\"))\n\n# Source:   SQL [?? x 3]\n# Database: sqlite 3.50.3 [:memory:]\n   religion                income_bracket income\n   &lt;chr&gt;                   &lt;chr&gt;          &lt;chr&gt; \n 1 Agnostic                &lt;$10k          &lt;$10k \n 2 Atheist                 &lt;$10k          &lt;$10k \n 3 Buddhist                &lt;$10k          &lt;$10k \n 4 Catholic                &lt;$10k          &lt;$10k \n 5 Don’t know/refused      &lt;$10k          &lt;$10k \n 6 Evangelical Prot        &lt;$10k          &lt;$10k \n 7 Hindu                   &lt;$10k          &lt;$10k \n 8 Historically Black Prot &lt;$10k          &lt;$10k \n 9 Jehovah's Witness       &lt;$10k          &lt;$10k \n10 Jewish                  &lt;$10k          &lt;$10k \n# ℹ more rows\n\n\nI am a little scared to see what this looks for pivot_wider but we should at least give it a go.\n\nlong = relig |&gt;\n    pivot_longer(-religion,\n                 names_to = 'income_bracket',\n                 values_to = 'income')\n\nlong |&gt;\n    pivot_wider(names_from = income_bracket, values_from = income) |&gt;\n    show_query()\n\nOkay again this is a little unwieldy to show. Basically what happens is that we are creating a big case_when condition and then from there we are going to use the same binding trick and then group the data. So lets go ahead and copy and paste some of this.\n\n\nCode\nquery = \"\nSELECT\n    religion,\n    MAX(CASE WHEN (income_bracket = '&lt;$10k') THEN income END) AS '&lt;$10K',\n    MAX(CASE WHEN (income_bracket = '$10-20k') THEN income END) AS '$10-20k',\n    MAX(CASE WHEN (income_bracket = '$20-30k') THEN income END) AS '$20-30k'\nFROM (\n    SELECT religion, '&lt;$10k' AS income_bracket, '&lt;$10k' AS income\n    FROM relig_income\n\n    UNION ALL\n\n    SELECT religion, '$10-20k' AS income_bracket, '$10-20k' AS income\n    FROM relig_income\n\n    UNION ALL\n\n    SELECT religion, '$20-30k' AS income_bracket, '$20-30k' AS income\n    FROM relig_income\n) AS wide_religion\nGROUP BY religion\n\"\n\ntbl(con5, sql(query))\n\n\n# Source:   SQL [?? x 4]\n# Database: sqlite 3.50.3 [:memory:]\n   religion                `&lt;$10K` `$10-20k` `$20-30k`\n   &lt;chr&gt;                   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;    \n 1 Agnostic                &lt;$10k   $10-20k   $20-30k  \n 2 Atheist                 &lt;$10k   $10-20k   $20-30k  \n 3 Buddhist                &lt;$10k   $10-20k   $20-30k  \n 4 Catholic                &lt;$10k   $10-20k   $20-30k  \n 5 Don’t know/refused      &lt;$10k   $10-20k   $20-30k  \n 6 Evangelical Prot        &lt;$10k   $10-20k   $20-30k  \n 7 Hindu                   &lt;$10k   $10-20k   $20-30k  \n 8 Historically Black Prot &lt;$10k   $10-20k   $20-30k  \n 9 Jehovah's Witness       &lt;$10k   $10-20k   $20-30k  \n10 Jewish                  &lt;$10k   $10-20k   $20-30k  \n11 Mainline Prot           &lt;$10k   $10-20k   $20-30k  \n12 Mormon                  &lt;$10k   $10-20k   $20-30k  \n13 Muslim                  &lt;$10k   $10-20k   $20-30k  \n14 Orthodox                &lt;$10k   $10-20k   $20-30k  \n15 Other Christian         &lt;$10k   $10-20k   $20-30k  \n16 Other Faiths            &lt;$10k   $10-20k   $20-30k  \n17 Other World Religions   &lt;$10k   $10-20k   $20-30k  \n18 Unaffiliated            &lt;$10k   $10-20k   $20-30k"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#unnesta-brief-aside",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#unnesta-brief-aside",
    "title": "Tidyverse to SQL",
    "section": "Unnest/a brief aside",
    "text": "Unnest/a brief aside\nSo one thing that you come across from time to time in R and python data wrangling are list columns. These happen for a variety of reasons and are pretty innocuous to handle.\n\nlist_starwars = starwars |&gt;\n    select(name, films)\n\n list_starwars |&gt;\n    unnest_longer(films)\n\n# A tibble: 173 × 2\n   name           films                  \n   &lt;chr&gt;          &lt;chr&gt;                  \n 1 Luke Skywalker A New Hope             \n 2 Luke Skywalker The Empire Strikes Back\n 3 Luke Skywalker Return of the Jedi     \n 4 Luke Skywalker Revenge of the Sith    \n 5 Luke Skywalker The Force Awakens      \n 6 C-3PO          A New Hope             \n 7 C-3PO          The Empire Strikes Back\n 8 C-3PO          Return of the Jedi     \n 9 C-3PO          The Phantom Menace     \n10 C-3PO          Attack of the Clones   \n# ℹ 163 more rows\n\n\nHowever, per this Stack overflow answer and the linked question this is not really a thing or like really not advised. Even when you try to copy the starwars dataset to a database you get an error."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#misc",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#misc",
    "title": "Tidyverse to SQL",
    "section": "Misc",
    "text": "Misc"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#ranking",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#ranking",
    "title": "Tidyverse to SQL",
    "section": "Ranking",
    "text": "Ranking\nThere are lots of different ways to rank things in R if we want to return the min/max you can do\n\npengs |&gt;\n    slice_max(bill_length_mm, n = 3)\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.50.3 [:memory:]\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo    Biscoe           59.6          17                 230        6050\n2 Chinstrap Dream            58            17.8               181        3700\n3 Gentoo    Biscoe           55.9          17                 228        5600\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nThere are also various ranking functions.\n\nexample = tribble(~id, ~col1,\n                   1, 1,\n                   2, 2,\n                   3, 2,\n                   4, 3,\n                   5, 4)\n\nexample |&gt;\n    mutate(rank_one = dense_rank(col1),\n           rank_two = min_rank(col1))\n\n# A tibble: 5 × 4\n     id  col1 rank_one rank_two\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;\n1     1     1        1        1\n2     2     2        2        2\n3     3     2        2        2\n4     4     3        3        4\n5     5     4        4        5\n\n\nLike our dplyr join functions the dense_rank and min_rank function actually takes inspiration from SQL. So in our example where the two functions differ is how they handle ties. So in dense_rank and min_rank both id 2 and 3 get assigned the same rank where they differ is dense_rank will assign id 4 the rank of 3 and min_rank will assign id 4 the rank of 4.\nSo how would we do this in SQL\n\ncon7 = src_memdb()\n\nteam_rankings = copy_to(con7, example)\n\nteam_rankings |&gt;\n    mutate(rank_one = dense_rank(col1)) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT\n  `example`.*,\n  CASE\nWHEN (NOT((`col1` IS NULL))) THEN DENSE_RANK() OVER (PARTITION BY (CASE WHEN ((`col1` IS NULL)) THEN 1 ELSE 0 END) ORDER BY `col1`)\nEND AS `rank_one`\nFROM `example`\n\n\nThis is deceptively a bit more complex. So lets break it down.\n\ntbl(con7, sql(\"\nSELECT\nexample .*,\n    CASE \nWHEN (NOT((col1 is NULL))) THEN DENSE_RANK() OVER (PARTITION BY (CASE WHEN ((col1 is NULL)) THEN 1 ELSE 0 END) ORDER BY col1)\nEND AS rank_one\nFROM example\n\"))\n\n# Source:   SQL [?? x 3]\n# Database: sqlite 3.50.3 [:memory:]\n     id  col1 rank_one\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt;\n1     1     1        1\n2     2     2        2\n3     3     2        2\n4     4     3        3\n5     5     4        4\n\n\nSo basically the PARTITION BY bit is used to divide the data into groups before we rank them. The CASE WHEN handles when we have missing values. Then the window function is applying dense rank over these partions. This was a somewhat silly example so lets do something a bit more realistic. Lets say we actually want to rank the penguins by average bill length and then return the penguins in the top 3.\n\ntbl(con, sql(\n    \"\n    SELECT\n    ranked_pengs .*,\n    CASE\n    WHEN (NOT((avg_bill_length is NULL))) THEN DENSE_RANK() OVER (PARTITION BY (CASE WHEN ((avg_bill_length is NULL)) THEN 1 ELSE 0 END) ORDER BY avg_bill_length)\n    END AS rank\n    FROM( \n     SELECT pengs .*, AVG(bill_length_mm) OVER () AS avg_bill_length\n     FROM pengs)\n     AS ranked_pengs \n     LIMIT 3\n    \"\n))\n\n# Source:   SQL [?? x 10]\n# Database: sqlite 3.50.3 [:memory:]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 4 more variables: sex &lt;chr&gt;, year &lt;int&gt;, avg_bill_length &lt;dbl&gt;, rank &lt;int&gt;\n\n\nWe could also do this by groups by just inserting a group by statement before the limit bit\n\ntbl(con, sql(\n    \"\n    SELECT\n    ranked_pengs .*,\n    CASE\n    WHEN (NOT((avg_bill_length is NULL))) THEN DENSE_RANK() OVER (PARTITION BY (CASE WHEN ((avg_bill_length is NULL)) THEN 1 ELSE 0 END) ORDER BY avg_bill_length)\n    END AS rank\n    FROM( \n     SELECT pengs .*, AVG(bill_length_mm) OVER () AS avg_bill_length\n     FROM pengs)\n     AS ranked_pengs \n     GROUP BY species\n     LIMIT 3\n    \"\n))\n\n# Source:   SQL [?? x 10]\n# Database: sqlite 3.50.3 [:memory:]\n  species   island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie    Torgersen           39.1          18.7               181        3750\n2 Chinstrap Dream               46.5          17.9               192        3500\n3 Gentoo    Biscoe              46.1          13.2               211        4500\n# ℹ 4 more variables: sex &lt;chr&gt;, year &lt;int&gt;, avg_bill_length &lt;dbl&gt;, rank &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#distinct-values",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#distinct-values",
    "title": "Tidyverse to SQL",
    "section": "Distinct Values",
    "text": "Distinct Values\nDuplicates are a fact of life but depending on your question or what information you are trying to show repeated records may not be desirable. We handle these with the same function but kind of like mutate we have to let select handle these. If we wanted one row per column without having to specify every column in our dataset than we could do something like this\n\ntbl(con, sql(\"SELECT *\n            FROM(\n            SELECT pengs .*,\n            ROW_NUMBER() OVER (PARTITION BY species ORDER BY species) AS id \n            FROM PENGS) AS small_pengs\n            WHERE id = 1\"))\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.50.3 [:memory:]\n  species   island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie    Torgersen           39.1          18.7               181        3750\n2 Chinstrap Dream               46.5          17.9               192        3500\n3 Gentoo    Biscoe              46.1          13.2               211        4500\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, id &lt;int&gt;\n\n\nHowever if we have a slightly less complex query than we can feed distinct multiple columns\n\ntbl(con, sql(\"SELECT DISTINCT species, island\n            FROM pengs\"))\n\n# Source:   SQL [?? x 2]\n# Database: sqlite 3.50.3 [:memory:]\n  species   island   \n  &lt;chr&gt;     &lt;chr&gt;    \n1 Adelie    Torgersen\n2 Adelie    Biscoe   \n3 Adelie    Dream    \n4 Gentoo    Biscoe   \n5 Chinstrap Dream"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#the-endfor-now",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#the-endfor-now",
    "title": "Tidyverse to SQL",
    "section": "The End…for now",
    "text": "The End…for now\nI am sure this will end up growing as I think of more than things in R that I need to be able to do in SQL."
  },
  {
    "objectID": "blog/2024/python-notes/index.html",
    "href": "blog/2024/python-notes/index.html",
    "title": "R to Python: Just the basics",
    "section": "",
    "text": "The job hunt is in full effect and I am pushing myself to do more and more things in Python out of fear that that there will be no R option at any future job. I feel as if I have a relatively okay handle on Polars and am comfortable enough to do data cleaning when prompted. However, one of the pain points with me is that I generally have a low level of understanding of various things in Python. I am going to use this blog post as a living notebook on Python. I am bascially just going to work through the ‘Zero to Python Textbook’ and as much as possible translate it to equivalent R syntax. Right now when writing in Python I first have to translate things to R and then back again to make sure to make it make sense."
  },
  {
    "objectID": "blog/2024/python-notes/index.html#loops",
    "href": "blog/2024/python-notes/index.html#loops",
    "title": "R to Python: Just the basics",
    "section": "Loops",
    "text": "Loops\nOne of the things that is incredibly infuriating with python for me is that the indentation thing never made anysense. Why should we care about it other than making our code look pretty. The problem is that python uses indentation to denote code blocks in lieu of using {} like R or some general purpose programming languages like Java. So when we are looping over things in R we do\n\nfor(i in 1:5){\n\nprint(i^2)\n \n}\n\n[1] 1\n[1] 4\n[1] 9\n[1] 16\n[1] 25\n\n\nThis works becuase R isn’t relying on the spacing to tell it what code is in the loop. Whereas in python if we did\n\nfor i in range(1,5):\nprint(i**2)\n\nexpected an indented block after 'for' statement on line 1 (&lt;string&gt;, line 2)\n\n\nWe get an error. So if we make it a little bit more complicated we are using spacing to tell python what is inside a loop, function definition, etc\n\nfor i in range(1,6):\n    i = i * 3\n    if i%2 == 0:\n        print(f'{i} is even')\n    else:\n        print(f'{i} is odd')\n\n3 is odd\n6 is even\n9 is odd\n12 is even\n15 is odd\n\n\nOne thing I have never really understood is when and how to use else if so we should learn how to do this. I think if’s are fairly straight forward if something is true do it. Same with else if the if statment isn’t met doing something else. The best way I can explain it to myself is that else if is colloquilly more equivelent to or if\n\nvals = [1,3,4,5,56,7,78,9,7]\n\nfor i in vals:\n    if i % 2 == 0:\n        print(f'{i} is even')\n    elif i == 5:\n        print(f'{i} triggered the elif')\n    else:\n        print(f'{i} is odd')\n\n1 is odd\n3 is odd\n4 is even\n5 triggered the elif\n56 is even\n7 is odd\n78 is even\n9 is odd\n7 is odd"
  },
  {
    "objectID": "blog/2024/python-notes/index.html#tuples-and-lists",
    "href": "blog/2024/python-notes/index.html#tuples-and-lists",
    "title": "R to Python: Just the basics",
    "section": "Tuples and Lists",
    "text": "Tuples and Lists\nSo a tuple is a container that stores an ordered collection of items of the same or different primitives but is not mutable. So lets define a tuple and a list. Both have the same indexing syntax so you can index do regular and negative indexing.\n\ntp = (1, '2', 3, 2*2)\n\ntype(tp)\n\n&lt;class 'tuple'&gt;\n\nlt = [1,'2', 3, 2 *2 ]\n\ntype(lt)\n\n&lt;class 'list'&gt;\n\nprint('This is the first element of the  tuple', tp[0], 'this is the first element of the  list', lt[0])\n\nThis is the first element of the  tuple 1 this is the first element of the  list 1\n\nprint('this is the last element of the tuple', tp[-1], 'this is the last element of the list', lt[-1])\n\nthis is the last element of the tuple 4 this is the last element of the list 4\n\n\nAdditionally you can use slicing to grab a range of elements. One thing that feels weird as an R user is you can some interesting things like example 2\n\nslice_one = lt[1:4]\n\nslice_two = lt[1:2:4]\n\nprint(slice_two)\n\n['2']\n\n\nHowever, one of the major differences is if we wanted to change the underlying object. You can change the elements of a list but you cannot change the elements of a tuple\n\ntp[1] = 2\n\nTypeError: 'tuple' object does not support item assignment\n\nlt[1] = 2\n\nlt\n\n[1, 2, 3, 4]\n\n\nSo this will update the second element of the this. If we wanted to add things to a list we can simply do\n\n\nlt.append(5)\n\nIf we wanted to remove items from a list we would simply do\n\n\ndel lt[0]\n\nThe interesting thing about python is that lists are not neccessarily equivelent as vectors in R but we can do stuff we would normally would do with vectors\n\nRPython\n\n\n\nvec_one = c(1:10)\nvec_two = c(11:20)\n\n\nsum(c(vec_one, vec_two))\n\n[1] 210\n\n\n\n\n\nvec_one = list(range(1,11))\n\nvec_two = list(range(11,21))\n\nsum(vec_one + vec_two)\n\n210"
  },
  {
    "objectID": "blog/2024/python-notes/index.html#dictionaries",
    "href": "blog/2024/python-notes/index.html#dictionaries",
    "title": "R to Python: Just the basics",
    "section": "Dictionaries",
    "text": "Dictionaries\nDictionaries in Python hold key values pairs. Which as an R user is a little bit foreign since we don’t neccessarily have something that is exactly equivelent. The closest equivelent I could think of would be a named list or a named vector. But that isn’t neccessarily the same thing. One of the nice things about dicts is that you can reference things by the key, but something that is a bit weird is that you can’t really do it by index position. This is likely for a good reason, but just not someting I am used to. However, if you wanted like the first element of the first key you would just index it like a list since well the value of it is a list.\n\nmy_dict = {'fruits':['apples', 'pears'], 'numbers':[1,2,3]}\n\nmy_dict['fruits']\n\n['apples', 'pears']\n\nmy_dict['numbers']\n\n[1, 2, 3]\n\nmy_dict['fruits'][0]\n\n'apples'\n\n\nSo this definetly matters when we go and thing about iterating things. Since we have to use different syntaxes. So if you wanted to print out the all the items in a list then you could do this.\n\nfor i in lt:\n    print(i)\n\n2\n3\n4\n5\n\n\nhowever in a dictionary you only get the keys and not the values which was what I was looking for. You would have to do something like this.\n\nfor key, value in my_dict.items():\n    print(key, value)\n\nfruits ['apples', 'pears']\nnumbers [1, 2, 3]\n\n\nThis also matters when you want to add things or delete things. If we did something like this we are just overwriting the existing dictionary.\n\n\nmy_dict['fruits'] = 'mango'\n\nmy_dict['numbers'] = 100\n\nIf we wanted to actually add things without overwriting an existing dictionary you have lots of options which I will cover in the next sections. However we can start adding new key value pairs like this\n\nmy_dict['Cities'] = ['Atlanta','New York City', 'San Francisco']\n\n\nmy_dict\n\n{'fruits': 'mango', 'numbers': 100, 'Cities': ['Atlanta', 'New York City', 'San Francisco']}\n\n\nYou can also update the dictionary using update\n\nmy_dict.update({'States': ['Georgia', 'New York', 'California']})\n\nprint(my_dict)\n\n{'fruits': 'mango', 'numbers': 100, 'Cities': ['Atlanta', 'New York City', 'San Francisco'], 'States': ['Georgia', 'New York', 'California']}"
  },
  {
    "objectID": "blog/2024/python-notes/index.html#more-efficient-appending",
    "href": "blog/2024/python-notes/index.html#more-efficient-appending",
    "title": "R to Python: Just the basics",
    "section": "More efficient appending",
    "text": "More efficient appending\n\nList Compression\nI am skipping ahead a little bit but I wanted to learn this since I have only ever implemented but don’t have a full understanding of what is going on and when and why to use it. So lets say I wanted to make a new list and fill it with its square. The R user in me would do something like this\n\nnumbs &lt;- list(1, 2, 3, 4, 5,6,7,8,9,10)\n\n\nnumbs = lapply(numbs, \\(x) x * x)\n\nnumbs\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 9\n\n[[4]]\n[1] 16\n\n[[5]]\n[1] 25\n\n[[6]]\n[1] 36\n\n[[7]]\n[1] 49\n\n[[8]]\n[1] 64\n\n[[9]]\n[1] 81\n\n[[10]]\n[1] 100\n\n\nYou could do a similar thing in python.\n\nnumbs = []\n\nfor i in range(10):\n    numbs.append(i * i)\n\n\nnumbs\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\nOne of the problems that you can run into is that for a lot of stuff growing a list can take awhile. In R that is why we tend to prefer using functions along with lapply or map over for loops. So if we wanted to convert some temperatures from farenheit to celsius we would generally prefer to write a function and then apply it to a list rather than use a for loop to do this. Python has a few more tricks up its sleeve to accomplish this. If we wanted a straight forward translation from the tidyverse to python we could do.\n\ndef temp_converter(temp):\n     return (temp-32) *5/9\n\n\ntemp_list = [32, 212, 100]\n\n\nc = map(temp_converter, temp_list)\n\nlist(c)\n\n[0.0, 100.0, 37.77777777777778]\n\n\nthis is totally fine! But there are some unncessary intermediate steps and really just more me trying to force it into my tiny little functional programming mind. Instead we can use list comprehesion to speed this process up and is more in line with python.\n\nc = [temp_converter(temp_list) for temp_list in temp_list]\n\nc\n\n[0.0, 100.0, 37.77777777777778]\n\n\nOne of the benefits of this is that you can add control flows to really quickly and really flexible change elements of a list. So lets say that some celcius that leaks into our little list. Normally we would want to address this leakage, but for pedagocical purposes lets just add control flows.\n\ntemp_list = [32, 212, 100, 0] \n\n\nc = [temp_converter(temp_list) for temp_list in temp_list if temp_list not in [0,100]]\n\n\nc\n\n[0.0, 100.0]\n\n\n\n\nUpdating dictionaries\nSo in the last section we learned that updating dictionaries is a bit more delicate. One big thing that you have to keep in mind is the types within the dictionary. So our dictionary is really just two little lists with a dictionary trench coat. So we have to use list appending. So lets do that.\n\n\nnew_dict = {'fruits': ['watermelons', 'strawberries'],  'numbers' : [4,5,6]}\n\nnew_dict['fruits'].append('cherry')\n\nnew_dict['numbers'].append(7)\n\nThis is fine but not neccessarily the most efficient way to do things outside of canned examples. The most likely case is that we have a new dictionary to help us update things.\n\n\nupdate_dict = {'fruits': ['mangos', 'rasberry', 'jackfruit'], 'numbers':[2,4,5,6,7]}\n\nnew_dict['fruits'].extend(update_dict['fruits'])\n\nSince our dictionaries hold lists we could also theoretically use list comprehesion like this.\n\nnew_dict['numbers'] = [temp_converter(num) for num in new_dict['numbers']]\n\nnew_dict\n\n{'fruits': ['watermelons', 'strawberries', 'cherry', 'mangos', 'rasberry', 'jackfruit'], 'numbers': [-15.555555555555555, -15.0, -14.444444444444445, -13.88888888888889]}\n\n\nWe can also combine dictionaries using the | operator\n\njosh_vals = {'Name': 'Josh Allen', 'Location' : 'Atlanta', 'job': 'Grad Student'}\n\ngeorgia_vals = {'Nickname': 'Peach State', 'mascot': 'White Tailed Dear', 'Power 5 Schools': ['UGA', 'Georgia Tech']}\n\njosh_vals | georgia_vals\n\n{'Name': 'Josh Allen', 'Location': 'Atlanta', 'job': 'Grad Student', 'Nickname': 'Peach State', 'mascot': 'White Tailed Dear', 'Power 5 Schools': ['UGA', 'Georgia Tech']}\n\n\nWe can also modify in place using a special operator\n\njosh_vals |= georgia_vals\n\nIf we wanted to keep it within a Python framework we can use something called dictionary compression were we can do something like this\n\n\nsquares_dict = {i: i**2 for i in range(1,11)}\n\nOr if we had somethign like this\n\nmy_dict = {'United States' : 'Washington DC', 'France' : 'Paris', 'Italy' : 'Rome'}\n\n{capital: country for country, capital in my_dict.items()}\n\n{'Washington DC': 'United States', 'Paris': 'France', 'Rome': 'Italy'}"
  },
  {
    "objectID": "blog/2024/python-notes/index.html#class-instance-and-static-methods",
    "href": "blog/2024/python-notes/index.html#class-instance-and-static-methods",
    "title": "R to Python: Just the basics",
    "section": "Class, instance, and static methods",
    "text": "Class, instance, and static methods\nOne way we can do this is enforcing types in our functions. There are several flavors which can be used to enforce various behaviours\n\nInstance methods\nInstance methods are the most common and are really just functions defined in the body of the class. However they take on a different flavor when we are using them inside the body of the class\n\nclass Dog:\n    def __init__(self, age: int, name:str):\n        if not isinstance(name, str):\n            raise ValueError(\"Name must be a string\")\n        self.name = name\n        if not isinstance(age, int):\n            raise ValueError(\"Age must be an integer\")\n        self.age  = age\n    def description(self, age:int, name:str):\n        print(f\"{self.name} is {self.age} old\")\n\n\ndoggo = Dog(name = 7, age = 'This is a string')\n\nValueError: Name must be a string\n\n\nNow our class is a little bit more robust we can’t start passing things off that we shouldn’t. One thing that we can do is actually bypass the the name/age checks\n\ndog = Dog(age=5, name=\"Buddy\")\n\ndog.description(age = 'five', name = 123)\n\nBuddy is 5 old\n\n\nOne thing that you will notice is that the description doesn’t care about these violations. Which is not ideal so to make this even more robust we can add some fairly simple checks\n\nclass Dog:\n    def __init__(self, name:str, age:int):\n        if not isinstance(name, str):\n            raise ValueError(\"name should be a string\")\n        self.name = name\n        if not isinstance(age, int) or age &lt;= 0:\n            raise ValueError(\"age should be an integer or be greater than 1\")\n        self.age = age\n    def description(self, name, age):\n        if age != self.age or name != self.name:\n            raise ValueError(\"Provided age or name does not match dog attributes\")\n        print(f\"{self.name} is {self.age} years old\")\n\n\ndog = Dog(age=5, name=\"Buddy\")\n\ndog.description(age = 'five', name = 123)\n\nValueError: Provided age or name does not match dog attributes"
  },
  {
    "objectID": "CV/index.html",
    "href": "CV/index.html",
    "title": "Curriculum vitae",
    "section": "",
    "text": "Download current CV"
  },
  {
    "objectID": "blog/2022/2021-11-25-what-to-do-when-you-break-r/index.html",
    "href": "blog/2022/2021-11-25-what-to-do-when-you-break-r/index.html",
    "title": "What to do when you break R",
    "section": "",
    "text": "Hi all, when I first stated using R I tried making my website using blogdown. While Alison Hill PhD provides an excellent intro to launching your website. However, I am truly special and managed to mess this process up. For a few days whenever I did anything more computationally intensive than\n\nrm(list=ls())\nlibrary(tidyverse)\n\nI would get a nasty error message saying “c stack usage is too close to the limit” and I could not do anything. This would have been fine but at the time I was still taking classes and need to have R working to complete the problem sets.\nSo what did I do to get in the c stack death spiral and how did it end up being fixed? For the former you should not skip steps in Dr. Hill’s post. For the later well to spare you the long arduous process here is what we tried.\n\nme consulting stackoverflow & realizing I really f****k up\nrestarting my computer\nuninstalling & reinstalling blogdown\nuninstalling & reinstalling R\nuninstalling & reinstalling pandocs\n\nAfter hours of trouble shooting #rstats twitter came to the rescue when this distress signal was sent out.\n\n\n#rstats world! I have a student who is getting a \"c stack usage is too close to the limit\" every time when using knitr (even with an R-chunk-free Rmd file) & getting same error when trying to install anything with devtools or remotes. We've un/reinstalled R but no luck. Ideas?\n\n— Andrew Heiss (🐘 @andrew@fediscience.org) (@andrewheiss) February 7, 2021\n\n\nSo here is what ended up working. To start you will need a super simple Rmd file to test with in a local directory. I suggest starting a new Rmd file with nothing in it other than the default YAML header and “test” in the main body or “Lorem Ipsum” if you feel fancy.\nIn the terminal run the following code\n\ncd ~ \n\nls -la\n\nThen look for files starting with a period. Okay if you messed up in the initial blogdown setup you are looking for the “.Rprofile” that is causing you the problem. What ended up happening is that you broke all of R by including a recursive function. So restarting and uninstalling R will not kill the function it will be there\n\n\n\nWhat you are going to do is open a terminal in Rstudio or otherwise than start running this.\n\ncat.Rprofile\n\nthan run\n\ncat.zshrc\n\nthan after that run\nmv. Rprofile .Rprofile-original\nThen close out Rstudio and reopen Rstudio. Then try to knit your super simple Rmd file and install a package and doing something fun! Than knit that file.\nHopefully the dreaded C stack usage error is gone. If it is than celebrate\n\n\n\nbecause you can use R again!!!!"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html",
    "href": "blog/2024/translating-dplyr-to-polars/index.html",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "",
    "text": "I suppose at some point it is good to become more well versed in lots of tools. I have been python curious for about a year or so and I think it is important to use the tool best suited for the task. Also sometimes it is important to get out of your comfort zone. I am definitely somebody who is very comfortable in R and the tidyverse and use it for a lot of stuff. I have heard lots of ravings about polars specifically about its speed and similarities in intuition with the tidyverse. So I thought I would have a collection of code for myself and the people of the internet to reference.\nJust a disclaimer. This is really just me working through the similarities and is going to be based on the tidyintelligence’s blog post, Robert Mitchell’s blog post, and Emily Rieder’s blog post. In all honesty, this is just for me to smash them together to have a one-stop shop for myself. If you found this post over these resources I highly recommend you check out these resources."
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#r-6",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#r-6",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "R",
    "text": "R\n\npenguins |&gt;\nfilter(!species %in% c(\"Gentoo\", \"Chinstrap\"),\n       island != \"Dream\")\n\n# A tibble: 96 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 86 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#python-6",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#python-6",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Python",
    "text": "Python\n\n# | error: true\n# | label: set-filter-not\n\npenguins.filter((pl.col(\"species\").is_in([\"Chinstrap\", \"Gentoo\"]).not_()) &\n                (pl.col(\"island\") != 'Dream'))\n\n\nshape: (96, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nstr\ni64\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181.0\n3750.0\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186.0\n3800.0\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195.0\n3250.0\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\nnull\nnull\nnull\nnull\nnull\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n36.7\n19.3\n193.0\n3450.0\n\"female\"\n2007\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Adelie\"\n\"Torgersen\"\n41.5\n18.3\n195.0\n4300.0\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n39.0\n17.1\n191.0\n3050.0\n\"female\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n44.1\n18.0\n210.0\n4000.0\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n38.5\n17.9\n190.0\n3325.0\n\"female\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n43.1\n19.2\n197.0\n3500.0\n\"male\"\n2009\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#group-by-and-summarize",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#group-by-and-summarize",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Group by and summarize",
    "text": "Group by and summarize\nLast but not least we need to do the group by and summarise bit. It looks like this is slightly more intuitive\n\nRPython\n\n\n\npenguins |&gt;\ngroup_by(species) |&gt;\nsummarise(total = n())\n\n# A tibble: 3 × 2\n  species   total\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\n\n\n\npenguins.group_by(pl.col(\"species\")).agg(total = pl.count())\n\n\nshape: (3, 2)\n\n\n\nspecies\ntotal\n\n\nstr\nu32\n\n\n\n\n\"Adelie\"\n152\n\n\n\"Gentoo\"\n124\n\n\n\"Chinstrap\"\n68\n\n\n\n\n\n\n\n\n\nLets do some mathy stuff\n\npenguins.group_by(pl.col(\"species\")).agg(count = pl.len(),\n                                         mean_flipp = pl.mean(\"flipper_length_mm\"),\n                                         median_flipp = pl.median(\"flipper_length_mm\"))\n\n\nshape: (3, 4)\n\n\n\nspecies\ncount\nmean_flipp\nmedian_flipp\n\n\nstr\nu32\nf64\nf64\n\n\n\n\n\"Adelie\"\n152\n189.953642\n190.0\n\n\n\"Chinstrap\"\n68\n195.823529\n196.0\n\n\n\"Gentoo\"\n124\n217.186992\n216.0\n\n\n\n\n\n\n\nacross\nA thing that is useful in summarize is that we can use our selectors to summarise across multiple columns like this\n\npenguins |&gt;\ngroup_by(species) |&gt;\nsummarise(across(starts_with(\"bill\"), list(mean = \\(x) mean(x, na.rm = TRUE,\n                                           median = \\(x) median(x, na.rm,  TRUE)))))\n\n# A tibble: 3 × 3\n  species   bill_length_mm_mean bill_depth_mm_mean\n  &lt;fct&gt;                   &lt;dbl&gt;              &lt;dbl&gt;\n1 Adelie                   38.8               18.3\n2 Chinstrap                48.8               18.4\n3 Gentoo                   47.5               15.0\n\n\nIn polars I imagine it would probably be something like this\n\npenguins.group_by(pl.col(\"species\")).agg(cs.starts_with(\"bill\").mean())\n\n\nshape: (3, 3)\n\n\n\nspecies\nbill_length_mm\nbill_depth_mm\n\n\nstr\nf64\nf64\n\n\n\n\n\"Chinstrap\"\n48.833824\n18.420588\n\n\n\"Adelie\"\n38.791391\n18.346358\n\n\n\"Gentoo\"\n47.504878\n14.982114\n\n\n\n\n\n\nThe think I am running into now is that I would like to add a _ without doing any extra work. It looks like according to the docs it should be this\n\npenguins.group_by(pl.col(\"species\")).agg(cs.starts_with(\"bill\").mean().name.suffix(\"_mean\"),\n                                         cs.starts_with(\"bill\").median().name.suffix(\"_median\"))\n\n\nshape: (3, 5)\n\n\n\nspecies\nbill_length_mm_mean\nbill_depth_mm_mean\nbill_length_mm_median\nbill_depth_mm_median\n\n\nstr\nf64\nf64\nf64\nf64\n\n\n\n\n\"Chinstrap\"\n48.833824\n18.420588\n49.55\n18.45\n\n\n\"Gentoo\"\n47.504878\n14.982114\n47.3\n15.0\n\n\n\"Adelie\"\n38.791391\n18.346358\n38.8\n18.4"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#pivots-of-all-shapes",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#pivots-of-all-shapes",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Pivots of all shapes",
    "text": "Pivots of all shapes\nSometimes we need to pivot our data. Lets use the built in example from tidyr. Basically we have a whole bunch of columns that denote counts of income brackets\n\nrelig = relig_income\n\n\nwrite_csv(relig,\"relig_income.csv\")\n\n\nhead(relig_income)\n\n# A tibble: 6 × 11\n  religion  `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 Agnostic       27        34        60        81        76       137        122\n2 Atheist        12        27        37        52        35        70         73\n3 Buddhist       27        21        30        34        33        58         62\n4 Catholic      418       617       732       670       638      1116        949\n5 Don’t kn…      15        14        15        11        10        35         21\n6 Evangeli…     575       869      1064       982       881      1486        949\n# ℹ 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;,\n#   `Don't know/refused` &lt;dbl&gt;\n\n\nIn tidyr we would just do this\n\nrelig |&gt;\npivot_longer(-religion,\n              names_to = \"income_bracket\",\n              values_to = \"count\")\n\n# A tibble: 180 × 3\n   religion income_bracket     count\n   &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;\n 1 Agnostic &lt;$10k                 27\n 2 Agnostic $10-20k               34\n 3 Agnostic $20-30k               60\n 4 Agnostic $30-40k               81\n 5 Agnostic $40-50k               76\n 6 Agnostic $50-75k              137\n 7 Agnostic $75-100k             122\n 8 Agnostic $100-150k            109\n 9 Agnostic &gt;150k                 84\n10 Agnostic Don't know/refused    96\n# ℹ 170 more rows\n\n\nwhich is nice because we can just identify a column and then pivot. One thing that I will have to just memorize is that when we are moving things to long in polars than we melt the dataframe. Kind of like a popsicle or something. The mnemonic device will come to me eventually\n\nrelig = pl.read_csv(\"relig_income.csv\")\n\nrelig.head()\n\n\nshape: (5, 11)\n\n\n\nreligion\n&lt;$10k\n$10-20k\n$20-30k\n$30-40k\n$40-50k\n$50-75k\n$75-100k\n$100-150k\n&gt;150k\nDon't know/refused\n\n\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n\"Agnostic\"\n27\n34\n60\n81\n76\n137\n122\n109\n84\n96\n\n\n\"Atheist\"\n12\n27\n37\n52\n35\n70\n73\n59\n74\n76\n\n\n\"Buddhist\"\n27\n21\n30\n34\n33\n58\n62\n39\n53\n54\n\n\n\"Catholic\"\n418\n617\n732\n670\n638\n1116\n949\n792\n633\n1489\n\n\n\"Don’t know/refused\"\n15\n14\n15\n11\n10\n35\n21\n17\n18\n116\n\n\n\n\n\n\nTo melt all we do is\n\nrelig.melt(id_vars = \"religion\", variable_name = \"income_bracket\", value_name = \"count\")\n\n\nshape: (180, 3)\n\n\n\nreligion\nincome_bracket\ncount\n\n\nstr\nstr\ni64\n\n\n\n\n\"Agnostic\"\n\"&lt;$10k\"\n27\n\n\n\"Atheist\"\n\"&lt;$10k\"\n12\n\n\n\"Buddhist\"\n\"&lt;$10k\"\n27\n\n\n\"Catholic\"\n\"&lt;$10k\"\n418\n\n\n\"Don’t know/refused\"\n\"&lt;$10k\"\n15\n\n\n…\n…\n…\n\n\n\"Orthodox\"\n\"Don't know/refused\"\n73\n\n\n\"Other Christian\"\n\"Don't know/refused\"\n18\n\n\n\"Other Faiths\"\n\"Don't know/refused\"\n71\n\n\n\"Other World Religions\"\n\"Don't know/refused\"\n8\n\n\n\"Unaffiliated\"\n\"Don't know/refused\"\n597\n\n\n\n\n\n\nsame would go for the pivoting wider\n\npenguins.pivot(index = \"island\",columns = \"species\", values = \"body_mass_g\",\n              aggregate_function=\"sum\")\n\n\nshape: (3, 4)\n\n\n\nisland\nAdelie\nGentoo\nChinstrap\n\n\nstr\nf64\nf64\nf64\n\n\n\n\n\"Torgersen\"\n189025.0\nnull\nnull\n\n\n\"Biscoe\"\n163225.0\n624350.0\nnull\n\n\n\"Dream\"\n206550.0\nnull\n253850.0\n\n\n\n\n\n\nthis isn’t quite the same because we are aggregating it. This is likely just a skill issue on the user end. But still we have wide data now!\n\nUsing selectors in pivot longer\nA slightly more complex example is using the billboards datas\n\nbillboards = tidyr::billboard\n\n\nwrite_csv(billboards, \"billboard.csv\")\n\n\nhead(billboards)\n\n# A tibble: 6 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby… 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp… 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do… Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb… 2000-04-15      57    34    25    17    17    31    36    49\n6 98^0        Give… 2000-08-19      51    39    34    26    26    19     2     2\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, …\n\n billboards |&gt;\npivot_longer(cols = starts_with(\"wk\"),\n              names_to = \"week\",\n              values_to = \"count_of_weeks\")\n\n# A tibble: 24,092 × 5\n   artist track                   date.entered week  count_of_weeks\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt;          &lt;dbl&gt;\n 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1               87\n 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2               82\n 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3               72\n 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4               77\n 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5               87\n 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6               94\n 7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7               99\n 8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8               NA\n 9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9               NA\n10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10              NA\n# ℹ 24,082 more rows\n\n\nWe can do something similar with polars by using our selectors.\n\nbillboards = pl.read_csv(\"billboard.csv\")\n\n\nbillboards.melt(id_vars = \"artist\",value_vars  = cs.starts_with(\"wk\"),\n                variable_name = \"week\", value_name = \"count\" )\n\n\nshape: (24_092, 3)\n\n\n\nartist\nweek\ncount\n\n\nstr\nstr\nstr\n\n\n\n\n\"2 Pac\"\n\"wk1\"\n\"87\"\n\n\n\"2Ge+her\"\n\"wk1\"\n\"91\"\n\n\n\"3 Doors Down\"\n\"wk1\"\n\"81\"\n\n\n\"3 Doors Down\"\n\"wk1\"\n\"76\"\n\n\n\"504 Boyz\"\n\"wk1\"\n\"57\"\n\n\n…\n…\n…\n\n\n\"Yankee Grey\"\n\"wk76\"\n\"NA\"\n\n\n\"Yearwood, Trisha\"\n\"wk76\"\n\"NA\"\n\n\n\"Ying Yang Twins\"\n\"wk76\"\n\"NA\"\n\n\n\"Zombie Nation\"\n\"wk76\"\n\"NA\"\n\n\n\"matchbox twenty\"\n\"wk76\"\n\"NA\"\n\n\n\n\n\n\nBroadly it works the same but if you don’t specify the id vars you will end up with just the week and count column"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#unnest",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#unnest",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Unnest",
    "text": "Unnest\nSometimes we have these unfriendly list columns that we would like to make not lists. Lets go ahead and use the starwars list columns.\n\nstarwars_lists = starwars |&gt;\nselect(name, where(is.list)) |&gt;\nunnest_longer(starships , keep_empty = TRUE) |&gt;\nunnest_longer(films, keep_empty = TRUE) |&gt;\nunnest_longer(vehicles, keep_empty = TRUE)\n\n\n\n\n\nhead(starwars_lists)\n\n# A tibble: 6 × 4\n  name           films                   vehicles              starships\n  &lt;chr&gt;          &lt;chr&gt;                   &lt;chr&gt;                 &lt;chr&gt;    \n1 Luke Skywalker A New Hope              Snowspeeder           X-wing   \n2 Luke Skywalker A New Hope              Imperial Speeder Bike X-wing   \n3 Luke Skywalker The Empire Strikes Back Snowspeeder           X-wing   \n4 Luke Skywalker The Empire Strikes Back Imperial Speeder Bike X-wing   \n5 Luke Skywalker Return of the Jedi      Snowspeeder           X-wing   \n6 Luke Skywalker Return of the Jedi      Imperial Speeder Bike X-wing   \n\n\nIn polars we have a similarish function named explode. Unfortunately we don’t have a a selector for all attribute types so we are going to do this by hand.\n\nstarwars_list = starwars.select([\"name\", \"films\", \"vehicles\", \"starships\"])\n\nstarwars_list.glimpse()\n\nRows: 87\nColumns: 4\n$ name            &lt;str&gt; 'Luke Skywalker', 'C-3PO', 'R2-D2', 'Darth Vader', 'Leia Organa', 'Owen Lars', 'Beru Whitesun Lars', 'R5-D4', 'Biggs Darklighter', 'Obi-Wan Kenobi'\n$ films     &lt;list[str]&gt; ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'Revenge of the Sith', 'The Force Awakens'], ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'The Phantom Menace', 'Attack of the Clones', 'Revenge of the Sith'], ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'The Phantom Menace', 'Attack of the Clones', 'Revenge of the Sith', 'The Force Awakens'], ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'Revenge of the Sith'], ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'Revenge of the Sith', 'The Force Awakens'], ['A New Hope', 'Attack of the Clones', 'Revenge of the Sith'], ['A New Hope', 'Attack of the Clones', 'Revenge of the Sith'], ['A New Hope'], ['A New Hope'], ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'The Phantom Menace', 'Attack of the Clones', 'Revenge of the Sith']\n$ vehicles  &lt;list[str]&gt; ['Snowspeeder', 'Imperial Speeder Bike'], [], [], [], ['Imperial Speeder Bike'], [], [], [], [], ['Tribubble bongo']\n$ starships &lt;list[str]&gt; ['X-wing', 'Imperial shuttle'], [], [], ['TIE Advanced x1'], [], [], [], [], ['X-wing'], ['Jedi starfighter', 'Trade Federation cruiser', 'Naboo star skiff', 'Jedi Interceptor', 'Belbullab-22 starfighter']\n\nstarwars_explode =  starwars_list.explode(\"films\").explode(\"vehicles\").explode(\"starships\")\n\nstarwars_explode.head()\n\n\nshape: (5, 4)\n\n\n\nname\nfilms\nvehicles\nstarships\n\n\nstr\nstr\nstr\nstr\n\n\n\n\n\"Luke Skywalker\"\n\"A New Hope\"\n\"Snowspeeder\"\n\"X-wing\"\n\n\n\"Luke Skywalker\"\n\"A New Hope\"\n\"Snowspeeder\"\n\"Imperial shuttle\"\n\n\n\"Luke Skywalker\"\n\"A New Hope\"\n\"Imperial Speeder Bike\"\n\"X-wing\"\n\n\n\"Luke Skywalker\"\n\"A New Hope\"\n\"Imperial Speeder Bike\"\n\"Imperial shuttle\"\n\n\n\"Luke Skywalker\"\n\"The Empire Strikes Back\"\n\"Snowspeeder\"\n\"X-wing\""
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#histograms",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#histograms",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Histograms",
    "text": "Histograms\n\n\nsns.histplot(data = penguins, x = \"body_mass_g\")\n\n\n\n\n\n\n\n\neasy enough\n\n\nsns.histplot(data = penguins, x = \"body_mass_g\", hue  = \"species\")\n\n\n\n\n\n\n\n\nWhat if we wanted densities instead of frequencies? In ggplot it would be\n\nggplot(penguins, aes(x = body_mass_g, fill = species)) +\ngeom_histogram(aes(y =  after_stat(density)))\n\n\n\n\n\n\n\n\nIn sns it would be.\n\n\nsns.histplot(data = penguins, x = \"body_mass_g\", hue = \"species\", stat = \"density\")\n\n\n\n\n\n\n\n\nI really like the legend on the inside! In new ggplot 3.whatever it is different now that there is an explicit legend.position=\"inside\".\n\nggplot(penguins, aes(x = body_mass_g, y = after_stat(density), fill = species)) +\ngeom_histogram() +\ntheme_minimal() +\ntheme(legend.position = c(.95,.95),\n      legend.justification = c(\"right\", \"top\"))\n\n\n\n\n\n\n\n\nCool I like that and will fiddle with that my ggplot theme!\nOkay lets now go and do some bivariate plots. Obviously the workhorse of bivariate plotting is the scatterplot ."
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#scatter-plots",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#scatter-plots",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Scatter Plots",
    "text": "Scatter Plots\n\n\nsns.scatterplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\")\n\n\n\n\n\n\n\n\nthe next thing that we would want is to size points by the size of the penguin\n\n\nsns.scatterplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\", size = \"body_mass_g\")\n\n\n\n\n\n\n\n\nThat is not really great since the legend is inside and covering stuff. In ggplot we would simply just move the legend position. In this case we have to save it as an object"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#adjusting-legend",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#adjusting-legend",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Adjusting legend",
    "text": "Adjusting legend\n\n\nexmp = sns.scatterplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\", size = \"body_mass_g\")\n\nsns.move_legend(exmp, \"upper left\", bbox_to_anchor = (1,1))\n\n\n\n\n\n\n\n\n\nsns.lmplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThen the other one that I use all the time is using a line of best fit . Okay obviously the most annoying part is that we don’t have great labels"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#adding-informative-labels",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#adding-informative-labels",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Adding Informative Labels",
    "text": "Adding Informative Labels\n\nlabs_examp = sns.lmplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\")\n\n\n\nlabs_examp.set_axis_labels(x_var= \"Flipper Length(mm)\", y_var = \"Body Mass(g)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the things we may want to do is to create small multiples."
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#facet-wrap",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#facet-wrap",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Facet Wrap",
    "text": "Facet Wrap\n\nsns.displot(data = penguins, x = \"body_mass_g\", hue = \"species\", row= \"species\", facet_kws = dict(margin_titles=False))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI am honestly not wild about the plot but that is life"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#make-a-column-into-a-vector",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#make-a-column-into-a-vector",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Make a column into a vector",
    "text": "Make a column into a vector\nIn R there are like a ton of different ways to do this\n\nvec1 = penguins$bill_depth_mm\n\nvec2 = penguins |&gt;\npluck(\"bill_depth_mm\")\n\nvec3 = penguins |&gt;\nselect(bill_depth_mm) |&gt;\ndeframe()\n\nIn polars the equivalent of this\n\nvec1 = penguins[\"bill_depth_mm\"]\n\nprint(vec1[0,1])\n\nshape: (2,)\nSeries: 'bill_depth_mm' [str]\n[\n    \"18.7\"\n    \"17.4\"\n]\n\n\n\nRPython\n\n\n\nvec1[1:3]\n\n[1] 18.7 17.4 18.0\n\n\n\n\n\nimport numpy as np \n\nprint(vec1[0:2])\n\nshape: (2,)\nSeries: 'bill_depth_mm' [str]\n[\n    \"18.7\"\n    \"17.4\"\n]"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "January 1, 2022\n        \n        \n            What to do when you break R\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    zsh\n                \n                \n            \n            \n\n            What happens when you keep getting c stack usage errors \n        \n        \n    \n    \n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section",
    "href": "blog/index.html#section",
    "title": "Blog",
    "section": "",
    "text": "January 1, 2022\n        \n        \n            What to do when you break R\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    zsh\n                \n                \n            \n            \n\n            What happens when you keep getting c stack usage errors \n        \n        \n    \n    \n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section-1",
    "href": "blog/index.html#section-1",
    "title": "Blog",
    "section": "2024",
    "text": "2024\n\n\n    \n    \n                  \n            \n        \n        \n            Tidyverse to SQL\n\n            \n\n            \n        \n        \n    \n    \n    \n                  \n            July 23, 2025\n        \n        \n            R to Python: Just the basics\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    tidyverse\n                \n                \n                \n                    python\n                \n                \n            \n            \n\n            This is me learning the snake language\n        \n        \n    \n    \n    \n                  \n            July 23, 2025\n        \n        \n            Translating What I know in the tidyverse to polars:\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    tidyverse\n                \n                \n                \n                    python\n                \n                \n                \n                    polars\n                \n                \n            \n            \n\n            This is me learning the snake language\n        \n        \n    \n    \n\nNo matching items"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research and Projects",
    "section": "",
    "text": "Allen Joshua. “The Use of The Holocaust in Online Discourse and in Media: A Computational Approach”\nAllen Joshua. “Collective Memory and Contemporary Political Behavior: Evidence from France”"
  },
  {
    "objectID": "research/index.html#working-papers",
    "href": "research/index.html#working-papers",
    "title": "Research and Projects",
    "section": "",
    "text": "Allen Joshua. “The Use of The Holocaust in Online Discourse and in Media: A Computational Approach”\nAllen Joshua. “Collective Memory and Contemporary Political Behavior: Evidence from France”"
  },
  {
    "objectID": "research/index.html#dormant-papers",
    "href": "research/index.html#dormant-papers",
    "title": "Research and Projects",
    "section": "Dormant Papers",
    "text": "Dormant Papers\n\nAllen Joshua. Testing The Effects of U.S. Airstrikes on Insurgent Initiated Violence in Yemen"
  }
]