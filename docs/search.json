[
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "Introduction to American Government \n            \n            \n                Pols 1101 | \n                Georgia State University\n            \n            Introduction to American Government\n            \n                 Fall 2022\n                 Summer 2022\n                 Spring 2022\n            \n        \n    \n    \n        \n            \n        \n        \n            \n                Introduction to Political Science Research \n            \n            \n                Pols 3800 | \n                Georgia State University\n            \n            This course serves as an introduction research methods, casual inference, applied statistics, and using R. During the semester we will cover how to develop research questions, theory development, and how to answer questions about political phenomena\n            \n                 Spring 2023\n                 Summer 2023\n                 Fall 2023\n            \n        \n    \n    \n        \n            \n        \n        \n            \n                R Workshops \n            \n            \n                 | \n                Georgia State University\n            \n            Research Data Services R Workshops\n            \n                 Spring 2023\n                 Fall 2022\n            \n        \n    \n\n\nNo matching items"
  },
  {
    "objectID": "teaching/index.html#section",
    "href": "teaching/index.html#section",
    "title": "Teaching",
    "section": "",
    "text": "Introduction to American Government \n            \n            \n                Pols 1101 | \n                Georgia State University\n            \n            Introduction to American Government\n            \n                 Fall 2022\n                 Summer 2022\n                 Spring 2022\n            \n        \n    \n    \n        \n            \n        \n        \n            \n                Introduction to Political Science Research \n            \n            \n                Pols 3800 | \n                Georgia State University\n            \n            This course serves as an introduction research methods, casual inference, applied statistics, and using R. During the semester we will cover how to develop research questions, theory development, and how to answer questions about political phenomena\n            \n                 Spring 2023\n                 Summer 2023\n                 Fall 2023\n            \n        \n    \n    \n        \n            \n        \n        \n            \n                R Workshops \n            \n            \n                 | \n                Georgia State University\n            \n            Research Data Services R Workshops\n            \n                 Spring 2023\n                 Fall 2022\n            \n        \n    \n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Josh Allen",
    "section": "",
    "text": "Welcome to my website! My name is Josh Allen and I am a PhD Candidate in the Department of Political Science at Georgia State University. I earned my M.A.¬†at Georgia State and am a proud Sonoma State University alum.\nMy research focuses on the impact of the Holocaust on contemporary political attitudes in Europe using causal inference tools and Large Language Models."
  },
  {
    "objectID": "blog/2022/2022-03-11-using-r-to-streamline-midsemester-reports/index.html",
    "href": "blog/2022/2022-03-11-using-r-to-streamline-midsemester-reports/index.html",
    "title": "Streamlining Midsemester Reports With The Tidyverse",
    "section": "",
    "text": "At GSU, we have Early Alert that is meant to connect students with resources if they are not doing well in the first few weeks of classes. While setting up your rules of thumb is up to you, this can quickly soak up an entire day if you are going row by row in your class of 60 or more students. To streamline the process I turned to R because it is a fairly simple data cleaning task.\nOur learning management software likes to add lots of extra stuff to the column names in our data. While most of us would come up with a more concise name like Chapter_4 our software exports the column names as assignment name, grading scheme, and the weights that are assigned. So it looks like Chapter 4.2 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;. We could use janitor::clean_names to eliminate some of the extraneous stuff, however iCollege will get grumpy at us because they do not match the names in the gradebook. We could do this in Excel, and I have done it in the past, I figured I could speed this up in R while avoiding the headaches of ensuring each and every column is where it should be.\n\nlibrary(tidyverse)\n\nset.seed(1994)\n\nstudents = 26\n\ndat = tibble(id = 1:26,\n             Students = LETTERS,\n             `Chapter 4.2 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;` = rnorm(students, mean = 90, sd = 5),\n            `Chapter 4.3 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;` = rnorm(students, mean = 90, sd = 5),\n            `Chapter 4.4  Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;` = rnorm(students, mean = 90, sd = 5),\n            `Chapter 4.5  Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;` = rnorm(students, mean = 90, sd = 5),\n            `Exam 1 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams` = rnorm(students, mean = 85, sd = 3))  \n\nIn this simple example there are only 5 columns they have annoying names sure but it is not that bad. We can probably copy and paste them and we will be fine. However, in my real data there are 13 or so chapters with a few subsections in each of them. So this can get out from under us kind of quick and copy and pasting does not make our lives any easier. We also usually get columns that do not help us. Our ID variable is not doing anything other than providing the same info in a less transparent way than the student name variable, and more minor items like surveys which do not have a lot of weight on their final grade.\nI just used rnorm for convenience; however your data is more likely to have some missing values because students did not do stuff so it looks like this.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nStudents\nChapter 4.2 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.3 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.4 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.5 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nExam 1 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams\nsurveys\n\n\n\n\n1\nA\n83.56343\n81.70468\n85.71587\n85.97115\n83.71489\n100\n\n\n2\nB\n91.44406\n86.12473\n91.53892\n91.80590\n84.62108\n100\n\n\n3\nC\n98.50185\n89.76872\n91.79794\nNA\n85.11662\n100\n\n\n4\nD\n96.99304\n88.53903\n83.42538\n92.42625\n86.08429\n100\n\n\n5\nE\n90.49552\n92.64055\n93.27846\n89.24096\n80.39882\n100\n\n\n6\nF\n83.30126\n86.91250\n90.75522\n83.04509\n78.98100\n100\n\n\n7\nG\n94.03755\n81.34807\n87.57366\n99.04721\n80.11158\n100\n\n\n8\nH\n89.47185\n89.62792\n91.37094\n96.30433\n89.58399\n100\n\n\n9\nI\n92.78107\nNA\n96.44479\n87.20809\n81.31118\n100\n\n\n10\nJ\n83.04019\n88.74052\nNA\n96.58848\n85.93511\n100\n\n\n11\nK\n91.57146\nNA\n87.94661\n93.73501\n88.43763\n100\n\n\n12\nL\n94.18791\n89.64253\n90.53395\n88.29499\n86.82630\n100\n\n\n13\nM\n95.96341\n94.94366\n91.53490\n85.17583\n82.57437\n100\n\n\n14\nN\n84.91042\n90.50202\n93.41616\n87.64364\n83.46703\n100\n\n\n15\nO\n92.76743\n81.32158\n84.05944\n103.32883\n87.00560\n100\n\n\n16\nP\n92.48953\n93.73259\n91.46155\n93.64285\n87.11260\n100\n\n\n17\nQ\n91.88890\n91.99284\n95.01500\n95.61172\n84.63614\n100\n\n\n18\nR\n87.25405\n89.89440\n91.07664\n91.93496\n89.64706\n100\n\n\n19\nS\n83.62513\n82.48662\nNA\n92.74020\n90.45662\n100\n\n\n20\nT\n87.91310\n92.87887\n95.78937\n84.74539\n86.05332\n100\n\n\n21\nU\n91.36955\n96.67913\n90.59384\n87.86449\n79.76733\n100\n\n\n22\nV\n91.30800\n87.35611\n88.29575\n90.40188\n89.97015\n100\n\n\n23\nW\nNA\n89.35205\n97.02888\nNA\n82.47724\n100\n\n\n24\nX\n94.06035\n83.28452\n97.71377\n82.26974\n90.26051\n100\n\n\n25\nY\nNA\n91.24920\n96.15636\n88.80131\n90.26133\n100\n\n\n26\nZ\n94.57923\n93.57157\n91.66163\n91.83234\n84.33456\n100\n\n\n\n\n\nSo for the purpose of the report I treat NA‚Äôs as zeros. If you are dealing with multiple columns this is a pretty easy step just use mutate(across) and using some combination of starts_with, contains, everything, or ends_with to achieve the desired goal.\n\nimputed =  dat_miss %&gt;%\n  mutate(across(c(starts_with(\"exam\"), starts_with(\"chapter\"), \n                  ), ~replace(., is.na(.), 0)))\n\nSo that should take care of the NA's but we still need to generate our indicators. The assignments that carry the most weight are exams and the chapters, so I focus the most on those. In my use case, taking the sum makes sense, but for yours the average is probably the better option. Thankfully, while the learning management software names are a bit cumbersome, they do share something in common. So we can use mutate(across) and rowwise to make our life easier. rowwise is a pretty neat little function that works perfectly for this task where you are trying to do things for each student. Then you can use case_when or ifelse to generate a logical to create your flag. This is a toy example, but we can quickly start to build it out for our specific use cases. Using a mixture of apply and select you can achieve the same thing.\n\n flag = imputed %&gt;% \n  rowwise() %&gt;% \n  mutate(flag_dplyr = round(sum(across(starts_with(\"chapter\")))))\n\n\nflag$flag_apply = imputed %&gt;% \n  select(contains(\"chapter\")) %&gt;% \n  apply(., 1, function(row){\n    round(sum(row))\n  })\n\nCool, we can use this for our basic stuff, but I tend to weigh exams by how well students did. So your highest exam score counts for more, and your lowest exam has the least amount of weight. As with lots of things in R you can do this a few ways. There is probably a more concise way of doing this with apply it is ugly but works.\n\nexams_complete = imputed %&gt;% \n  mutate(`Exam 2 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams` = rnorm(students, mean = 70, sd = 11),\n         `Exam 3 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams` = rnorm(students, mean = 75, sd = 11))\n\n\n\nexams_complete$higest_exam_apply = exams_complete %&gt;%  \n  select(contains(\"Exam\")) %&gt;% \n  apply(., 1, function(row){\n    round(max(row))\n  })\n\n\nexams_complete = exams_complete %&gt;% \n  rowwise() %&gt;% \n  mutate(hig_exam_dplyr = round(max(c_across(contains(\"Exam\")))))\n\nexams_complete$lowest_exam_apply = exams_complete %&gt;%  \n  select(contains(\"Exam\")) %&gt;% \n  apply(., 1, function(row){\n    round(min(row))\n  })\n\nexams_complete = exams_complete %&gt;% \n  rowwise() %&gt;% \n  mutate(low_exam_dplyr = round(min(c_across(contains(\"Exam\")))))\n\nSo this is easy enough because we are just changing what we are doing with our summary function, but what about the second highest exam score? In this case you are going to have to use some trickery to get what you want\n\nexams_complete$second_highest = exams_complete %&gt;% \n  select(starts_with(\"Exam\")) %&gt;% \n  apply(., 1, function(row){\n    round(sort(row, decreasing = TRUE)[2])\n  })\n\nThis is simple enough and you can just use select and filter to get the info you want. However, as we all know we have to do some grading. You can use all your favorite dplyr tricks to grade and impute grades. This is the easy part, and now you can start to expand this out to using R to automate calculating grades. One super neat assignment all Intro to Government students at Georgia State do is assigning an adult field trip of sorts that is free for them. The students go to the National Center for Civil and Human Rights and do a tour and simulation of the lunch counter sit-ins. There are a few components to this: they submit a unique code as part of the proof that they have done it. Naturally, as is the case, some students just did not do it, but that nbd just use our friend left join, but to retain all the students be sure to include keep = TRUE so each student gets graded.\n\ncodes_data = tibble(id = 1:10,\n             Students = LETTERS[1:10],\n             code = 100)\n\n\nexams_complete = mutate(exams_complete, Code = NA)\n\n\ngrades_with_codes = left_join(exams_complete, codes_data, by = \"Students\", keep = TRUE) %&gt;% \n  mutate(Code = code,\n         Code = ifelse(is.na(Code), 0, Code)) %&gt;% \n  rename(id = id.x,\n         students = Students.x) %&gt;% \n  select(-id.y, -Students.y, -code)\n\nIn the real data, I join by using last names, which works for the most part. But you may need to check to make sure that your LMS has correctly spelled your students‚Äô last name or, just as importantly, they spelled their last name correctly. Hopefully, this helps somebody. If not, at least it is tucked in a nice blog post. Be sure to check everything to make sure it is working, but if it works correctly then hopefully , you get a nice graded dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nstudents\nChapter 4.2 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.3 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.4 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nChapter 4.5 Points Grade &lt;Numeric MaxPoints:100 Weight:3.125 Category:Area9 Chapters CategoryWeight:23&gt;\nExam 1 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams\nsurveys\nExam 2 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams\nExam 3 Points Grade &lt;Numeric MaxPoints:55 Weight 10 Category: Exams\nhigest_exam_apply\nhig_exam_dplyr\nlowest_exam_apply\nlow_exam_dplyr\nsecond_highest\nCode\n\n\n\n\n1\nA\n83.56343\n81.70468\n85.71587\n85.97115\n83.71489\n100\n58.06166\n68.83867\n84\n84\n58\n58\n69\n100\n\n\n2\nB\n91.44406\n86.12473\n91.53892\n91.80590\n84.62108\n100\n69.96645\n73.51084\n85\n85\n70\n70\n74\n100\n\n\n3\nC\n98.50185\n89.76872\n91.79794\n0.00000\n85.11662\n100\n66.30306\n74.42536\n85\n85\n66\n66\n74\n100\n\n\n4\nD\n96.99304\n88.53903\n83.42538\n92.42625\n86.08429\n100\n65.79288\n85.94456\n86\n86\n66\n66\n86\n100\n\n\n5\nE\n90.49552\n92.64055\n93.27846\n89.24096\n80.39882\n100\n88.72094\n64.87935\n89\n89\n65\n65\n80\n100\n\n\n6\nF\n83.30126\n86.91250\n90.75522\n83.04509\n78.98100\n100\n80.41976\n73.06732\n80\n80\n73\n73\n79\n100\n\n\n7\nG\n94.03755\n81.34807\n87.57366\n99.04721\n80.11158\n100\n86.56743\n66.79291\n87\n87\n67\n67\n80\n100\n\n\n8\nH\n89.47185\n89.62792\n91.37094\n96.30433\n89.58399\n100\n87.48637\n74.13581\n90\n90\n74\n74\n87\n100\n\n\n9\nI\n92.78107\n0.00000\n96.44479\n87.20809\n81.31118\n100\n69.63665\n68.36826\n81\n81\n68\n68\n70\n100\n\n\n10\nJ\n83.04019\n88.74052\n0.00000\n96.58848\n85.93511\n100\n69.71254\n71.65925\n86\n86\n70\n70\n72\n100\n\n\n11\nK\n91.57146\n0.00000\n87.94661\n93.73501\n88.43763\n100\n71.99278\n78.33438\n88\n88\n72\n72\n78\n0\n\n\n12\nL\n94.18791\n89.64253\n90.53395\n88.29499\n86.82630\n100\n66.30946\n99.16532\n99\n99\n66\n66\n87\n0\n\n\n13\nM\n95.96341\n94.94366\n91.53490\n85.17583\n82.57437\n100\n71.14509\n62.94670\n83\n83\n63\n63\n71\n0\n\n\n14\nN\n84.91042\n90.50202\n93.41616\n87.64364\n83.46703\n100\n66.72115\n67.17081\n83\n83\n67\n67\n67\n0\n\n\n15\nO\n92.76743\n81.32158\n84.05944\n103.32883\n87.00560\n100\n88.98898\n66.12589\n89\n89\n66\n66\n87\n0\n\n\n16\nP\n92.48953\n93.73259\n91.46155\n93.64285\n87.11260\n100\n63.42139\n77.70564\n87\n87\n63\n63\n78\n0\n\n\n17\nQ\n91.88890\n91.99284\n95.01500\n95.61172\n84.63614\n100\n70.82987\n53.49421\n85\n85\n53\n53\n71\n0\n\n\n18\nR\n87.25405\n89.89440\n91.07664\n91.93496\n89.64706\n100\n69.95649\n86.20525\n90\n90\n70\n70\n86\n0\n\n\n19\nS\n83.62513\n82.48662\n0.00000\n92.74020\n90.45662\n100\n78.62938\n64.34364\n90\n90\n64\n64\n79\n0\n\n\n20\nT\n87.91310\n92.87887\n95.78937\n84.74539\n86.05332\n100\n84.55215\n80.42847\n86\n86\n80\n80\n85\n0\n\n\n21\nU\n91.36955\n96.67913\n90.59384\n87.86449\n79.76733\n100\n75.08180\n64.40788\n80\n80\n64\n64\n75\n0\n\n\n22\nV\n91.30800\n87.35611\n88.29575\n90.40188\n89.97015\n100\n68.53960\n79.79600\n90\n90\n69\n69\n80\n0\n\n\n23\nW\n0.00000\n89.35205\n97.02888\n0.00000\n82.47724\n100\n88.95738\n70.28810\n89\n89\n70\n70\n82\n0\n\n\n24\nX\n94.06035\n83.28452\n97.71377\n82.26974\n90.26051\n100\n63.12942\n78.58372\n90\n90\n63\n63\n79\n0\n\n\n25\nY\n0.00000\n91.24920\n96.15636\n88.80131\n90.26133\n100\n88.82365\n86.03999\n90\n90\n86\n86\n89\n0\n\n\n26\nZ\n94.57923\n93.57157\n91.66163\n91.83234\n84.33456\n100\n65.54887\n82.58063\n84\n84\n66\n66\n83\n0"
  },
  {
    "objectID": "CV/index.html",
    "href": "CV/index.html",
    "title": "Curriculum vitae",
    "section": "",
    "text": "Download current CV"
  },
  {
    "objectID": "blog/2022/2021-11-25-what-to-do-when-you-break-r/index.html",
    "href": "blog/2022/2021-11-25-what-to-do-when-you-break-r/index.html",
    "title": "What to do when you break R",
    "section": "",
    "text": "Hi all, when I first stated using R I tried making my website using blogdown. While Alison Hill PhD provides an excellent intro to launching your website. However, I am truly special and managed to mess this process up. For a few days whenever I did anything more computationally intensive than\n\nrm(list=ls())\nlibrary(tidyverse)\n\nI would get a nasty error message saying ‚Äúc stack usage is too close to the limit‚Äù and I could not do anything. This would have been fine but at the time I was still taking classes and need to have R working to complete the problem sets.\nSo what did I do to get in the c stack death spiral and how did it end up being fixed? For the former you should not skip steps in Dr.¬†Hill‚Äôs post. For the later well to spare you the long arduous process here is what we tried.\n\nme consulting stackoverflow & realizing I really f****k up\nrestarting my computer\nuninstalling & reinstalling blogdown\nuninstalling & reinstalling R\nuninstalling & reinstalling pandocs\n\nAfter hours of trouble shooting #rstats twitter came to the rescue when this distress signal was sent out.\n\n\n#rstats world! I have a student who is getting a \"c stack usage is too close to the limit\" every time when using knitr (even with an R-chunk-free Rmd file) & getting same error when trying to install anything with devtools or remotes. We've un/reinstalled R but no luck. Ideas?\n\n‚Äî Andrew Heiss (üêò @andrew@fediscience.org) (@andrewheiss) February 7, 2021\n\n\nSo here is what ended up working. To start you will need a super simple Rmd file to test with in a local directory. I suggest starting a new Rmd file with nothing in it other than the default YAML header and ‚Äútest‚Äù in the main body or ‚ÄúLorem Ipsum‚Äù if you feel fancy.\nIn the terminal run the following code\n\ncd ~ \n\nls -la\n\nThen look for files starting with a period. Okay if you messed up in the initial blogdown setup you are looking for the ‚Äú.Rprofile‚Äù that is causing you the problem. What ended up happening is that you broke all of R by including a recursive function. So restarting and uninstalling R will not kill the function it will be there\n\n\n\nWhat you are going to do is open a terminal in Rstudio or otherwise than start running this.\n\ncat.Rprofile\n\nthan run\n\ncat.zshrc\n\nthan after that run\nmv. Rprofile .Rprofile-original\nThen close out Rstudio and reopen Rstudio. Then try to knit your super simple Rmd file and install a package and doing something fun! Than knit that file.\nHopefully the dreaded C stack usage error is gone. If it is than celebrate\n\n\n\nbecause you can use R again!!!!"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "March 11, 2022\n        \n        \n            Streamlining Midsemester Reports With The Tidyverse\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    tidyverse\n                \n                \n            \n            \n\n            Working with LMS data using the tidyverse\n        \n        \n    \n    \n    \n                  \n            January 1, 2022\n        \n        \n            What to do when you break R\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    zsh\n                \n                \n            \n            \n\n            What happens when you keep getting c stack usage errors \n        \n        \n    \n    \n\n\nNo matching items\n\n\n\n\n    \n    \n                  \n            \n        \n        \n            Tidyverse to SQL\n\n            \n\n            \n        \n        \n    \n    \n    \n                  \n            July 3, 2024\n        \n        \n            Translating What I know in the tidyverse to polars:\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    tidyverse\n                \n                \n                \n                    python\n                \n                \n                \n                    polars\n                \n                \n            \n            \n\n            This is me learning the snake language\n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section",
    "href": "blog/index.html#section",
    "title": "Blog",
    "section": "",
    "text": "March 11, 2022\n        \n        \n            Streamlining Midsemester Reports With The Tidyverse\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    tidyverse\n                \n                \n            \n            \n\n            Working with LMS data using the tidyverse\n        \n        \n    \n    \n    \n                  \n            January 1, 2022\n        \n        \n            What to do when you break R\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    zsh\n                \n                \n            \n            \n\n            What happens when you keep getting c stack usage errors \n        \n        \n    \n    \n\n\nNo matching items\n\n\n\n\n    \n    \n                  \n            \n        \n        \n            Tidyverse to SQL\n\n            \n\n            \n        \n        \n    \n    \n    \n                  \n            July 3, 2024\n        \n        \n            Translating What I know in the tidyverse to polars:\n\n            \n            \n                \n                \n                    r\n                \n                \n                \n                    tidyverse\n                \n                \n                \n                    python\n                \n                \n                \n                    polars\n                \n                \n            \n            \n\n            This is me learning the snake language\n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research and Projects",
    "section": "",
    "text": "Allen Joshua. ‚ÄúThe Use of The Holocaust in Online Discourse and in Media: A Computational Approach‚Äù\nAllen Joshua. ‚ÄúCollective Memory and Contemporary Political Behavior: Evidence from France‚Äù"
  },
  {
    "objectID": "research/index.html#working-papers",
    "href": "research/index.html#working-papers",
    "title": "Research and Projects",
    "section": "",
    "text": "Allen Joshua. ‚ÄúThe Use of The Holocaust in Online Discourse and in Media: A Computational Approach‚Äù\nAllen Joshua. ‚ÄúCollective Memory and Contemporary Political Behavior: Evidence from France‚Äù"
  },
  {
    "objectID": "research/index.html#dormant-papers",
    "href": "research/index.html#dormant-papers",
    "title": "Research and Projects",
    "section": "Dormant Papers",
    "text": "Dormant Papers\n\nAllen Joshua. Testing The Effects of U.S. Airstrikes on Insurgent Initiated Violence in Yemen"
  },
  {
    "objectID": "blog/2023/2023-webscraping/index.html",
    "href": "blog/2023/2023-webscraping/index.html",
    "title": "An Introduction to Webscraping",
    "section": "",
    "text": "Introduction\nSince may I have had to start collecting data for my dissertation which is exciting and a little scary. I was also hired on to an NSF grant to do some data collection. Based on the data I needed for my dissertation and the data collection for the grant all this entailed a ton of web scraping. Which I had largely avoided before this and felt like out of my skill set.\nAfter like six months of having to do this more or less every week I decided to write this post to demystify the process a bit and for me to refer back to from time to time. For the most part webscraping is more like a solving a mystery rather than building a skyscrapper."
  },
  {
    "objectID": "blog/2024/index.html",
    "href": "blog/2024/index.html",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "",
    "text": "I suppose at some point it is good to become more well versed in lots of tools. I have been python curious for about a year or so and I think it is important to use the tool best suited for the task. Also sometimes it is important to get out of your comfort zone. I am definitely somebody who is very comfortable in R and the tidyverse and use it for a lot of stuff. I have heard lots of ravings about polars specifically about its speed and similarities in intuition with the tidyverse. So I thought I would have a collection of code for myself and the people of the internet to reference.\nJust a disclaimer. This is really just me working through the similarities and is going to be based on the tidyintelligence‚Äôs blog post, Robert Mitchell‚Äôs blog post, and Emily Rieder‚Äôs blog post. In all honesty, this is just for me to smash them together to have a one-stop shop for myself. If you found this post over these resources I highly recommend you check out these resources."
  },
  {
    "objectID": "blog/2024/index.html#the-basics",
    "href": "blog/2024/index.html#the-basics",
    "title": "Translating What I know in the tidyverse to python",
    "section": "The Basics",
    "text": "The Basics\nAs always we should load in the respected packages we are going to use. as\n:::{layout = ‚Äú[[1,1]]‚Äù} ## R\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.2          ‚úî readr     2.1.4     \n‚úî forcats   1.0.0          ‚úî stringr   1.5.0     \n‚úî ggplot2   3.4.2.9000     ‚úî tibble    3.2.1     \n‚úî lubridate 1.9.2          ‚úî tidyr     1.3.0     \n‚úî purrr     1.0.1          \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npenguins = read_csv(\"penguins.csv\")\n\nRows: 344 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "blog/2024/index.html#python",
    "href": "blog/2024/index.html#python",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\nimport polars as pl\nimport polars.selectors as cs\n\npenguins = pl.read_csv(\"penguins.csv\")\n\npl.Config(tbl_rows = 10)\n\n&lt;polars.config.Config object at 0x12754c2f0&gt;"
  },
  {
    "objectID": "blog/2024/index.html#r",
    "href": "blog/2024/index.html#r",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\nsuppressPackageStartupMessages(library(tidyverse))\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "blog/2024/index.html#r-1",
    "href": "blog/2024/index.html#r-1",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\nhead(penguins) |&gt;\nknitr::kable(booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007"
  },
  {
    "objectID": "blog/2024/index.html#python-1",
    "href": "blog/2024/index.html#python-1",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.head()\n\n\nshape: (5, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\ni64\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n\"39.1\"\n\"18.7\"\n\"181\"\n\"3750\"\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n\"39.5\"\n\"17.4\"\n\"186\"\n\"3800\"\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n\"40.3\"\n\"18\"\n\"195\"\n\"3250\"\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n\"NA\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n\"36.7\"\n\"19.3\"\n\"193\"\n\"3450\"\n\"female\"\n2007"
  },
  {
    "objectID": "blog/2024/index.html#r-2",
    "href": "blog/2024/index.html#r-2",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶"
  },
  {
    "objectID": "blog/2024/index.html#python-2",
    "href": "blog/2024/index.html#python-2",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.glimpse()\n\nRows: 344\nColumns: 8\n$ species           &lt;str&gt; 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie'\n$ island            &lt;str&gt; 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen'\n$ bill_length_mm    &lt;str&gt; '39.1', '39.5', '40.3', 'NA', '36.7', '39.3', '38.9', '39.2', '34.1', '42'\n$ bill_depth_mm     &lt;str&gt; '18.7', '17.4', '18', 'NA', '19.3', '20.6', '17.8', '19.6', '18.1', '20.2'\n$ flipper_length_mm &lt;str&gt; '181', '186', '195', 'NA', '193', '190', '181', '195', '193', '190'\n$ body_mass_g       &lt;str&gt; '3750', '3800', '3250', 'NA', '3450', '3650', '3625', '4675', '3475', '4250'\n$ sex               &lt;str&gt; 'male', 'female', 'female', 'NA', 'female', 'male', 'female', 'male', 'NA', 'NA'\n$ year              &lt;i64&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007"
  },
  {
    "objectID": "blog/2024/index.html#r-3",
    "href": "blog/2024/index.html#r-3",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nfilter(species == \"Adelie\", body_mass_g &gt; mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 25 √ó 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.2          19.6               195        4675\n 2 Adelie  Torgersen           42            20.2               190        4250\n 3 Adelie  Torgersen           34.6          21.1               198        4400\n 4 Adelie  Torgersen           42.5          20.7               197        4500\n 5 Adelie  Dream               39.8          19.1               184        4650\n 6 Adelie  Dream               44.1          19.7               196        4400\n 7 Adelie  Dream               39.6          18.8               190        4600\n 8 Adelie  Biscoe              40.1          18.9               188        4300\n 9 Adelie  Biscoe              41.3          21.1               195        4400\n10 Adelie  Torgersen           41.8          19.4               198        4450\n# ‚Ñπ 15 more rows\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/index.html#python-3",
    "href": "blog/2024/index.html#python-3",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.filter(pl.col(\"species\") == \"Adelie\" &\n                pl.col(\"body_mass_g\" &gt; mean(pl.col(\"body_mass_g\"))))\n\nname 'mean' is not defined"
  },
  {
    "objectID": "blog/2024/index.html#r-4",
    "href": "blog/2024/index.html#r-4",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nfilter(species == \"Adelie\", body_mass_g &gt; mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 25 √ó 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.2          19.6               195        4675\n 2 Adelie  Torgersen           42            20.2               190        4250\n 3 Adelie  Torgersen           34.6          21.1               198        4400\n 4 Adelie  Torgersen           42.5          20.7               197        4500\n 5 Adelie  Dream               39.8          19.1               184        4650\n 6 Adelie  Dream               44.1          19.7               196        4400\n 7 Adelie  Dream               39.6          18.8               190        4600\n 8 Adelie  Biscoe              40.1          18.9               188        4300\n 9 Adelie  Biscoe              41.3          21.1               195        4400\n10 Adelie  Torgersen           41.8          19.4               198        4450\n# ‚Ñπ 15 more rows\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/index.html#python-4",
    "href": "blog/2024/index.html#python-4",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.filter((pl.col(\"species\") == \"Adelie\") &\n                (pl.col(\"body_mass_g\") &gt; pl.col(\"body_mass_g\").mean()))\n\n\nshape: (0, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\ni64"
  },
  {
    "objectID": "blog/2024/index.html#r-5",
    "href": "blog/2024/index.html#r-5",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nfilter(species %in% c(\"Gentoo\", \"Chinstrap\"),\n       bill_depth_mm &gt; median(bill_depth_mm, na.rm = TRUE))\n\n# A tibble: 52 √ó 8\n   species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Chinstrap Dream            46.5          17.9               192        3500\n 2 Chinstrap Dream            50            19.5               196        3900\n 3 Chinstrap Dream            51.3          19.2               193        3650\n 4 Chinstrap Dream            45.4          18.7               188        3525\n 5 Chinstrap Dream            52.7          19.8               197        3725\n 6 Chinstrap Dream            45.2          17.8               198        3950\n 7 Chinstrap Dream            46.1          18.2               178        3250\n 8 Chinstrap Dream            51.3          18.2               197        3750\n 9 Chinstrap Dream            46            18.9               195        4150\n10 Chinstrap Dream            51.3          19.9               198        3700\n# ‚Ñπ 42 more rows\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/index.html#python-5",
    "href": "blog/2024/index.html#python-5",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.filter((pl.col(\"species\").is_in([\"Chinstrap\", \"Gentoo\"])) & \n                (pl.col(\"bill_depth_mm\") &gt; pl.col(\"bill_depth_mm\").median()))\n\n`median` operation not supported for dtype `str`"
  },
  {
    "objectID": "blog/2024/index.html#r-6",
    "href": "blog/2024/index.html#r-6",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nselect(island)\n\n# A tibble: 344 √ó 1\n   island   \n   &lt;fct&gt;    \n 1 Torgersen\n 2 Torgersen\n 3 Torgersen\n 4 Torgersen\n 5 Torgersen\n 6 Torgersen\n 7 Torgersen\n 8 Torgersen\n 9 Torgersen\n10 Torgersen\n# ‚Ñπ 334 more rows"
  },
  {
    "objectID": "blog/2024/index.html#python-6",
    "href": "blog/2024/index.html#python-6",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.select((pl.col(\"island\")))\n\n\nshape: (344, 1)\n\n\n\nisland\n\n\nstr\n\n\n\n\n\"Torgersen\"\n\n\n\"Torgersen\"\n\n\n\"Torgersen\"\n\n\n\"Torgersen\"\n\n\n\"Torgersen\"\n\n\n‚Ä¶\n\n\n\"Dream\"\n\n\n\"Dream\"\n\n\n\"Dream\"\n\n\n\"Dream\"\n\n\n\"Dream\""
  },
  {
    "objectID": "blog/2024/index.html#r-7",
    "href": "blog/2024/index.html#r-7",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nselect(species, island)\n\n# A tibble: 344 √ó 2\n   species island   \n   &lt;fct&gt;   &lt;fct&gt;    \n 1 Adelie  Torgersen\n 2 Adelie  Torgersen\n 3 Adelie  Torgersen\n 4 Adelie  Torgersen\n 5 Adelie  Torgersen\n 6 Adelie  Torgersen\n 7 Adelie  Torgersen\n 8 Adelie  Torgersen\n 9 Adelie  Torgersen\n10 Adelie  Torgersen\n# ‚Ñπ 334 more rows"
  },
  {
    "objectID": "blog/2024/index.html#python-7",
    "href": "blog/2024/index.html#python-7",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.select((pl.col(\"species\", \"island\")))\n\n\nshape: (344, 2)\n\n\n\nspecies\nisland\n\n\nstr\nstr\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n\"Adelie\"\n\"Torgersen\"\n\n\n‚Ä¶\n‚Ä¶\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\"\n\n\n\"Chinstrap\"\n\"Dream\""
  },
  {
    "objectID": "blog/2024/index.html#r-8",
    "href": "blog/2024/index.html#r-8",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nselect(starts_with(\"bill\"))\n\n# A tibble: 344 √ó 2\n   bill_length_mm bill_depth_mm\n            &lt;dbl&gt;         &lt;dbl&gt;\n 1           39.1          18.7\n 2           39.5          17.4\n 3           40.3          18  \n 4           NA            NA  \n 5           36.7          19.3\n 6           39.3          20.6\n 7           38.9          17.8\n 8           39.2          19.6\n 9           34.1          18.1\n10           42            20.2\n# ‚Ñπ 334 more rows"
  },
  {
    "objectID": "blog/2024/index.html#python-8",
    "href": "blog/2024/index.html#python-8",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.select(cs.starts_with(\"bill\"))\n\n\nshape: (344, 2)\n\n\n\nbill_length_mm\nbill_depth_mm\n\n\nstr\nstr\n\n\n\n\n\"39.1\"\n\"18.7\"\n\n\n\"39.5\"\n\"17.4\"\n\n\n\"40.3\"\n\"18\"\n\n\n\"NA\"\n\"NA\"\n\n\n\"36.7\"\n\"19.3\"\n\n\n‚Ä¶\n‚Ä¶\n\n\n\"55.8\"\n\"19.8\"\n\n\n\"43.5\"\n\"18.1\"\n\n\n\"49.6\"\n\"18.2\"\n\n\n\"50.8\"\n\"19\"\n\n\n\"50.2\"\n\"18.7\""
  },
  {
    "objectID": "blog/2024/index.html#r-9",
    "href": "blog/2024/index.html#r-9",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nslice(90:100)\n\n# A tibble: 11 √ó 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Dream            38.9          18.8               190        3600\n 2 Adelie  Dream            35.7          18                 202        3550\n 3 Adelie  Dream            41.1          18.1               205        4300\n 4 Adelie  Dream            34            17.1               185        3400\n 5 Adelie  Dream            39.6          18.1               186        4450\n 6 Adelie  Dream            36.2          17.3               187        3300\n 7 Adelie  Dream            40.8          18.9               208        4300\n 8 Adelie  Dream            38.1          18.6               190        3700\n 9 Adelie  Dream            40.3          18.5               196        4350\n10 Adelie  Dream            33.1          16.1               178        2900\n11 Adelie  Dream            43.2          18.5               192        4100\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/index.html#python-9",
    "href": "blog/2024/index.html#python-9",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.slice(89:10)\n\ninvalid syntax (&lt;string&gt;, line 1)"
  },
  {
    "objectID": "blog/2024/index.html#r-10",
    "href": "blog/2024/index.html#r-10",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nslice(90:100)\n\n# A tibble: 11 √ó 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Dream            38.9          18.8               190        3600\n 2 Adelie  Dream            35.7          18                 202        3550\n 3 Adelie  Dream            41.1          18.1               205        4300\n 4 Adelie  Dream            34            17.1               185        3400\n 5 Adelie  Dream            39.6          18.1               186        4450\n 6 Adelie  Dream            36.2          17.3               187        3300\n 7 Adelie  Dream            40.8          18.9               208        4300\n 8 Adelie  Dream            38.1          18.6               190        3700\n 9 Adelie  Dream            40.3          18.5               196        4350\n10 Adelie  Dream            33.1          16.1               178        2900\n11 Adelie  Dream            43.2          18.5               192        4100\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/index.html#python-10",
    "href": "blog/2024/index.html#python-10",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.slice(89,10)\n\n\nshape: (10, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\ni64\n\n\n\n\n\"Adelie\"\n\"Dream\"\n\"38.9\"\n\"18.8\"\n\"190\"\n\"3600\"\n\"female\"\n2008\n\n\n\"Adelie\"\n\"Dream\"\n\"35.7\"\n\"18\"\n\"202\"\n\"3550\"\n\"female\"\n2008\n\n\n\"Adelie\"\n\"Dream\"\n\"41.1\"\n\"18.1\"\n\"205\"\n\"4300\"\n\"male\"\n2008\n\n\n\"Adelie\"\n\"Dream\"\n\"34\"\n\"17.1\"\n\"185\"\n\"3400\"\n\"female\"\n2008\n\n\n\"Adelie\"\n\"Dream\"\n\"39.6\"\n\"18.1\"\n\"186\"\n\"4450\"\n\"male\"\n2008\n\n\n\"Adelie\"\n\"Dream\"\n\"36.2\"\n\"17.3\"\n\"187\"\n\"3300\"\n\"female\"\n2008\n\n\n\"Adelie\"\n\"Dream\"\n\"40.8\"\n\"18.9\"\n\"208\"\n\"4300\"\n\"male\"\n2008\n\n\n\"Adelie\"\n\"Dream\"\n\"38.1\"\n\"18.6\"\n\"190\"\n\"3700\"\n\"female\"\n2008\n\n\n\"Adelie\"\n\"Dream\"\n\"40.3\"\n\"18.5\"\n\"196\"\n\"4350\"\n\"male\"\n2008\n\n\n\"Adelie\"\n\"Dream\"\n\"33.1\"\n\"16.1\"\n\"178\"\n\"2900\"\n\"female\"\n2008"
  },
  {
    "objectID": "blog/2024/index.html#r-11",
    "href": "blog/2024/index.html#r-11",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\nset.seed(1994)\npenguins |&gt;\nslice_sample(n = 10)\n\n# A tibble: 10 √ó 8\n   species   island   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;     &lt;fct&gt;             &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Chinstrap Dream              50.2          18.7               198        3775\n 2 Adelie    Biscoe             39.7          18.9               184        3550\n 3 Chinstrap Dream              45.4          18.7               188        3525\n 4 Gentoo    Biscoe             46.2          14.1               217        4375\n 5 Gentoo    Biscoe             50            16.3               230        5700\n 6 Chinstrap Dream              49.8          17.3               198        3675\n 7 Adelie    Biscoe             35            17.9               192        3725\n 8 Adelie    Biscoe             40.6          18.6               183        3550\n 9 Adelie    Torgers‚Ä¶           40.6          19                 199        4000\n10 Chinstrap Dream              46.5          17.9               192        3500\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/index.html#python-11",
    "href": "blog/2024/index.html#python-11",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.sample(n = 10, seed = 1994)\n\n\nshape: (10, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\ni64\n\n\n\n\n\"Adelie\"\n\"Biscoe\"\n\"42.7\"\n\"18.3\"\n\"196\"\n\"4075\"\n\"male\"\n2009\n\n\n\"Gentoo\"\n\"Biscoe\"\n\"50\"\n\"15.2\"\n\"218\"\n\"5700\"\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Biscoe\"\n\"35\"\n\"17.9\"\n\"192\"\n\"3725\"\n\"female\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n\"36.6\"\n\"17.8\"\n\"185\"\n\"3700\"\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Dream\"\n\"36\"\n\"18.5\"\n\"186\"\n\"3100\"\n\"female\"\n2007\n\n\n\"Gentoo\"\n\"Biscoe\"\n\"48.4\"\n\"14.4\"\n\"203\"\n\"4625\"\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n\"50.2\"\n\"18.7\"\n\"198\"\n\"3775\"\n\"female\"\n2009\n\n\n\"Gentoo\"\n\"Biscoe\"\n\"45.2\"\n\"16.4\"\n\"223\"\n\"5950\"\n\"male\"\n2008\n\n\n\"Gentoo\"\n\"Biscoe\"\n\"49.8\"\n\"16.8\"\n\"230\"\n\"5700\"\n\"male\"\n2008\n\n\n\"Adelie\"\n\"Dream\"\n\"38.8\"\n\"20\"\n\"190\"\n\"3950\"\n\"male\"\n2007"
  },
  {
    "objectID": "blog/2024/index.html#r-12",
    "href": "blog/2024/index.html#r-12",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nrename(BillLengthMm = bill_length_mm,\n       BillDepthMm = bill_depth_mm)\n\n# A tibble: 344 √ó 8\n   species island   BillLengthMm BillDepthMm flipper_length_mm body_mass_g sex  \n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;       &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;fct&gt;\n 1 Adelie  Torgers‚Ä¶         39.1        18.7               181        3750 male \n 2 Adelie  Torgers‚Ä¶         39.5        17.4               186        3800 fema‚Ä¶\n 3 Adelie  Torgers‚Ä¶         40.3        18                 195        3250 fema‚Ä¶\n 4 Adelie  Torgers‚Ä¶         NA          NA                  NA          NA &lt;NA&gt; \n 5 Adelie  Torgers‚Ä¶         36.7        19.3               193        3450 fema‚Ä¶\n 6 Adelie  Torgers‚Ä¶         39.3        20.6               190        3650 male \n 7 Adelie  Torgers‚Ä¶         38.9        17.8               181        3625 fema‚Ä¶\n 8 Adelie  Torgers‚Ä¶         39.2        19.6               195        4675 male \n 9 Adelie  Torgers‚Ä¶         34.1        18.1               193        3475 &lt;NA&gt; \n10 Adelie  Torgers‚Ä¶         42          20.2               190        4250 &lt;NA&gt; \n# ‚Ñπ 334 more rows\n# ‚Ñπ 1 more variable: year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/index.html#python-12",
    "href": "blog/2024/index.html#python-12",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins = penguins.rename({\"bill_length_mm\": \"BillLengthMm\",\n                \"bill_depth_mm\" : \"BillDepthMm\"})"
  },
  {
    "objectID": "blog/2024/index.html#r-13",
    "href": "blog/2024/index.html#r-13",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\njanitor::clean_names(case = \"lower_camel\")\n\n# A tibble: 344 √ó 8\n   species island billLengthMm billDepthMm flipperLengthMm bodyMassG sex    year\n   &lt;fct&gt;   &lt;fct&gt;         &lt;dbl&gt;       &lt;dbl&gt;           &lt;int&gt;     &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n 1 Adelie  Torge‚Ä¶         39.1        18.7             181      3750 male   2007\n 2 Adelie  Torge‚Ä¶         39.5        17.4             186      3800 fema‚Ä¶  2007\n 3 Adelie  Torge‚Ä¶         40.3        18               195      3250 fema‚Ä¶  2007\n 4 Adelie  Torge‚Ä¶         NA          NA                NA        NA &lt;NA&gt;   2007\n 5 Adelie  Torge‚Ä¶         36.7        19.3             193      3450 fema‚Ä¶  2007\n 6 Adelie  Torge‚Ä¶         39.3        20.6             190      3650 male   2007\n 7 Adelie  Torge‚Ä¶         38.9        17.8             181      3625 fema‚Ä¶  2007\n 8 Adelie  Torge‚Ä¶         39.2        19.6             195      4675 male   2007\n 9 Adelie  Torge‚Ä¶         34.1        18.1             193      3475 &lt;NA&gt;   2007\n10 Adelie  Torge‚Ä¶         42          20.2             190      4250 &lt;NA&gt;   2007\n# ‚Ñπ 334 more rows"
  },
  {
    "objectID": "blog/2024/index.html#python-13",
    "href": "blog/2024/index.html#python-13",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\nfrom janitor import clean_names\n\npenguins.clean_names()\n\n'DataFrame' object has no attribute 'clean_names'"
  },
  {
    "objectID": "blog/2024/index.html#r-14",
    "href": "blog/2024/index.html#r-14",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\njanitor::clean_names(case = \"small_camel\")\n\n# A tibble: 344 √ó 8\n   species island billLengthMm billDepthMm flipperLengthMm bodyMassG sex    year\n   &lt;fct&gt;   &lt;fct&gt;         &lt;dbl&gt;       &lt;dbl&gt;           &lt;int&gt;     &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n 1 Adelie  Torge‚Ä¶         39.1        18.7             181      3750 male   2007\n 2 Adelie  Torge‚Ä¶         39.5        17.4             186      3800 fema‚Ä¶  2007\n 3 Adelie  Torge‚Ä¶         40.3        18               195      3250 fema‚Ä¶  2007\n 4 Adelie  Torge‚Ä¶         NA          NA                NA        NA &lt;NA&gt;   2007\n 5 Adelie  Torge‚Ä¶         36.7        19.3             193      3450 fema‚Ä¶  2007\n 6 Adelie  Torge‚Ä¶         39.3        20.6             190      3650 male   2007\n 7 Adelie  Torge‚Ä¶         38.9        17.8             181      3625 fema‚Ä¶  2007\n 8 Adelie  Torge‚Ä¶         39.2        19.6             195      4675 male   2007\n 9 Adelie  Torge‚Ä¶         34.1        18.1             193      3475 &lt;NA&gt;   2007\n10 Adelie  Torge‚Ä¶         42          20.2             190      4250 &lt;NA&gt;   2007\n# ‚Ñπ 334 more rows"
  },
  {
    "objectID": "blog/2024/index.html#python-14",
    "href": "blog/2024/index.html#python-14",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\nclean_names(penguins)\n\n'list' object has no attribute 'dtype'"
  },
  {
    "objectID": "blog/2024/index.html#make-a-column-into-a-vector",
    "href": "blog/2024/index.html#make-a-column-into-a-vector",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Make a column into a vector",
    "text": "Make a column into a vector\nIn R there are like a ton of different ways to do this\n\nvec1 = penguins$bill_depth_mm\n\nvec2 = penguins |&gt;\npluck(\"bill_depth_mm\")\n\nvec3 = penguins |&gt;\nselect(bill_depth_mm) |&gt;\ndeframe()\n\nIn polars the equivalent of this\n\nvec1 = penguins[\"bill_depth_mm\"]\n\nprint(vec1[0,1])\n\nshape: (2,)\nSeries: 'bill_depth_mm' [f64]\n[\n    18.7\n    17.4\n]\n\n\n\nRPython\n\n\n\nvec1[1:3]\n\n[1] 18.7 17.4 18.0\n\n\n\n\n\nimport numpy as np \n\nprint(vec1[0:2])\n\nshape: (2,)\nSeries: 'bill_depth_mm' [f64]\n[\n    18.7\n    17.4\n]"
  },
  {
    "objectID": "blog/2024/index.html#r-15",
    "href": "blog/2024/index.html#r-15",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\nvec1[1:3]\n\n[1] 18.7 17.4 18.0"
  },
  {
    "objectID": "blog/2024/index.html#python-15",
    "href": "blog/2024/index.html#python-15",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\nimport numpy as np \n\nprint(vec1[0:2])\n\nshape: (2,)\nSeries: 'bill_depth_mm' [str]\n[\n    \"18.7\"\n    \"17.4\"\n]"
  },
  {
    "objectID": "blog/2024/index.html#r-16",
    "href": "blog/2024/index.html#r-16",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nmutate(sqr_bill_length = bill_length_mm^2) |&gt;\nselect(sqr_bill_length) |&gt;\nhead()\n\n# A tibble: 6 √ó 1\n  sqr_bill_length\n            &lt;dbl&gt;\n1           1529.\n2           1560.\n3           1624.\n4             NA \n5           1347.\n6           1544."
  },
  {
    "objectID": "blog/2024/index.html#python-16",
    "href": "blog/2024/index.html#python-16",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.mutate({pl.col(\"bill_length_mm\")^2: \"sqr_bill_length\"}).select(pl.col(\"sqr_bill_length\"))\n\n'DataFrame' object has no attribute 'mutate'"
  },
  {
    "objectID": "blog/2024/index.html#r-17",
    "href": "blog/2024/index.html#r-17",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nmutate(sqr_bill = bill_length_mm^2,\n       og_bill = sqrt(sqr_bill)) |&gt;\n       select(sqr_bill, og_bill, bill_length_mm) |&gt;\n       head(n = 5)\n\n# A tibble: 5 √ó 3\n  sqr_bill og_bill bill_length_mm\n     &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;\n1    1529.    39.1           39.1\n2    1560.    39.5           39.5\n3    1624.    40.3           40.3\n4      NA     NA             NA  \n5    1347.    36.7           36.7"
  },
  {
    "objectID": "blog/2024/index.html#python-17",
    "href": "blog/2024/index.html#python-17",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.with_columns(sqr_bill = pl.col(\"bill_length_mm\")**2).with_columns(og_bill = pl.col(\"sqr_bill\").sqrt()).select(pl.col(\"sqr_bill\", \"og_bill\", \"bill_length_mm\")).head(5)\n\n\nshape: (5, 3)\n\n\n\nsqr_bill\nog_bill\nbill_length_mm\n\n\nf64\nf64\nstr\n\n\n\n\n1528.81\n39.1\n\"39.1\"\n\n\n1560.25\n39.5\n\"39.5\"\n\n\n1624.09\n40.3\n\"40.3\"\n\n\nnull\nnull\n\"NA\"\n\n\n1346.89\n36.7\n\"36.7\""
  },
  {
    "objectID": "blog/2024/index.html#r-18",
    "href": "blog/2024/index.html#r-18",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\nmutate(female = ifelse(sex == \"female\", TRUE, FALSE)) |&gt;\nselect(sex, female) |&gt;\nhead(5)\n\n# A tibble: 5 √ó 2\n  sex    female\n  &lt;fct&gt;  &lt;lgl&gt; \n1 male   FALSE \n2 female TRUE  \n3 female TRUE  \n4 &lt;NA&gt;   NA    \n5 female TRUE"
  },
  {
    "objectID": "blog/2024/index.html#python-18",
    "href": "blog/2024/index.html#python-18",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.with_columns(female = pl.when(pl.col(\"sex\") == \"female\").then(True).otherwise(False)).select([\"sex\", \"female\"]).head(5)\n\n\nshape: (5, 2)\n\n\n\nsex\nfemale\n\n\nstr\nbool\n\n\n\n\n\"male\"\nfalse\n\n\n\"female\"\ntrue\n\n\n\"female\"\ntrue\n\n\n\"NA\"\nfalse\n\n\n\"female\"\ntrue"
  },
  {
    "objectID": "blog/2024/index.html#r-19",
    "href": "blog/2024/index.html#r-19",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\nstarwars |&gt;\nmutate(dog_years = birth_year * 7,\n       comment = paste(name, \"is\", dog_years, \"in dog years\")) |&gt;\n       select(name, dog_years, comment) |&gt;\n       head(5)\n\n# A tibble: 5 √ó 3\n  name           dog_years comment                           \n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;                             \n1 Luke Skywalker      133  Luke Skywalker is 133 in dog years\n2 C-3PO               784  C-3PO is 784 in dog years         \n3 R2-D2               231  R2-D2 is 231 in dog years         \n4 Darth Vader         293. Darth Vader is 293.3 in dog years \n5 Leia Organa         133  Leia Organa is 133 in dog years"
  },
  {
    "objectID": "blog/2024/index.html#python-19",
    "href": "blog/2024/index.html#python-19",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\nstarwars = pl.read_csv(\"starwars.csv\")\n\nNo such file or directory (os error 2): starwars.csv\n\nstarwars.with_columns(dog_years = pl.col(\"birth_year\") * 7).with_columns(dog_years_string = pl.col(\"dog_years\").cast(str)).with_columns(comment = pl.col(\"name\") + \" is \" + pl.col(\"dog_years_string\") + \" in dog years \")\n\nname 'starwars' is not defined"
  },
  {
    "objectID": "blog/2024/index.html#group-by-and-summarize",
    "href": "blog/2024/index.html#group-by-and-summarize",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Group by and summarize",
    "text": "Group by and summarize\nLast but not least we need to do the group by and summarise bit. It looks like this is slightly more intuitive\n\nRPython\n\n\n\npenguins |&gt;\ngroup_by(species) |&gt;\nsummarise(total = n())\n\n# A tibble: 3 √ó 2\n  species   total\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\n\n\n\npenguins.group_by(pl.col(\"species\")).agg(total = pl.count())\n\n\nshape: (3, 2)\n\n\n\nspecies\ntotal\n\n\nstr\nu32\n\n\n\n\n\"Chinstrap\"\n68\n\n\n\"Gentoo\"\n124\n\n\n\"Adelie\"\n152\n\n\n\n\n\n\n\n\n\nLets do some mathy stuff\n\npenguins.group_by(pl.col(\"species\")).agg(count = pl.len(),\n                                         mean_flipp = pl.mean(\"flipper_length_mm\"),\n                                         median_flipp = pl.median(\"flipper_length_mm\"))\n\n\nshape: (3, 4)\n\n\n\nspecies\ncount\nmean_flipp\nmedian_flipp\n\n\nstr\nu32\nf64\nf64\n\n\n\n\n\"Gentoo\"\n124\n217.186992\n216.0\n\n\n\"Adelie\"\n152\n189.953642\n190.0\n\n\n\"Chinstrap\"\n68\n195.823529\n196.0\n\n\n\n\n\n\nA thing that is useful in summarize is that we can use our selectors to summarise across multiple columns like this\n\npenguins |&gt;\ngroup_by(species) |&gt;\nsummarise(across(starts_with(\"bill\"), list(mean = \\(x) mean(x, na.rm = TRUE,\n                                           median = \\(x) median(x, na.rm,  TRUE)))))\n\n# A tibble: 3 √ó 3\n  species   bill_length_mm_mean bill_depth_mm_mean\n  &lt;fct&gt;                   &lt;dbl&gt;              &lt;dbl&gt;\n1 Adelie                   38.8               18.3\n2 Chinstrap                48.8               18.4\n3 Gentoo                   47.5               15.0\n\n\nIn polars I imagine it would probably be something like this\n\npenguins.group_by(pl.col(\"species\")).agg(cs.starts_with(\"bill\").mean())\n\n\nshape: (3, 3)\n\n\n\nspecies\nbill_length_mm\nbill_depth_mm\n\n\nstr\nf64\nf64\n\n\n\n\n\"Chinstrap\"\n48.833824\n18.420588\n\n\n\"Gentoo\"\n47.504878\n14.982114\n\n\n\"Adelie\"\n38.791391\n18.346358\n\n\n\n\n\n\nThe think I am running into now is that I would like to add a _ without doing any extra work. It looks like according to the docs it should be this\n\npenguins.group_by(pl.col(\"species\")).agg(cs.starts_with(\"bill\").mean().name.suffix(\"_mean\"),\n                                         cs.starts_with(\"bill\").median().name.suffix(\"_median\"))\n\n\nshape: (3, 5)\n\n\n\nspecies\nbill_length_mm_mean\nbill_depth_mm_mean\nbill_length_mm_median\nbill_depth_mm_median\n\n\nstr\nf64\nf64\nf64\nf64\n\n\n\n\n\"Gentoo\"\n47.504878\n14.982114\n47.3\n15.0\n\n\n\"Chinstrap\"\n48.833824\n18.420588\n49.55\n18.45\n\n\n\"Adelie\"\n38.791391\n18.346358\n38.8\n18.4"
  },
  {
    "objectID": "blog/2024/index.html#r-20",
    "href": "blog/2024/index.html#r-20",
    "title": "Translating What I know in the tidyverse to python",
    "section": "R",
    "text": "R\npenguins |&gt;\ngroup_by(species) |&gt;\nsummarise(total = n())\n\n# A tibble: 3 √ó 2\n  species   total\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124"
  },
  {
    "objectID": "blog/2024/index.html#python-20",
    "href": "blog/2024/index.html#python-20",
    "title": "Translating What I know in the tidyverse to python",
    "section": "Python",
    "text": "Python\npenguins.group_by(pl.col(\"species\")).agg(total = pl.count())\n\n\nshape: (3, 2)\n\n\n\nspecies\ntotal\n\n\nstr\nu32\n\n\n\n\n\"Chinstrap\"\n68\n\n\n\"Adelie\"\n152\n\n\n\"Gentoo\"\n124"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html",
    "href": "blog/2024/translating-dplyr-to-polars/index.html",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "",
    "text": "I suppose at some point it is good to become more well versed in lots of tools. I have been python curious for about a year or so and I think it is important to use the tool best suited for the task. Also sometimes it is important to get out of your comfort zone. I am definitely somebody who is very comfortable in R and the tidyverse and use it for a lot of stuff. I have heard lots of ravings about polars specifically about its speed and similarities in intuition with the tidyverse. So I thought I would have a collection of code for myself and the people of the internet to reference.\nJust a disclaimer. This is really just me working through the similarities and is going to be based on the tidyintelligence‚Äôs blog post, Robert Mitchell‚Äôs blog post, and Emily Rieder‚Äôs blog post. In all honesty, this is just for me to smash them together to have a one-stop shop for myself. If you found this post over these resources I highly recommend you check out these resources."
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#group-by-and-summarize",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#group-by-and-summarize",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Group by and summarize",
    "text": "Group by and summarize\nLast but not least we need to do the group by and summarise bit. It looks like this is slightly more intuitive\n\nRPython\n\n\n\npenguins |&gt;\ngroup_by(species) |&gt;\nsummarise(total = n())\n\n# A tibble: 3 √ó 2\n  species   total\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\n\n\n\npenguins.group_by(pl.col(\"species\")).agg(total = pl.count())\n\n\n\nshape: (3, 2)\n\n\n\nspecies\ntotal\n\n\nstr\nu32\n\n\n\n\n\"Chinstrap\"\n68\n\n\n\"Gentoo\"\n124\n\n\n\"Adelie\"\n152\n\n\n\n\n\n\n\n\n\n\nLets do some mathy stuff\n\npenguins.group_by(pl.col(\"species\")).agg(count = pl.len(),\n                                         mean_flipp = pl.mean(\"flipper_length_mm\"),\n                                         median_flipp = pl.median(\"flipper_length_mm\"))\n\n\n\nshape: (3, 4)\n\n\n\nspecies\ncount\nmean_flipp\nmedian_flipp\n\n\nstr\nu32\nf64\nf64\n\n\n\n\n\"Chinstrap\"\n68\n195.823529\n196.0\n\n\n\"Gentoo\"\n124\n217.186992\n216.0\n\n\n\"Adelie\"\n152\n189.953642\n190.0\n\n\n\n\n\n\n\n\nacross\nA thing that is useful in summarize is that we can use our selectors to summarise across multiple columns like this\n\npenguins |&gt;\ngroup_by(species) |&gt;\nsummarise(across(starts_with(\"bill\"), list(mean = \\(x) mean(x, na.rm = TRUE,\n                                           median = \\(x) median(x, na.rm,  TRUE)))))\n\n# A tibble: 3 √ó 3\n  species   bill_length_mm_mean bill_depth_mm_mean\n  &lt;fct&gt;                   &lt;dbl&gt;              &lt;dbl&gt;\n1 Adelie                   38.8               18.3\n2 Chinstrap                48.8               18.4\n3 Gentoo                   47.5               15.0\n\n\nIn polars I imagine it would probably be something like this\n\npenguins.group_by(pl.col(\"species\")).agg(cs.starts_with(\"bill\").mean())\n\n\n\nshape: (3, 3)\n\n\n\nspecies\nbill_length_mm\nbill_depth_mm\n\n\nstr\nf64\nf64\n\n\n\n\n\"Gentoo\"\n47.504878\n14.982114\n\n\n\"Adelie\"\n38.791391\n18.346358\n\n\n\"Chinstrap\"\n48.833824\n18.420588\n\n\n\n\n\n\n\nThe think I am running into now is that I would like to add a _ without doing any extra work. It looks like according to the docs it should be this\n\npenguins.group_by(pl.col(\"species\")).agg(cs.starts_with(\"bill\").mean().name.suffix(\"_mean\"),\n                                         cs.starts_with(\"bill\").median().name.suffix(\"_median\"))\n\n\n\nshape: (3, 5)\n\n\n\nspecies\nbill_length_mm_mean\nbill_depth_mm_mean\nbill_length_mm_median\nbill_depth_mm_median\n\n\nstr\nf64\nf64\nf64\nf64\n\n\n\n\n\"Adelie\"\n38.791391\n18.346358\n38.8\n18.4\n\n\n\"Chinstrap\"\n48.833824\n18.420588\n49.55\n18.45\n\n\n\"Gentoo\"\n47.504878\n14.982114\n47.3\n15.0"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#make-a-column-into-a-vector",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#make-a-column-into-a-vector",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Make a column into a vector",
    "text": "Make a column into a vector\nIn R there are like a ton of different ways to do this\n\nvec1 = penguins$bill_depth_mm\n\nvec2 = penguins |&gt;\npluck(\"bill_depth_mm\")\n\nvec3 = penguins |&gt;\nselect(bill_depth_mm) |&gt;\ndeframe()\n\nIn polars the equivalent of this\n\nvec1 = penguins[\"bill_depth_mm\"]\n\nprint(vec1[0,1])\n\nshape: (2,)\nSeries: 'bill_depth_mm' [str]\n[\n    \"18.7\"\n    \"17.4\"\n]\n\n\n\nRPython\n\n\n\nvec1[1:3]\n\n[1] 18.7 17.4 18.0\n\n\n\n\n\nimport numpy as np \n\nprint(vec1[0:2])\n\nshape: (2,)\nSeries: 'bill_depth_mm' [str]\n[\n    \"18.7\"\n    \"17.4\"\n]"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#joins-in-polars",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#joins-in-polars",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Joins in Polars",
    "text": "Joins in Polars\nIt would be nice if we had all the data we wanted in one dataset but that is not life we often need to join data. Critically we also would not want to have all our data in one place if we care about users safety. So we may want to keep portions of the dataset in separate places. So lets define a simple dataset to work with.\n\nnational_data &lt;- tribble(\n  ~state, ~year, ~unemployment, ~inflation, ~population,\n  \"GA\",   2018,  5,             2,          100,\n  \"GA\",   2019,  5.3,           1.8,        200,\n  \"GA\",   2020,  5.2,           2.5,        300,\n  \"NC\",   2018,  6.1,           1.8,        350,\n  \"NC\",   2019,  5.9,           1.6,        375,\n  \"NC\",   2020,  5.3,           1.8,        400,\n  \"CO\",   2018,  4.7,           2.7,        200,\n  \"CO\",   2019,  4.4,           2.6,        300,\n  \"CO\",   2020,  5.1,           2.5,        400\n)\n\nnational_libraries &lt;- tribble(\n  ~state, ~year, ~libraries, ~schools,\n  \"CO\",   2018,  230,        470,\n  \"CO\",   2019,  240,        440,\n  \"CO\",   2020,  270,        510,\n  \"NC\",   2018,  200,        610,\n  \"NC\",   2019,  210,        590,\n  \"NC\",   2020,  220,        530,\n)\n\n\n\nnational_dict = {\"state\": [\"Ga\", \"Ga\", \"Ga\",  \"NC\", \"NC\", \"NC\", \"CO\", \"CO\", \"CO\"], \"unemployment\":[6,6,8,6,4,3,7,8,9], \"year\": [2019,2018,2017,2019,2018,2017,2019,2018,2017]}\n\n\nnational_data = pl.DataFrame(national_dict)\n\n\nlibrary_dict = {\"state\":[\"CO\", \"CO\", \"CO\"], \"libraries\": [23234,2343234,32342342], \"year\":[2019,2018,2017]}\n\n\nlibrary_data = pl.DataFrame(library_dict)\n\nWe may want to merge in the library dataset. In tidyland we would do something like this\n\nnational_data |&gt;\nleft_join(national_libraries, join_by(state, year))\n\n# A tibble: 9 √ó 7\n  state  year unemployment inflation population libraries schools\n  &lt;chr&gt; &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 GA     2018          5         2          100        NA      NA\n2 GA     2019          5.3       1.8        200        NA      NA\n3 GA     2020          5.2       2.5        300        NA      NA\n4 NC     2018          6.1       1.8        350       200     610\n5 NC     2019          5.9       1.6        375       210     590\n6 NC     2020          5.3       1.8        400       220     530\n7 CO     2018          4.7       2.7        200       230     470\n8 CO     2019          4.4       2.6        300       240     440\n9 CO     2020          5.1       2.5        400       270     510\n\n\nIn polars land we would join the data like this\n\njoined_data = national_data.join(library_data, on = [\"state\",\"year\"], how = \"left\")\n\njoined_data \n\n\nshape: (9, 4)\n\n\n\nstate\nunemployment\nyear\nlibraries\n\n\nstr\ni64\ni64\ni64\n\n\n\n\n\"Ga\"\n6\n2019\nnull\n\n\n\"Ga\"\n6\n2018\nnull\n\n\n\"Ga\"\n8\n2017\nnull\n\n\n\"NC\"\n6\n2019\nnull\n\n\n\"NC\"\n4\n2018\nnull\n\n\n\"NC\"\n3\n2017\nnull\n\n\n\"CO\"\n7\n2019\n23234\n\n\n\"CO\"\n8\n2018\n2343234\n\n\n\"CO\"\n9\n2017\n32342342\n\n\n\n\n\n\nThis is honestly pretty comfortable. One thing that is really nice about dplyr is that you can pretty easily join columns that are not named the same thing.\n\nnational_libraries = national_libraries |&gt;\nrename(state_name = state)\n\n\n\nnational_data |&gt;\nleft_join(national_libraries, join_by(state == state_name, year))\n\n# A tibble: 9 √ó 7\n  state  year unemployment inflation population libraries schools\n  &lt;chr&gt; &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 GA     2018          5         2          100        NA      NA\n2 GA     2019          5.3       1.8        200        NA      NA\n3 GA     2020          5.2       2.5        300        NA      NA\n4 NC     2018          6.1       1.8        350       200     610\n5 NC     2019          5.9       1.6        375       210     590\n6 NC     2020          5.3       1.8        400       220     530\n7 CO     2018          4.7       2.7        200       230     470\n8 CO     2019          4.4       2.6        300       240     440\n9 CO     2020          5.1       2.5        400       270     510\n\n\nIn polars the process is less clear immediately. Instead of a nice join_by argument you have specify the keys separately. But still pretty intuitive.\n\nlibrary_dat = library_data.rename({\"state\": \"state_name\"})\n\n\nnational_data.join(library_dat, left_on = [\"state\", \"year\"],\n               right_on = [\"state_name\", \"year\"], how = \"left\" )\n\n\nshape: (9, 4)\n\n\n\nstate\nunemployment\nyear\nlibraries\n\n\nstr\ni64\ni64\ni64\n\n\n\n\n\"Ga\"\n6\n2019\nnull\n\n\n\"Ga\"\n6\n2018\nnull\n\n\n\"Ga\"\n8\n2017\nnull\n\n\n\"NC\"\n6\n2019\nnull\n\n\n\"NC\"\n4\n2018\nnull\n\n\n\"NC\"\n3\n2017\nnull\n\n\n\"CO\"\n7\n2019\n23234\n\n\n\"CO\"\n8\n2018\n2343234\n\n\n\"CO\"\n9\n2017\n32342342"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#binding-rows",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#binding-rows",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Binding Rows",
    "text": "Binding Rows\nSometimes we just want to add rows to our data\n\na = data.frame(id = 1:2, vals = 1:2)\n\nb  = data.frame(id = 3:4, vals = 3:4)\n\n\na |&gt;\nbind_rows(b)\n\n  id vals\n1  1    1\n2  2    2\n3  3    3\n4  4    4\n\n\nor we want to add columns\n\nc = data.frame(chars = c(\"hello\", \"lorem\"),\n               var_23 = c(\"world\", \"ipsum\"))\n\na |&gt;\nbind_cols(c)\n\n  id vals chars var_23\n1  1    1 hello  world\n2  2    2 lorem  ipsum\n\n\nHow would we do this in polars?\n\na = pl.DataFrame(\n       {\"a\": [1,2],\n        \"b\": [3,4]}\n)\n\nb = pl.DataFrame({\"a\" : [3,4], \"b\": [5,6]})\n\n\npl.concat([a, b], how = \"vertical\")\n\n\nshape: (4, 2)\n\n\n\na\nb\n\n\ni64\ni64\n\n\n\n\n1\n3\n\n\n2\n4\n\n\n3\n5\n\n\n4\n6\n\n\n\n\n\n\nAgain fairly intuitive if we wanted to bind the columns\n\nc = pl.DataFrame({\"chars\": [\"hello\", \"lorem\"], \"chars2\":[\"world\",\"ipsum\"]})\n\n\npl.concat([a,c], how = \"horizontal\")\n\n\nshape: (2, 4)\n\n\n\na\nb\nchars\nchars2\n\n\ni64\ni64\nstr\nstr\n\n\n\n\n1\n3\n\"hello\"\n\"world\"\n\n\n2\n4\n\"lorem\"\n\"ipsum\""
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#pivots-of-all-shapes",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#pivots-of-all-shapes",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Pivots of all shapes",
    "text": "Pivots of all shapes\nSometimes we need to pivot our data. Lets use the built in example from tidyr. Basically we have a whole bunch of columns that denote counts of income brackets\n\nrelig = relig_income\n\n\nwrite_csv(relig,\"relig_income.csv\")\n\n\nhead(relig_income)\n\n# A tibble: 6 √ó 11\n  religion  `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 Agnostic       27        34        60        81        76       137        122\n2 Atheist        12        27        37        52        35        70         73\n3 Buddhist       27        21        30        34        33        58         62\n4 Catholic      418       617       732       670       638      1116        949\n5 Don‚Äôt kn‚Ä¶      15        14        15        11        10        35         21\n6 Evangeli‚Ä¶     575       869      1064       982       881      1486        949\n# ‚Ñπ 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;,\n#   `Don't know/refused` &lt;dbl&gt;\n\n\nIn tidyr we would just do this\n\nrelig |&gt;\npivot_longer(-religion,\n              names_to = \"income_bracket\",\n              values_to = \"count\")\n\n# A tibble: 180 √ó 3\n   religion income_bracket     count\n   &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;\n 1 Agnostic &lt;$10k                 27\n 2 Agnostic $10-20k               34\n 3 Agnostic $20-30k               60\n 4 Agnostic $30-40k               81\n 5 Agnostic $40-50k               76\n 6 Agnostic $50-75k              137\n 7 Agnostic $75-100k             122\n 8 Agnostic $100-150k            109\n 9 Agnostic &gt;150k                 84\n10 Agnostic Don't know/refused    96\n# ‚Ñπ 170 more rows\n\n\nwhich is nice because we can just identify a column and then pivot. One thing that I will have to just memorize is that when we are moving things to long in polars than we melt the dataframe. Kind of like a popsicle or something. The mnemonic device will come to me eventually\n\nrelig = pl.read_csv(\"relig_income.csv\")\n\nrelig.head()\n\n\n\nshape: (5, 11)\n\n\n\nreligion\n&lt;$10k\n$10-20k\n$20-30k\n$30-40k\n$40-50k\n$50-75k\n$75-100k\n$100-150k\n&gt;150k\nDon't know/refused\n\n\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n\"Agnostic\"\n27\n34\n60\n81\n76\n137\n122\n109\n84\n96\n\n\n\"Atheist\"\n12\n27\n37\n52\n35\n70\n73\n59\n74\n76\n\n\n\"Buddhist\"\n27\n21\n30\n34\n33\n58\n62\n39\n53\n54\n\n\n\"Catholic\"\n418\n617\n732\n670\n638\n1116\n949\n792\n633\n1489\n\n\n\"Don‚Äôt know/refused\"\n15\n14\n15\n11\n10\n35\n21\n17\n18\n116\n\n\n\n\n\n\n\nTo melt all we do is\n\nrelig.melt(id_vars = \"religion\", variable_name = \"income_bracket\", value_name = \"count\")\n\n\n\nshape: (180, 3)\n\n\n\nreligion\nincome_bracket\ncount\n\n\nstr\nstr\ni64\n\n\n\n\n\"Agnostic\"\n\"&lt;$10k\"\n27\n\n\n\"Atheist\"\n\"&lt;$10k\"\n12\n\n\n\"Buddhist\"\n\"&lt;$10k\"\n27\n\n\n\"Catholic\"\n\"&lt;$10k\"\n418\n\n\n\"Don‚Äôt know/refused\"\n\"&lt;$10k\"\n15\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n\"Orthodox\"\n\"Don't know/refused\"\n73\n\n\n\"Other Christian\"\n\"Don't know/refused\"\n18\n\n\n\"Other Faiths\"\n\"Don't know/refused\"\n71\n\n\n\"Other World Religions\"\n\"Don't know/refused\"\n8\n\n\n\"Unaffiliated\"\n\"Don't know/refused\"\n597\n\n\n\n\n\n\n\nsame would go for the pivoting wider\n\npenguins.pivot(index = \"island\",columns = \"species\", values = \"body_mass_g\",\n              aggregate_function=\"sum\")\n\n\n\nshape: (3, 4)\n\n\n\nisland\nAdelie\nGentoo\nChinstrap\n\n\nstr\nstr\nstr\nstr\n\n\n\n\n\"Torgersen\"\nnull\nnull\nnull\n\n\n\"Biscoe\"\nnull\nnull\nnull\n\n\n\"Dream\"\nnull\nnull\nnull\n\n\n\n\n\n\n\nthis isn‚Äôt quite the same because we are aggregating it. This is likely just a skill issue on the user end. But still we have wide data now!\n\nUsing selectors in pivot longer\nA slightly more complex example is using the billboards datas\n\nbillboards = tidyr::billboard\n\n\nwrite_csv(billboards, \"billboard.csv\")\n\n\nhead(billboards)\n\n# A tibble: 6 √ó 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby‚Ä¶ 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The ‚Ä¶ 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do‚Ä¶ Kryp‚Ä¶ 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do‚Ä¶ Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb‚Ä¶ 2000-04-15      57    34    25    17    17    31    36    49\n6 98^0        Give‚Ä¶ 2000-08-19      51    39    34    26    26    19     2     2\n# ‚Ñπ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, ‚Ä¶\n\n billboards |&gt;\npivot_longer(cols = starts_with(\"wk\"),\n              names_to = \"week\",\n              values_to = \"count_of_weeks\")\n\n# A tibble: 24,092 √ó 5\n   artist track                   date.entered week  count_of_weeks\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt;          &lt;dbl&gt;\n 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1               87\n 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2               82\n 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3               72\n 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4               77\n 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5               87\n 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6               94\n 7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7               99\n 8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8               NA\n 9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9               NA\n10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10              NA\n# ‚Ñπ 24,082 more rows\n\n\nWe can do something similar with polars by using our selectors.\n\nbillboards = pl.read_csv(\"billboard.csv\")\n\n\nbillboards.melt(id_vars = \"artist\",value_vars  = cs.starts_with(\"wk\"),\n                variable_name = \"week\", value_name = \"count\" )\n\n\n\nshape: (24_092, 3)\n\n\n\nartist\nweek\ncount\n\n\nstr\nstr\nstr\n\n\n\n\n\"2 Pac\"\n\"wk1\"\n\"87\"\n\n\n\"2Ge+her\"\n\"wk1\"\n\"91\"\n\n\n\"3 Doors Down\"\n\"wk1\"\n\"81\"\n\n\n\"3 Doors Down\"\n\"wk1\"\n\"76\"\n\n\n\"504 Boyz\"\n\"wk1\"\n\"57\"\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n\"Yankee Grey\"\n\"wk76\"\n\"NA\"\n\n\n\"Yearwood, Trisha\"\n\"wk76\"\n\"NA\"\n\n\n\"Ying Yang Twins\"\n\"wk76\"\n\"NA\"\n\n\n\"Zombie Nation\"\n\"wk76\"\n\"NA\"\n\n\n\"matchbox twenty\"\n\"wk76\"\n\"NA\"\n\n\n\n\n\n\n\nBroadly it works the same but if you don‚Äôt specify the id vars you will end up with just the week and count column"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#plotting-data",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#plotting-data",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Plotting data",
    "text": "Plotting data\nConfession time. I hate matplots I never think they look very nice. However I as somebody who enjoys data visualization should learn how to do it in python too. From what I can tell there are a few different attempts at porting over ggplot. But It seems like working in something somewhat standard versus going polars and ibis all the way probably makes sense.\nOne thing that should be mentioned is that missing values in python are not the same. Since quarto was getting mad at me for some reason about not having installed the palmer penguins package I decided to stop fighting with it. One thing that is\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n\n\n\nsns.set_theme(style = \"whitegrid\")\n\nSo I think seaborne might be the way to go. Since I don‚Äôt think histograms will go out of style lets just go and make a histogram\n\n\nsns.histplot(data = penguins, x = \"body_mass_g\")\n\n\n\n\neasy enough\n\n\nsns.histplot(data = penguins, x = \"body_mass_g\", hue  = \"species\")\n\n\n\n\nWhat if we wanted densities instead of frequencies? In ggplot it would be\n\nggplot(penguins, aes(x = body_mass_g, fill = species)) +\ngeom_histogram(aes(y =  after_stat(density)))\n\n\n\n\nIn sns it would be.\n\n\nsns.histplot(data = penguins, x = \"body_mass_g\", hue = \"species\", stat = \"density\")\n\n\n\n\nI really like the legend on the inside! In new ggplot 3.whatever it is\n\nggplot(penguins, aes(x = body_mass_g, y = after_stat(density), fill = species)) +\ngeom_histogram() +\ntheme_minimal() +\ntheme(legend.position = c(.95,.95),\n      legend.justification = c(\"right\", \"top\"))\n\n\n\n\nCool I like that and will fiddle with that my ggplot theme!\nOkay lets now go and do some bivariate plots. Obviously the workhorse of bivariate plotting is the scatterplot .\n\n\nsns.scatterplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\")\n\n\n\n\nthe next thing that we would want is to size points by the size of the penguin\n\n\nsns.scatterplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\", size = \"body_mass_g\")\n\n\n\n\nThat is not really great since the legend is inside and covering stuff. In ggplot we would simply just move the legend position. In this case we have to save it as an object\n\n\nexmp = sns.scatterplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\", size = \"body_mass_g\")\n\nsns.move_legend(exmp, \"upper left\", bbox_to_anchor = (1,1))\n\n\n\n\n\nsns.lmplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\")\n\n\n\n\n\n\n\nThen the other one that I use all the time is using a line of best fit . Okay obviously the most annoying part is that we don‚Äôt have great labels\n\nlabs_examp = sns.lmplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\")\n\n\n\nlabs_examp.set_axis_labels(x_var= \"Flipper Length(mm)\", y_var = \"Body Mass(g)\")\n\n\n\n\n\n\n\nOne of the things we may want to do is to create small multiples.\n\nsns.displot(data = penguins, x = \"body_mass_g\", hue = \"species\", row= \"species\", facet_kws = dict(margin_titles=False))\n\n\n\n\n\n\n\nI am honestly not wild about the plot but that is life"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#modeling",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#modeling",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Modeling",
    "text": "Modeling\nThe last step in the journey is really just learning the basics of modeling. The annoying part is that there is no native support for our favorite stats stuff. So no trusty dust glm or OLS when you open up python. From the excellent marginaleffects package it looks like there is a nice interface called statsmodels and they have a formula api which works like modeling in R just without lazy evaluation.\n\n\nimport statsmodels.formula.api as smf\nimport numpy as np\n\nLets fit a few simple models to try and get the hang of statsmodels and see what happens. I will also load broom since I find that it makes working with all the various list components that R spits less annoying to work with.\nLets fit a univariate model first and then we can start playing with the api a little more\n\nRPython\n\n\n\nlibrary(broom)\n\nnaive = lm(body_mass_g ~ flipper_length_mm, data = penguins)\n\ntidy(naive)\n\n# A tibble: 2 √ó 5\n  term              estimate std.error statistic   p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\n\n\n\n\nnaive = smf.ols(\"body_mass_g ~ flipper_length_mm\", data = penguins).fit()\n\n\n\n\nThe biggest difference between the two approaches is that specifying the model and fitting the model are two different steps. If we wanted to see a similar print out we would have to do something like\n\nnaive.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nbody_mass_g\nR-squared:\n0.759\n\n\nModel:\nOLS\nAdj. R-squared:\n0.758\n\n\nMethod:\nLeast Squares\nF-statistic:\n1071.\n\n\nDate:\nTue, 12 Mar 2024\nProb (F-statistic):\n4.37e-107\n\n\nTime:\n15:29:45\nLog-Likelihood:\n-2528.4\n\n\nNo. Observations:\n342\nAIC:\n5061.\n\n\nDf Residuals:\n340\nBIC:\n5069.\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-5780.8314\n305.815\n-18.903\n0.000\n-6382.358\n-5179.305\n\n\nflipper_length_mm\n49.6856\n1.518\n32.722\n0.000\n46.699\n52.672\n\n\n\n\n\n\nOmnibus:\n5.634\nDurbin-Watson:\n2.190\n\n\nProb(Omnibus):\n0.060\nJarque-Bera (JB):\n5.585\n\n\nSkew:\n0.313\nProb(JB):\n0.0613\n\n\nKurtosis:\n3.019\nCond. No.\n2.89e+03\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 2.89e+03. This might indicate that there arestrong multicollinearity or other numerical problems.\n\n\nCool. A multivariate model would broadly be the same. One thing that we can do in R is we can transform the predictors in the formula like this\n\nsquared = lm(body_mass_g ~ flipper_length_mm + I(flipper_length_mm^2) + bill_depth_mm,\n              data = penguins)\n              \ntidy(squared)\n\n# A tibble: 4 √ó 5\n  term                    estimate std.error statistic     p.value\n  &lt;chr&gt;                      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 (Intercept)            16824.     4532.         3.71 0.000240   \n2 flipper_length_mm       -181.       44.9       -4.04 0.0000669  \n3 I(flipper_length_mm^2)     0.573     0.110      5.19 0.000000363\n4 bill_depth_mm             29.3      12.9        2.28 0.0232     \n\n\nWe can do something like it.\n\nsquared = smf.ols(\"body_mass_g ~ flipper_length_mm**2 + flipper_length_mm  + bill_depth_mm\", data = penguins).fit()\n\n\nsquared.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nbody_mass_g\nR-squared:\n0.761\n\n\nModel:\nOLS\nAdj. R-squared:\n0.760\n\n\nMethod:\nLeast Squares\nF-statistic:\n539.8\n\n\nDate:\nTue, 12 Mar 2024\nProb (F-statistic):\n4.23e-106\n\n\nTime:\n15:29:46\nLog-Likelihood:\n-2527.0\n\n\nNo. Observations:\n342\nAIC:\n5060.\n\n\nDf Residuals:\n339\nBIC:\n5071.\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-6541.9075\n540.751\n-12.098\n0.000\n-7605.557\n-5478.258\n\n\nflipper_length_mm\n51.5414\n1.865\n27.635\n0.000\n47.873\n55.210\n\n\nbill_depth_mm\n22.6341\n13.280\n1.704\n0.089\n-3.488\n48.756\n\n\n\n\n\n\nOmnibus:\n5.490\nDurbin-Watson:\n2.069\n\n\nProb(Omnibus):\n0.064\nJarque-Bera (JB):\n5.361\n\n\nSkew:\n0.305\nProb(JB):\n0.0685\n\n\nKurtosis:\n3.067\nCond. No.\n5.14e+03\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 5.14e+03. This might indicate that there arestrong multicollinearity or other numerical problems.\n\n\nHowever the results differ pretty wildly! Luckily there is an I operator in the underlying thing that makes this work. The problem is that it only works on pandas dataframes\n\n\n\npenguins_pd = penguins.to_pandas()\n\n\nsquared = smf.ols('body_mass_g ~ I(flipper_length_mm**2) + flipper_length_mm + bill_depth_mm', data = penguins_pd).fit()\n\nNow the results are lining up. As a political scientist by training we love ourselves an interaction term.\n\nRPython\n\n\n\ninteracted = lm(body_mass_g ~ bill_depth_mm * species + flipper_length_mm,\ndata = penguins) \n\n\ntidy(interacted)\n\n# A tibble: 7 √ó 5\n  term                           estimate std.error statistic  p.value\n  &lt;chr&gt;                             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                     -4213.     648.      -6.50  2.84e-10\n2 bill_depth_mm                     176.      22.6      7.81  7.22e-14\n3 speciesChinstrap                 1008.     771.       1.31  1.92e- 1\n4 speciesGentoo                     129.     608.       0.213 8.32e- 1\n5 flipper_length_mm                  24.6      3.17     7.76  1.04e-13\n6 bill_depth_mm:speciesChinstrap    -61.5     42.0     -1.47  1.44e- 1\n7 bill_depth_mm:speciesGentoo        78.0     38.5      2.02  4.37e- 2\n\n\n\n\n\ninteracted = smf.ols(\"body_mass_g ~ bill_length_mm * species + flipper_length_mm\", data = penguins_pd).fit()\n\n\ninteracted.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nbody_mass_g\nR-squared:\n0.826\n\n\nModel:\nOLS\nAdj. R-squared:\n0.823\n\n\nMethod:\nLeast Squares\nF-statistic:\n265.8\n\n\nDate:\nTue, 12 Mar 2024\nProb (F-statistic):\n4.07e-124\n\n\nTime:\n15:29:46\nLog-Likelihood:\n-2472.3\n\n\nNo. Observations:\n342\nAIC:\n4959.\n\n\nDf Residuals:\n335\nBIC:\n4985.\n\n\nDf Model:\n6\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-4297.9054\n645.054\n-6.663\n0.000\n-5566.772\n-3029.039\n\n\nspecies[T.Chinstrap]\n1146.2869\n726.217\n1.578\n0.115\n-282.232\n2574.806\n\n\nspecies[T.Gentoo]\n54.7163\n619.934\n0.088\n0.930\n-1164.739\n1274.171\n\n\nbill_length_mm\n72.6920\n10.642\n6.831\n0.000\n51.759\n93.625\n\n\nbill_length_mm:species[T.Chinstrap]\n-41.0350\n16.104\n-2.548\n0.011\n-72.713\n-9.357\n\n\nbill_length_mm:species[T.Gentoo]\n-1.1626\n14.436\n-0.081\n0.936\n-29.559\n27.234\n\n\nflipper_length_mm\n27.2632\n3.175\n8.586\n0.000\n21.017\n33.509\n\n\n\n\n\n\nOmnibus:\n4.761\nDurbin-Watson:\n2.272\n\n\nProb(Omnibus):\n0.093\nJarque-Bera (JB):\n4.564\n\n\nSkew:\n0.279\nProb(JB):\n0.102\n\n\nKurtosis:\n3.098\nCond. No.\n1.01e+04\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 1.01e+04. This might indicate that there arestrong multicollinearity or other numerical problems.\n\n\n\n\n\nAgain for whatever reason patsy does not have great support for polars dataframe so the original polars frame throws an error.\nOne thing that we generally want to do is check our OLS assumptions. There are lots of different tests that we can run. But a good first check is to look at the fitted values versus the residuals.\nIn R we can do\n\npacman::p_load(patchwork)\n\ndropped_nas = penguins |&gt; drop_na(sex)\n\n\nwith_species = lm(body_mass_g ~ bill_length_mm + flipper_length_mm + species,\n             data = dropped_nas)\n\ncheck_resids = augment(with_species, data = dropped_nas)\n\n\nviolation_one = ggplot(check_resids, aes(x = .fitted, y = .resid, color = species)) +\ngeom_point() +\ntheme_minimal()\n\nviolation_two = ggplot(check_resids, aes(x = .resid)) +\ngeom_histogram() +\ntheme_minimal()\n\n\nviolation_one + violation_two \n\n\n\n\nIn Python we would do something like this.\n\nimport pandas as pd\n\npenguins_sans_na = penguins.filter((pl.col(\"sex\").is_not_null())).to_pandas()\n\n\nwith_species = smf.ols('body_mass_g ~ bill_length_mm + flipper_length_mm + species', data = penguins_sans_na).fit()\n\npenguins_sans_na['fitted_vals'] = with_species.fittedvalues\n\npenguins_sans_na['residuals'] = with_species.resid\n\n\n\nsns.scatterplot(x = \"fitted_vals\", y = \"residuals\", hue = \"species\", data = penguins_sans_na)"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#r-21",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#r-21",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "R",
    "text": "R\nlibrary(broom)\n\nnaive = lm(body_mass_g ~ flipper_length_mm, data = penguins)\n\ntidy(naive)\n\n# A tibble: 2 √ó 5\n  term              estimate std.error statistic   p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#python-21",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#python-21",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Python",
    "text": "Python\n\nnaive = smf.ols(\"body_mass_g ~ flipper_length_mm\", data = penguins).fit()"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#r-22",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#r-22",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "R",
    "text": "R\n\ninteracted = lm(body_mass_g ~ bill_depth_mm * species + flipper_length_mm,\ndata = penguins) \n\n\ntidy(interacted)\n\n# A tibble: 7 √ó 5\n  term                           estimate std.error statistic  p.value\n  &lt;chr&gt;                             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                     -4213.     648.      -6.50  2.84e-10\n2 bill_depth_mm                     176.      22.6      7.81  7.22e-14\n3 speciesChinstrap                 1008.     771.       1.31  1.92e- 1\n4 speciesGentoo                     129.     608.       0.213 8.32e- 1\n5 flipper_length_mm                  24.6      3.17     7.76  1.04e-13\n6 bill_depth_mm:speciesChinstrap    -61.5     42.0     -1.47  1.44e- 1\n7 bill_depth_mm:speciesGentoo        78.0     38.5      2.02  4.37e- 2"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#python-22",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#python-22",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Python",
    "text": "Python\n\ninteracted = smf.ols(\"body_mass_g ~ bill_length_mm * species + flipper_length_mm\", data = penguins_pd).fit()\n\n\ninteracted.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nbody_mass_g\nR-squared:\n0.826\n\n\nModel:\nOLS\nAdj. R-squared:\n0.823\n\n\nMethod:\nLeast Squares\nF-statistic:\n265.8\n\n\nDate:\nTue, 12 Mar 2024\nProb (F-statistic):\n4.07e-124\n\n\nTime:\n15:06:03\nLog-Likelihood:\n-2472.3\n\n\nNo. Observations:\n342\nAIC:\n4959.\n\n\nDf Residuals:\n335\nBIC:\n4985.\n\n\nDf Model:\n6\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n-4297.9054\n645.054\n-6.663\n0.000\n-5566.772\n-3029.039\n\n\nspecies[T.Chinstrap]\n1146.2869\n726.217\n1.578\n0.115\n-282.232\n2574.806\n\n\nspecies[T.Gentoo]\n54.7163\n619.934\n0.088\n0.930\n-1164.739\n1274.171\n\n\nbill_length_mm\n72.6920\n10.642\n6.831\n0.000\n51.759\n93.625\n\n\nbill_length_mm:species[T.Chinstrap]\n-41.0350\n16.104\n-2.548\n0.011\n-72.713\n-9.357\n\n\nbill_length_mm:species[T.Gentoo]\n-1.1626\n14.436\n-0.081\n0.936\n-29.559\n27.234\n\n\nflipper_length_mm\n27.2632\n3.175\n8.586\n0.000\n21.017\n33.509\n\n\n\n\n\n\nOmnibus:\n4.761\nDurbin-Watson:\n2.272\n\n\nProb(Omnibus):\n0.093\nJarque-Bera (JB):\n4.564\n\n\nSkew:\n0.279\nProb(JB):\n0.102\n\n\nKurtosis:\n3.098\nCond. No.\n1.01e+04\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 1.01e+04. This might indicate that there arestrong multicollinearity or other numerical problems."
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#unnest",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#unnest",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Unnest",
    "text": "Unnest\nSometimes we have these unfriendly list columns that we would like to make not lists. Lets go ahead and use the starwars list columns.\n\nstarwars_lists = starwars |&gt;\nselect(name, where(is.list)) |&gt;\nunnest_longer(starships , keep_empty = TRUE) |&gt;\nunnest_longer(films, keep_empty = TRUE) |&gt;\nunnest_longer(vehicles, keep_empty = TRUE)\n\n\n\n\n\nhead(starwars_lists)\n\n# A tibble: 6 √ó 4\n  name           films                   vehicles              starships\n  &lt;chr&gt;          &lt;chr&gt;                   &lt;chr&gt;                 &lt;chr&gt;    \n1 Luke Skywalker A New Hope              Snowspeeder           X-wing   \n2 Luke Skywalker A New Hope              Imperial Speeder Bike X-wing   \n3 Luke Skywalker The Empire Strikes Back Snowspeeder           X-wing   \n4 Luke Skywalker The Empire Strikes Back Imperial Speeder Bike X-wing   \n5 Luke Skywalker Return of the Jedi      Snowspeeder           X-wing   \n6 Luke Skywalker Return of the Jedi      Imperial Speeder Bike X-wing   \n\n\nIn polars we have a similarish function named explode. Unfortunately we don‚Äôt have a a selector for all attribute types so we are going to do this by hand.\n\nstarwars_list = starwars.select([\"name\", \"films\", \"vehicles\", \"starships\"])\n\nstarwars_list.glimpse()\n\nRows: 87\nColumns: 4\n$ name            &lt;str&gt; 'Luke Skywalker', 'C-3PO', 'R2-D2', 'Darth Vader', 'Leia Organa', 'Owen Lars', 'Beru Whitesun Lars', 'R5-D4', 'Biggs Darklighter', 'Obi-Wan Kenobi'\n$ films     &lt;list[str]&gt; ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'Revenge of the Sith', 'The Force Awakens'], ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'The Phantom Menace', 'Attack of the Clones', 'Revenge of the Sith'], ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'The Phantom Menace', 'Attack of the Clones', 'Revenge of the Sith', 'The Force Awakens'], ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'Revenge of the Sith'], ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'Revenge of the Sith', 'The Force Awakens'], ['A New Hope', 'Attack of the Clones', 'Revenge of the Sith'], ['A New Hope', 'Attack of the Clones', 'Revenge of the Sith'], ['A New Hope'], ['A New Hope'], ['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi', 'The Phantom Menace', 'Attack of the Clones', 'Revenge of the Sith']\n$ vehicles  &lt;list[str]&gt; ['Snowspeeder', 'Imperial Speeder Bike'], [], [], [], ['Imperial Speeder Bike'], [], [], [], [], ['Tribubble bongo']\n$ starships &lt;list[str]&gt; ['X-wing', 'Imperial shuttle'], [], [], ['TIE Advanced x1'], [], [], [], [], ['X-wing'], ['Jedi starfighter', 'Trade Federation cruiser', 'Naboo star skiff', 'Jedi Interceptor', 'Belbullab-22 starfighter']\n\nstarwars_explode =  starwars_list.explode(\"films\").explode(\"vehicles\").explode(\"starships\")\n\nstarwars_explode.head()\n\n\n\nshape: (5, 4)\n\n\n\nname\nfilms\nvehicles\nstarships\n\n\nstr\nstr\nstr\nstr\n\n\n\n\n\"Luke Skywalker\"\n\"A New Hope\"\n\"Snowspeeder\"\n\"X-wing\"\n\n\n\"Luke Skywalker\"\n\"A New Hope\"\n\"Snowspeeder\"\n\"Imperial shuttle\"\n\n\n\"Luke Skywalker\"\n\"A New Hope\"\n\"Imperial Speeder Bike\"\n\"X-wing\"\n\n\n\"Luke Skywalker\"\n\"A New Hope\"\n\"Imperial Speeder Bike\"\n\"Imperial shuttle\"\n\n\n\"Luke Skywalker\"\n\"The Empire Strikes Back\"\n\"Snowspeeder\"\n\"X-wing\""
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#r-6",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#r-6",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "R",
    "text": "R\n\npenguins |&gt;\nfilter(!species %in% c(\"Gentoo\", \"Chinstrap\"),\n       island != \"Dream\")\n\n# A tibble: 96 √ó 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ 86 more rows\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#python-6",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#python-6",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Python",
    "text": "Python\n\npenguins.filter((pl.col(\"species\").is_in([\"Chinstrap\", \"Gentoo\"]).not_()) & \n                (pl.col(\"island\") != 'Dream'))\n\n\n\nshape: (96, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nf64\nf64\nf64\nstr\nstr\ni64\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181.0\n\"3750\"\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186.0\n\"3800\"\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195.0\n\"3250\"\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\nnull\nnull\nnull\n\"NA\"\n\"NA\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n36.7\n19.3\n193.0\n\"3450\"\n\"female\"\n2007\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n\"Adelie\"\n\"Torgersen\"\n41.5\n18.3\n195.0\n\"4300\"\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n39.0\n17.1\n191.0\n\"3050\"\n\"female\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n44.1\n18.0\n210.0\n\"4000\"\n\"male\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n38.5\n17.9\n190.0\n\"3325\"\n\"female\"\n2009\n\n\n\"Adelie\"\n\"Torgersen\"\n43.1\n19.2\n197.0\n\"3500\"\n\"male\"\n2009\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#histograms",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#histograms",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Histograms",
    "text": "Histograms\n\n\nsns.histplot(data = penguins, x = \"body_mass_g\")\n\n\n\n\n\n\n\n\neasy enough\n\n\nsns.histplot(data = penguins, x = \"body_mass_g\", hue  = \"species\")\n\n\n\n\n\n\n\n\nWhat if we wanted densities instead of frequencies? In ggplot it would be\n\nggplot(penguins, aes(x = body_mass_g, fill = species)) +\ngeom_histogram(aes(y =  after_stat(density)))\n\n\n\n\n\n\n\n\nIn sns it would be.\n\n\nsns.histplot(data = penguins, x = \"body_mass_g\", hue = \"species\", stat = \"density\")\n\n\n\n\n\n\n\n\nI really like the legend on the inside! In new ggplot 3.whatever it is different now that there is an explicit legend.position=\"inside\".\n\nggplot(penguins, aes(x = body_mass_g, y = after_stat(density), fill = species)) +\ngeom_histogram() +\ntheme_minimal() +\ntheme(legend.position = c(.95,.95),\n      legend.justification = c(\"right\", \"top\"))\n\n\n\n\n\n\n\n\nCool I like that and will fiddle with that my ggplot theme!\nOkay lets now go and do some bivariate plots. Obviously the workhorse of bivariate plotting is the scatterplot ."
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#scatter-plots",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#scatter-plots",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Scatter Plots",
    "text": "Scatter Plots\n\n\nsns.scatterplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\")\n\n\n\n\n\n\n\n\nthe next thing that we would want is to size points by the size of the penguin\n\n\nsns.scatterplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\", size = \"body_mass_g\")\n\n\n\n\n\n\n\n\nThat is not really great since the legend is inside and covering stuff. In ggplot we would simply just move the legend position. In this case we have to save it as an object"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#adjusting-legend",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#adjusting-legend",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Adjusting legend",
    "text": "Adjusting legend\n\n\nexmp = sns.scatterplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\", size = \"body_mass_g\")\n\nsns.move_legend(exmp, \"upper left\", bbox_to_anchor = (1,1))\n\n\n\n\n\n\n\n\n\nsns.lmplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThen the other one that I use all the time is using a line of best fit . Okay obviously the most annoying part is that we don‚Äôt have great labels"
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#adding-informative-labels",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#adding-informative-labels",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Adding Informative Labels",
    "text": "Adding Informative Labels\n\nlabs_examp = sns.lmplot(data = penguins, x = \"flipper_length_mm\", y = \"body_mass_g\", hue = \"species\")\n\n\n\nlabs_examp.set_axis_labels(x_var= \"Flipper Length(mm)\", y_var = \"Body Mass(g)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the things we may want to do is to create small multiples."
  },
  {
    "objectID": "blog/2024/translating-dplyr-to-polars/index.html#facet-wrap",
    "href": "blog/2024/translating-dplyr-to-polars/index.html#facet-wrap",
    "title": "Translating What I know in the tidyverse to polars:",
    "section": "Facet Wrap",
    "text": "Facet Wrap\n\nsns.displot(data = penguins, x = \"body_mass_g\", hue = \"species\", row= \"species\", facet_kws = dict(margin_titles=False))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI am honestly not wild about the plot but that is life"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html",
    "title": "Tidyverse to SQL",
    "section": "",
    "text": "Since I am going on the non-academic job market it is high time I learned SQL. I have tried lots of amazing resources but find it hard for me to navigate between notes and various and learning SQL since they are just familiar enough to trip me up and lots of them send you off to various editors. This blog post will serve as my notes and hopefully as a resource for not myself. The general idea is I am just going to work through R4DS and the various dplyr verbs. Then move onto some more advanced SQL stuff like window functions and what not."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#setup",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#setup",
    "title": "Tidyverse to SQL",
    "section": "Setup",
    "text": "Setup\nFor the majority of this palmerpenguins dataset not because you really need to use SQL for a dataset this small but copying over the nyc-taxi dataset is incredibly annoying for blogging purposes.\n\nlibrary(DBI)\nlibrary(arrow)\n\n\nAttaching package: 'arrow'\n\n\nThe following object is masked from 'package:utils':\n\n    timestamp\n\nlibrary(dbplyr)\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ lubridate::duration() masks arrow::duration()\n‚úñ dplyr::filter()       masks stats::filter()\n‚úñ dplyr::ident()        masks dbplyr::ident()\n‚úñ dplyr::lag()          masks stats::lag()\n‚úñ dplyr::sql()          masks dbplyr::sql()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npengs = palmerpenguins::penguins\n\ncon =  src_memdb()\n\npengs = copy_to(con, pengs,\n       overwrite = TRUE)\n\nWe are going to go back and forth using dbplyr and SQL to query the dataset. What impressed me throughout this process was how seamless dbplyr works with dplyr verbs work. With the exception of some string functions it can work as a drop in replacement for SQL. What really helped throughout this process was writing out my queries and using show_query.\n\npengs |&gt;\n    select(species) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT `species`\nFROM `pengs`\n\n\nWhich will give us a SQL query. Obviously this is a pretty simple query but as we get more and more complex this is going to be helpful. For the most part show_query outputs the right query but can be a little bit difficult to debug because of the limitations of showing things in the R console."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#select",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#select",
    "title": "Tidyverse to SQL",
    "section": "Select",
    "text": "Select\nOne convention in SQL which I don‚Äôt really get but is a thing is that functions are defined using all caps. Luckily for us the SQL and dplyr versions are pretty much the same one is just shouty. If we wanted all the columns like we may when we are importing the dataset for the first time we are just going to do SELECT * FROM taxis. There is really not like a perfect equivalent in R except for maybe head. But even then it is not a perfect one to one."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#r",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#r",
    "title": "Tidyverse to SQL",
    "section": "R",
    "text": "R\n\nhead(pengs)\n\n# Source:   SQL [6 x 8]\n# Database: sqlite 3.46.0 [:memory:]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#sql",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#sql",
    "title": "Tidyverse to SQL",
    "section": "SQL",
    "text": "SQL\n\ntbl(con, sql(\"SELECT * FROM pengs\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#filter",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#filter",
    "title": "Tidyverse to SQL",
    "section": "Filter",
    "text": "Filter\nThe first major difference syntactically between dplyr and SQL is with filter statements aka WHERE statements in SQL. So let‚Äôs say we want only penguins that are Adelie penguins.\n\nRSQL\n\n\n\npengs |&gt;\n    filter(species == 'Adelie')\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nBecomes.\n\n\n\ntbl(con,sql( \"\n    SELECT * from pengs\n    WHERE species = 'Adelie'\n\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\n\n\n\n\n\nSome flavors of SQL make you end lines with ‚Äò;‚Äô\nAs dplyr users will notice the way we specified the equality position uses the = instead of ==. This is going to come up a lot. The same thing goes for negation operations.\n\nRSQL\n\n\n\npengs |&gt;\n    filter(species != 'Adelie')\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           50            16.3               230        5700\n 3 Gentoo  Biscoe           48.7          14.1               210        4450\n 4 Gentoo  Biscoe           50            15.2               218        5700\n 5 Gentoo  Biscoe           47.6          14.5               215        5400\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           45.4          14.6               211        4800\n 8 Gentoo  Biscoe           46.7          15.3               219        5200\n 9 Gentoo  Biscoe           43.3          13.4               209        4400\n10 Gentoo  Biscoe           46.8          15.4               215        5150\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\n\n\n\ntbl(con, sql(\"SELECT * from pengs \n             WHERE NOT species = 'Adelie'\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           50            16.3               230        5700\n 3 Gentoo  Biscoe           48.7          14.1               210        4450\n 4 Gentoo  Biscoe           50            15.2               218        5700\n 5 Gentoo  Biscoe           47.6          14.5               215        5400\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           45.4          14.6               211        4800\n 8 Gentoo  Biscoe           46.7          15.3               219        5200\n 9 Gentoo  Biscoe           43.3          13.4               209        4400\n10 Gentoo  Biscoe           46.8          15.4               215        5150\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\n\n\n\nIf we want multiple conditions in our where statements instead of | or &/, we actually just use the words or and and\n\nRSQL\n\n\n\npengs |&gt;\n    filter(species == 'Chinstrap' | species == 'Adelie')\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nbecomes\n\n\n\ntbl(con, sql(\"SELECT * from pengs \n            WHERE species = 'Adelie' OR species = 'Chinstrap'\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\n\n\n\nYou could easily sub in AND but that feels a bit excessive to continue this process for each possible combination. One thing that I do all the time is use sets to subset my data.\n\nRSQL\n\n\n\npengs |&gt;\n    filter(species %in% c('Chinstrap', \"Gentoo\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           50            16.3               230        5700\n 3 Gentoo  Biscoe           48.7          14.1               210        4450\n 4 Gentoo  Biscoe           50            15.2               218        5700\n 5 Gentoo  Biscoe           47.6          14.5               215        5400\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           45.4          14.6               211        4800\n 8 Gentoo  Biscoe           46.7          15.3               219        5200\n 9 Gentoo  Biscoe           43.3          13.4               209        4400\n10 Gentoo  Biscoe           46.8          15.4               215        5150\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nBecomes\n\n\n\ntbl(con, sql(\"SELECT * from pengs\n            WHERE species IN ('Chinstrap', 'Gentoo')\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           50            16.3               230        5700\n 3 Gentoo  Biscoe           48.7          14.1               210        4450\n 4 Gentoo  Biscoe           50            15.2               218        5700\n 5 Gentoo  Biscoe           47.6          14.5               215        5400\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           45.4          14.6               211        4800\n 8 Gentoo  Biscoe           46.7          15.3               219        5200\n 9 Gentoo  Biscoe           43.3          13.4               209        4400\n10 Gentoo  Biscoe           46.8          15.4               215        5150\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\n\n\n\nin this case we define a set in a similar way. If we wanted to negate this statement all we would do is\n\ntbl(con, sql(\"SELECT * from pengs\n            WHERE NOT species IN ('Chinstrap', 'Gentoo')\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nLets say we want to find penguins that are less than the average body mass in R this is fairly straightforward\n\npengs |&gt;\n    filter(body_mass_g &lt; mean(body_mass_g, na.rm = TRUE))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           34.1          18.1               193        3475\n 8 Adelie  Torgersen           37.8          17.1               186        3300\n 9 Adelie  Torgersen           37.8          17.3               180        3700\n10 Adelie  Torgersen           41.1          17.6               182        3200\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nHowever when we do this in some flavor of SQL it is not as straightforward. These are aggregation functions that where can‚Äôt handle because thats not its job. So if we did\n\ntbl(con, \"SELECT * from pengs WHERE body_mass_g &lt; AVG(body_mass_g)\")\n\nError in `db_query_fields.DBIConnection()`:\n! Can't query fields.\n‚Ñπ Using SQL: SELECT * FROM `SELECT * from pengs WHERE body_mass_g &lt;\n  AVG(body_mass_g)` AS `q01` WHERE (0 = 1)\nCaused by error:\n! no such table: SELECT * from pengs WHERE body_mass_g &lt; AVG(body_mass_g)\n\n\nWe get an error. If we wanted to use aggregation functions we have to change how we do this\n\npengs |&gt;\n    filter(body_mass_g &lt; mean(body_mass_g, na.rm = TRUE)) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT\n  `species`,\n  `island`,\n  `bill_length_mm`,\n  `bill_depth_mm`,\n  `flipper_length_mm`,\n  `body_mass_g`,\n  `sex`,\n  `year`\nFROM (\n  SELECT `pengs`.*, AVG(`body_mass_g`) OVER () AS `col01`\n  FROM `pengs`\n) AS `q01`\nWHERE (`body_mass_g` &lt; `col01`)\n\n\nWhat is this OVER thing? OVER in SQL is a window function. There is a more technical way to explain this but heuristically when we pass AVG to WHERE we are effectively doing this. So there is not really anything to compare it too.\n\npengs |&gt;\n    summarise(mean(body_mass_g, na.rm = TRUE))\n\n# Source:   SQL [1 x 1]\n# Database: sqlite 3.46.0 [:memory:]\n  `mean(body_mass_g, na.rm = TRUE)`\n                              &lt;dbl&gt;\n1                             4202.\n\n\nIf we wanted to filter penguins that are less than the average body mass we have to prevent this aggregation process by creating a column and then creating a less than statement like this\n\ntbl(con, sql(\"SELECT * FROM(\n              SELECT pengs .*, AVG(body_mass_g) OVER () AS avg\n               FROM pengs)\n              WHERE (body_mass_g &lt; avg)\"))\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           34.1          18.1               193        3475\n 8 Adelie  Torgersen           37.8          17.1               186        3300\n 9 Adelie  Torgersen           37.8          17.3               180        3700\n10 Adelie  Torgersen           41.1          17.6               182        3200\n# ‚Ñπ more rows\n# ‚Ñπ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, avg &lt;dbl&gt;\n\n\nIt is a little clunky but the tl;dr is that we basically have two FROM statements so if we wanted all penguins between the minimum and the average we could do\n\nRSQL\n\n\n\npalmerpenguins::penguins |&gt;\n    filter(between(body_mass_g, left = min(body_mass_g, na.rm = TRUE), right = mean(body_mass_g, na.rm = TRUE)))\n\n# A tibble: 193 √ó 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           34.1          18.1               193        3475\n 8 Adelie  Torgersen           37.8          17.1               186        3300\n 9 Adelie  Torgersen           37.8          17.3               180        3700\n10 Adelie  Torgersen           41.1          17.6               182        3200\n# ‚Ñπ 183 more rows\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\ntbl(con, sql(\"SELECT * FROM(\n             SELECT pengs .*, AVG(body_mass_g) OVER() AS avg, MIN(body_mass_g) OVER() AS min\n            FROM pengs)\n            WHERE body_mass_g BETWEEN min AND avg\"))\n\n# Source:   SQL [?? x 10]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           34.1          18.1               193        3475\n 8 Adelie  Torgersen           37.8          17.1               186        3300\n 9 Adelie  Torgersen           37.8          17.3               180        3700\n10 Adelie  Torgersen           41.1          17.6               182        3200\n# ‚Ñπ more rows\n# ‚Ñπ 4 more variables: sex &lt;chr&gt;, year &lt;int&gt;, avg &lt;dbl&gt;, min &lt;int&gt;\n\n\n\n\n\nIf you notice in all our examples, we have lots and lots of missing values. This is one of the most common tasks in like any data science task. Let‚Äôs say that we can safely ignore the missing valus. In R we have a lot of options whether we are using filter or drop_na from tidyr. However, in SQL missing values are usually represented by NULL\n\ntbl(con, sql(\"SELECt * FROM pengs \n                WHERE NOT sex IS NULL\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           39.2          19.6               195        4675\n 8 Adelie  Torgersen           41.1          17.6               182        3200\n 9 Adelie  Torgersen           38.6          21.2               191        3800\n10 Adelie  Torgersen           34.6          21.1               198        4400\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#mutate",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#mutate",
    "title": "Tidyverse to SQL",
    "section": "Mutate",
    "text": "Mutate\nAs lots of things go we need to be able to create our own variables. So to do this in R we do this\n\npengs |&gt;\n    mutate(sqr_body_mass = body_mass_g^2)\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, sqr_body_mass &lt;dbl&gt;\n\n\nIn SQL to get the equivalent statement we use SELECT transformation AS new_var_name when we need to do things that are not in the dataset. So we basically need to define the column before we do anything.\n\ntbl(con, sql(\"SELECT pengs .*, POWER(body_mass_g,2) AS sqr_body_mass\n            FROM pengs\"))\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, sqr_body_mass &lt;dbl&gt;\n\n\nSo if we needed wanted to make a ratio of bill depth to bill length we would do\n\ntbl(con, sql(\"SELECT pengs .*, bill_depth_mm/bill_length_mm AS ratio \n            FROM pengs\"))\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, ratio &lt;dbl&gt;\n\n\nA very important thing we do all the time is generate indicator variables for treatment status gender etc. Oddly enough if we peep the output of show query we see a familiar face!"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#r-7",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#r-7",
    "title": "Tidyverse to SQL",
    "section": "R",
    "text": "R\n\npengs |&gt;\n    mutate(male = ifelse(sex == 'Male', 1, 0)) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT\n  `pengs`.*,\n  CASE WHEN (`sex` = 'Male') THEN 1.0 WHEN NOT (`sex` = 'Male') THEN 0.0 END AS `male`\nFROM `pengs`\n\n\nSo to make an indicator variable we would just do\n\ntbl(con, sql(\"SELECT pengs.*, CASE WHEN (sex = 'male') THEN 1.0 WHEN not (sex = 'male') THEN 0.0 END AS male\n             FROM pengs\"))\n\n# Source:   SQL [?? x 9]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, male &lt;dbl&gt;\n\n\nLet‚Äôs combine our window functions with our friend case_when\n\ntbl(con, sql(\"SELECT * FROM(SELECT pengs .*,\n           AVG(body_mass_g) AS avg, MIN(body_mass_g) AS min, MAX(body_mass_g) AS max,\n            CASE WHEN (body_mass_g = min) THEN 'This penguins is small' WHEN (body_mass_g = avg) THEN 'This is an average sized penguin' WHEN (body_mass_g = max) THEN 'this is a really big penguin' END AS note \n            FROM pengs)\"))\n\nI will spare you the long output of the error message. But needless to say this was wrong. If we translate what I was trying to do into dplyr we get this\n\npengs |&gt;\n    mutate(note = case_when(\n            body_mass_g == min(body_mass_g) ~ 'This is a small peng',\n            body_mass_g == mean(body_mass_g) ~ 'Average sized peng',\n            body_mass_g == max(body_mass_g) ~ 'Big sized peng',\n             .default = 'Penguin is some size')) |&gt;\n        show_query()\n\nWarning: Missing values are always removed in SQL aggregation functions.\nUse `na.rm = TRUE` to silence this warning\nThis warning is displayed once every 8 hours.\n\n\n&lt;SQL&gt;\nSELECT\n  `pengs`.*,\n  CASE\nWHEN (`body_mass_g` = MIN(`body_mass_g`) OVER `win1`) THEN 'This is a small peng'\nWHEN (`body_mass_g` = AVG(`body_mass_g`) OVER `win1`) THEN 'Average sized peng'\nWHEN (`body_mass_g` = MAX(`body_mass_g`) OVER `win1`) THEN 'Big sized peng'\nELSE 'Penguin is some size'\nEND AS `note`\nFROM `pengs`\nWINDOW `win1` AS ()\n\n\nSo it looks like we need to change the window function\n\ncheck = tbl(con, sql(\"SELECT pengs .*,\n              CASE\n            WHEN (body_mass_g &gt;= MIN(body_mass_g) OVER win1) THEN 'this is a small penguin'\n            WHEN (body_mass_g = AVG(body_mass_g) OVER win1) THEN 'this is an average sized penguin'\n            WHEN (body_mass_g = MAX(body_mass_g) OVER win1) THEN 'this is a big penguin'\n            ELSE 'This penguin is not big, small or average'\n            END AS note\n            FROM pengs \n            WINDOW win1 AS ()\")) |&gt;\n                collect()\n\nLets look at this a little closer to make sure this worked. We would probably want to make this a little more robust. So lets go ahead and define a range.\n\ntbl(con, sql(\"SELECT pengs .*,\n              CASE\n            WHEN (body_mass_g &gt;= MIN(body_mass_g) OR body_mass_g &lt; AVG(body_mass_g)  OVER win1) THEN 'this is a small penguin'\n            WHEN (body_mass_g &gt;= AVG(body_mass_g) OR body_mass_g &lt; MAX(body_mass_G) OVER win1) THEN 'this is an average sized penguin'\n            WHEN (body_mass_g &gt;= MAX(body_mass_g) OVER win1) THEN 'this is a big penguin'\n            ELSE 'This penguin is not big, small or average'\n            END AS note\n            FROM pengs \n            WINDOW win1 AS ()\"))\n\n# Source:   SQL [1 x 9]\n# Database: sqlite 3.46.0 [:memory:]\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Chinstrap Dream            46.9          16.6               192        2700\n# ‚Ñπ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, note &lt;chr&gt;"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#group-by-and-summarize",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#group-by-and-summarize",
    "title": "Tidyverse to SQL",
    "section": "Group by and summarize",
    "text": "Group by and summarize\nAs established earlier we can use SQL to summarize like this.\n\ntbl(con, sql('SELECT AVG(bill_depth_mm) AS avg\n           FROM pengs'))\n\n# Source:   SQL [1 x 1]\n# Database: sqlite 3.46.0 [:memory:]\n    avg\n  &lt;dbl&gt;\n1  17.2\n\n\nBut the actual practical utility is somewhat limited. Often we want group specific differences. Oddly enough I expected this to be a window function thing, but we actually delay computing of the mean by different groups to the end. I guess this makes sense if we are dealing with big data\n\ntbl(con, sql(\"SELECT species, AVG(body_mass_g) AS avg_body_mass\n            FROM pengs\n            GROUP BY species\"))\n\n# Source:   SQL [3 x 2]\n# Database: sqlite 3.46.0 [:memory:]\n  species   avg_body_mass\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Adelie            3701.\n2 Chinstrap         3733.\n3 Gentoo            5076.\n\n\nSo if we wanted to count of the species we would do something along this line\n\ntbl(con, sql(\"SELECT species, COUNT(species) AS total\n            FROM pengs \n            GROUP BY species\"))\n\n# Source:   SQL [3 x 2]\n# Database: sqlite 3.46.0 [:memory:]\n  species   total\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nFor multiple grouping variables we would define the grouping variables the same way as we would in dplyr\n\ntbl(con, sql(\"SELECT species, sex, COUNT(species) AS total\n            FROM pengs \n            GROUP BY species, sex\"))\n\n# Source:   SQL [8 x 3]\n# Database: sqlite 3.46.0 [:memory:]\n  species   sex    total\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    &lt;NA&gt;       6\n2 Adelie    female    73\n3 Adelie    male      73\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    &lt;NA&gt;       5\n7 Gentoo    female    58\n8 Gentoo    male      61\n\n\nThe same would go for multiple summary functions\n\ntbl(con, sql(\"SELECT species, COUNT(species) AS total, AVG(bill_depth_mm) AS avg_bill_depth, MEDIAN(bill_depth_mm) AS median_bill_depth\n             FROM pengs \n             GROUP BY sex\"))\n\n# Source:   SQL [3 x 4]\n# Database: sqlite 3.46.0 [:memory:]\n  species total avg_bill_depth median_bill_depth\n  &lt;chr&gt;   &lt;int&gt;          &lt;dbl&gt;             &lt;dbl&gt;\n1 Adelie     11           16.6              17.1\n2 Adelie    165           16.4              17  \n3 Adelie    168           17.9              18.4"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#rename",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#rename",
    "title": "Tidyverse to SQL",
    "section": "Rename",
    "text": "Rename\nThe AS function is kind the work horse for the next few sections. The naming convention differs a little bit so instead of new_name = old_name we do SELECT old_name as new_name\n\ntbl(con, sql(\"SELECT species AS kinds_of_penguins\n          FROM pengs\"))\n\n# Source:   SQL [?? x 1]\n# Database: sqlite 3.46.0 [:memory:]\n   kinds_of_penguins\n   &lt;chr&gt;            \n 1 Adelie           \n 2 Adelie           \n 3 Adelie           \n 4 Adelie           \n 5 Adelie           \n 6 Adelie           \n 7 Adelie           \n 8 Adelie           \n 9 Adelie           \n10 Adelie           \n# ‚Ñπ more rows"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#joinsappending-rows",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#joinsappending-rows",
    "title": "Tidyverse to SQL",
    "section": "Joins/Appending Rows",
    "text": "Joins/Appending Rows\nIn the real world it is rare that we will have all our data in one place. Companies keep information in lots of different places because well it would be bad if we kept credit card information with all the necessary components to make a purchase. Instead of having to figure out three different things malicious actors would just need to access one database. Replacing entire data tables can also skyrocket costs. So instead, it is more efficient to simply insert rows.\n\nApppending Rows\nTo kind of mimic this we are just going to slice this data frame roughly in half. While not entirely realistic the general process will be similar enough\n\n\nCode\npengs_top = palmerpenguins::penguins |&gt;\n    slice(1:172)\n\npengs_bottom = palmerpenguins::penguins |&gt;\n    slice(173:344)\n\ncon2 = src_memdb()\n\ncon3 = src_memdb()\n\npengs_top = copy_to(con2, pengs_top)\n\npengs_bottom = copy_to(con3, pengs_bottom)\n\n\nFor whatever reason show_query is not working with this so we are going to have to consult the interwebs. The SQL equivalent of bind_rows is UNION.\n\ntbl(con2, sql(\"SELECT * FROM pengs_top\n             UNION ALL \n             SELECT * FROM pengs_bottom\"))\n\n# Source:   SQL [?? x 8]\n# Database: sqlite 3.46.0 [:memory:]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ more rows\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nOne of the key things in this query is ALL which is somewhat new to me. Basically the ALL tells SQL that we don‚Äôt really care about duplicates so just add the rows regardless. So if we wanted to exclude duplicates we would do something like this\n\n\nCode\ntbl(con2, sql(\"SELECt * FROM pengs_top \n              UNION \n              SELECT * FROM pengs_top\")) |&gt;\n                collect() |&gt;\n                nrow()\n\n\n[1] 172\n\n\nCode\ntbl(con2,sql(\"SELECT * FROM pengs_top\") ) |&gt;\n    collect() |&gt;\n    nrow()\n\n\n[1] 172\n\n\n\n\nJoins\nLuckily for us the join syntax from dplyr is pretty directly taken SQL so lefts create some dummy data to join.\n\n\nCode\nnational_data &lt;- tribble(\n  ~state, ~year, ~unemployment, ~inflation, ~population,\n  \"GA\",   2018,  5,             2,          100,\n  \"GA\",   2019,  5.3,           1.8,        200,\n  \"GA\",   2020,  5.2,           2.5,        300,\n  \"NC\",   2018,  6.1,           1.8,        350,\n  \"NC\",   2019,  5.9,           1.6,        375,\n  \"NC\",   2020,  5.3,           1.8,        400,\n  \"CO\",   2018,  4.7,           2.7,        200,\n  \"CO\",   2019,  4.4,           2.6,        300,\n  \"CO\",   2020,  5.1,           2.5,        400\n)\n\nnational_libraries &lt;- tribble(\n  ~state, ~year, ~libraries, ~schools,\n  \"CO\",   2018,  230,        470,\n  \"CO\",   2019,  240,        440,\n  \"CO\",   2020,  270,        510,\n  \"NC\",   2018,  200,        610,\n  \"NC\",   2019,  210,        590,\n  \"NC\",   2020,  220,        530,\n)\n\ncon3 = src_memdb()\n\ncon4 = src_memdb()\n\nnational_data = copy_to(con4, national_data, overwrite = TRUE)\n\nnational_libraries = copy_to(con3, national_libraries, overwrite = TRUE)\n\n\nSo we have some fake national level data that we would like to join in to the dataset. We could do something like this but what we notice is that it is going to decide the join keys for us and probably create some headaches for us later on. To solve this we need to use our keys if we expose the underlying logic\n\nnational_data |&gt;\n    left_join(national_libraries, join_by(state, year)) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT `national_data`.*, `libraries`, `schools`\nFROM `national_data`\nLEFT JOIN `national_libraries`\n  ON (\n    `national_data`.`state` = `national_libraries`.`state` AND\n    `national_data`.`year` = `national_libraries`.`year`\n  )\n\n\nWe will notice that join_by is shorthand for equality joins. What changes is that instead of left_key = right_key we have to specify what is coming from what table using .\n\ndb_con = con4$con\n\nquery = \"SELECT *\n             FROM national_data\n             LEFT JOIN national_libraries\n             ON (\n             national_data.state = national_libraries.state AND\n             national_data.year = national_libraries.year\n             )\n             \"\n\ndbGetQuery(db_con, sql(query))       \n\n  state year unemployment inflation population state year libraries schools\n1    GA 2018          5.0       2.0        100  &lt;NA&gt;   NA        NA      NA\n2    GA 2019          5.3       1.8        200  &lt;NA&gt;   NA        NA      NA\n3    GA 2020          5.2       2.5        300  &lt;NA&gt;   NA        NA      NA\n4    NC 2018          6.1       1.8        350    NC 2018       200     610\n5    NC 2019          5.9       1.6        375    NC 2019       210     590\n6    NC 2020          5.3       1.8        400    NC 2020       220     530\n7    CO 2018          4.7       2.7        200    CO 2018       230     470\n8    CO 2019          4.4       2.6        300    CO 2019       240     440\n9    CO 2020          5.1       2.5        400    CO 2020       270     510\n\n\n\n\nFor whatever reason with SQLite gets a little grumpy with the join syntax.\nIf we wanted to do various other joins like inner and anti joins we would do a similar thing.\n\nquery = \"SELECT * \n        FROM national_data\n    INNER JOIN national_libraries \n    ON(\n    national_data.state = national_libraries.state AND\n    national_data.year = national_libraries.year\n    )\n\"\n\ndbGetQuery(db_con, sql(query))\n\n  state year unemployment inflation population state year libraries schools\n1    CO 2018          4.7       2.7        200    CO 2018       230     470\n2    CO 2019          4.4       2.6        300    CO 2019       240     440\n3    CO 2020          5.1       2.5        400    CO 2020       270     510\n4    NC 2018          6.1       1.8        350    NC 2018       200     610\n5    NC 2019          5.9       1.6        375    NC 2019       210     590\n6    NC 2020          5.3       1.8        400    NC 2020       220     530\n\n\n\n\nInequality joins\nConfession I have never really understood how inequality joins work in regular dplyr but I am sure at some point I am going to need them and now when the stakes are so low is a good time to do it. So lets just take the data from the dplyr 1.1.0 announcement to do this since we know what the output should be.\n\ncompanies &lt;- tibble(\n  id = c(\"A\", \"B\", \"B\"),\n  since = c(1973, 2009, 2022),\n  name = c(\"Patagonia\", \"RStudio\", \"Posit\")\n)\n\ntransactions &lt;- tibble(\n  company = c(\"A\", \"A\", \"B\", \"B\"),\n  year = c(2019, 2020, 2021, 2023),\n  revenue = c(50, 4, 10, 12)\n)\n\ncompanies = copy_to(con3, companies, overwrite = TRUE)\n\ntransactions = copy_to(con4, transactions, overwrite = TRUE)\n\ndb_con = con3$con\n\nSo the main idea of an inequality join is that we can join by a key in this case company but only keep records from a certain date. The blog post kind of equates it with a filter/WHERE that happens during the join phase. So we would see something like this\n\ntransactions |&gt;\n  inner_join(companies, join_by(company == id, year &gt;= since)) \n\n# Source:   SQL [5 x 5]\n# Database: sqlite 3.46.0 [:memory:]\n  company  year revenue since name     \n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    \n1 A        2019      50  1973 Patagonia\n2 A        2020       4  1973 Patagonia\n3 B        2021      10  2009 RStudio  \n4 B        2023      12  2009 RStudio  \n5 B        2023      12  2022 Posit    \n\n\nInstead of two equality statements we would effectively use the same syntax just swapping out the = with &gt;=\n\nquery = \"\n      SELECT * FROM transactions\n      INNER JOIN companies \n      ON(\n      transactions.company = companies.id AND\n      transactions.year &gt;= companies.since\n      )\n\n\"\n\ndbGetQuery(db_con, sql(query))\n\n  company year revenue id since      name\n1       A 2019      50  A  1973 Patagonia\n2       A 2020       4  A  1973 Patagonia\n3       B 2021      10  B  2009   RStudio\n4       B 2023      12  B  2009   RStudio\n5       B 2023      12  B  2022     Posit"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#pivots",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#pivots",
    "title": "Tidyverse to SQL",
    "section": "Pivots",
    "text": "Pivots\nIn tidyverse parlance we use pivots to change the ‚Äúshape of the data.‚Äù If you are unfamiliar with this idea consider the religion and income data below. You will notice that we have a column for each income bracket or what is sometimes called ‚Äúwide‚Äù data. This may be useful for some question but generally if we want to plot things or do things it will be easier if they are ‚Äúlong‚Äù data.\n\n\nCode\ncon5 = src_memdb()\n\nrelig = copy_to(con5, relig_income, overwrite = TRUE)\n\nhead(relig_income, n = 2)\n\n\n# A tibble: 2 √ó 11\n  religion `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 Agnostic      27        34        60        81        76       137        122\n2 Atheist       12        27        37        52        35        70         73\n# ‚Ñπ 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;,\n#   `Don't know/refused` &lt;dbl&gt;\n\n\nTo make our data ‚Äúlong‚Äù we use pivot_longer and to make data ‚Äúwide‚Äù we use pivot_wider each has their own quirks but the general idea is that we have to tell these functions where to put the old names/where to get the new names and where to put the old values/where to get the new values. So if we wanted to make our data longer we would do something like this.\n\nlong = relig_income |&gt;\n    pivot_longer(-religion,\n                names_to = 'income_bracket',\n                values_to = 'income')\n\nhead(long, n = 2)\n\n# A tibble: 2 √ó 3\n  religion income_bracket income\n  &lt;chr&gt;    &lt;chr&gt;           &lt;dbl&gt;\n1 Agnostic &lt;$10k              27\n2 Agnostic $10-20k            34\n\n\nIf we wanted to make this wide again all we would do is reverse this with pivot_wider\n\nwide = long |&gt;\n    pivot_wider(names_from = income_bracket, values_from = income)\n\n\n\nThere are ton of additional functionality that will not be covered like dealing with not uniquely identified columns.\nTo get a sense of how to do this let‚Äôs consult our old friend show_query\n\nrelig |&gt;\n    pivot_longer(-religion,\n                names_to = 'income_bracket',\n                values_to = 'income') |&gt;\n                    show_query()\n\nWe are not going to actually show the results because it is quite the query. The summary of what is happening is that SQLite doesn‚Äôt have a perfect equivalent of pivot_longer. Basically, what you need to do is to keep appending smaller and smaller data frames to each other until you get to a long data frame. In other flavors of SQL this process is a lot more humane with explicit PIVOT and UNPIVOT but I am not in one of those flavors. To spare myself a bit I am just going to do two columns\n\ntbl(con5, sql(\"\n    SELECT religion, '&lt;$10k' AS income_bracket, '&lt;$10k' AS income\n    FROM relig_income \n\n    UNION ALL\n\n    SELECT religion, '$10-20k' AS income_bracket, '$10-20k' AS income\n    FROM relig_income\n\n    UNION ALL\n\n    SELECT religion, '$20-30k' AS income_bracket, '$20-30k' AS income\n    FROM relig_income\n\n    \n\"))\n\n# Source:   SQL [?? x 3]\n# Database: sqlite 3.46.0 [:memory:]\n   religion                income_bracket income\n   &lt;chr&gt;                   &lt;chr&gt;          &lt;chr&gt; \n 1 Agnostic                &lt;$10k          &lt;$10k \n 2 Atheist                 &lt;$10k          &lt;$10k \n 3 Buddhist                &lt;$10k          &lt;$10k \n 4 Catholic                &lt;$10k          &lt;$10k \n 5 Don‚Äôt know/refused      &lt;$10k          &lt;$10k \n 6 Evangelical Prot        &lt;$10k          &lt;$10k \n 7 Hindu                   &lt;$10k          &lt;$10k \n 8 Historically Black Prot &lt;$10k          &lt;$10k \n 9 Jehovah's Witness       &lt;$10k          &lt;$10k \n10 Jewish                  &lt;$10k          &lt;$10k \n# ‚Ñπ more rows\n\n\nI am a little scared to see what this looks for pivot_wider but we should at least give it a go.\n\nlong = relig |&gt;\n    pivot_longer(-religion,\n                 names_to = 'income_bracket',\n                 values_to = 'income')\n\nlong |&gt;\n    pivot_wider(names_from = income_bracket, values_from = income) |&gt;\n    show_query()\n\nOkay again this is a little unwieldy to show. Basically what happens is that we are creating a big case_when condition and then from there we are going to use the same binding trick and then group the data. So lets go ahead and copy and paste some of this.\n\n\nCode\nquery = \"\nSELECT\n    religion,\n    MAX(CASE WHEN (income_bracket = '&lt;$10k') THEN income END) AS '&lt;$10K',\n    MAX(CASE WHEN (income_bracket = '$10-20k') THEN income END) AS '$10-20k',\n    MAX(CASE WHEN (income_bracket = '$20-30k') THEN income END) AS '$20-30k'\nFROM (\n    SELECT religion, '&lt;$10k' AS income_bracket, '&lt;$10k' AS income\n    FROM relig_income\n\n    UNION ALL\n\n    SELECT religion, '$10-20k' AS income_bracket, '$10-20k' AS income\n    FROM relig_income\n\n    UNION ALL\n\n    SELECT religion, '$20-30k' AS income_bracket, '$20-30k' AS income\n    FROM relig_income\n) AS wide_religion\nGROUP BY religion\n\"\n\ntbl(con5, sql(query))\n\n\n# Source:   SQL [?? x 4]\n# Database: sqlite 3.46.0 [:memory:]\n   religion                `&lt;$10K` `$10-20k` `$20-30k`\n   &lt;chr&gt;                   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;    \n 1 Agnostic                &lt;$10k   $10-20k   $20-30k  \n 2 Atheist                 &lt;$10k   $10-20k   $20-30k  \n 3 Buddhist                &lt;$10k   $10-20k   $20-30k  \n 4 Catholic                &lt;$10k   $10-20k   $20-30k  \n 5 Don‚Äôt know/refused      &lt;$10k   $10-20k   $20-30k  \n 6 Evangelical Prot        &lt;$10k   $10-20k   $20-30k  \n 7 Hindu                   &lt;$10k   $10-20k   $20-30k  \n 8 Historically Black Prot &lt;$10k   $10-20k   $20-30k  \n 9 Jehovah's Witness       &lt;$10k   $10-20k   $20-30k  \n10 Jewish                  &lt;$10k   $10-20k   $20-30k  \n# ‚Ñπ more rows"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#unnesta-brief-aside",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#unnesta-brief-aside",
    "title": "Tidyverse to SQL",
    "section": "Unnest/a brief aside",
    "text": "Unnest/a brief aside\nSo one thing that you come across from time to time in R and python data wrangling are list columns. These happen for a variety of reasons and are pretty innocuous to handle.\n\nlist_starwars = starwars |&gt;\n    select(name, films)\n\n list_starwars |&gt;\n    unnest_longer(films)\n\n# A tibble: 173 √ó 2\n   name           films                  \n   &lt;chr&gt;          &lt;chr&gt;                  \n 1 Luke Skywalker A New Hope             \n 2 Luke Skywalker The Empire Strikes Back\n 3 Luke Skywalker Return of the Jedi     \n 4 Luke Skywalker Revenge of the Sith    \n 5 Luke Skywalker The Force Awakens      \n 6 C-3PO          A New Hope             \n 7 C-3PO          The Empire Strikes Back\n 8 C-3PO          Return of the Jedi     \n 9 C-3PO          The Phantom Menace     \n10 C-3PO          Attack of the Clones   \n# ‚Ñπ 163 more rows\n\n\nHowever, per this Stack overflow answer and the linked question this is not really a thing or like really not advised. Even when you try to copy the starwars dataset to a database you get an error."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#misc",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#misc",
    "title": "Tidyverse to SQL",
    "section": "Misc",
    "text": "Misc"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#ranking-and-returning",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#ranking-and-returning",
    "title": "Tidyverse to SQL",
    "section": "Ranking and returning",
    "text": "Ranking and returning\nThere are lots of different ways to rank things in R if we want to return the min/max you can do\n\npengs |&gt;\n    slice_max(bill_length_mm, n = 3)\n\n# Source:   SQL [3 x 8]\n# Database: sqlite 3.46.0 [:memory:]\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo    Biscoe           59.6          17                 230        6050\n2 Chinstrap Dream            58            17.8               181        3700\n3 Gentoo    Biscoe           55.9          17                 228        5600\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nThere are also various ranking functions.\n\nexample = tribble(~id, ~col1,\n                   1, 1,\n                   2, 2,\n                   3, 2,\n                   4, 3,\n                   5, 4)\n\nexample |&gt;\n    mutate(rank_one = dense_rank(col1),\n           rank_two = min_rank(col1))\n\n# A tibble: 5 √ó 4\n     id  col1 rank_one rank_two\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;\n1     1     1        1        1\n2     2     2        2        2\n3     3     2        2        2\n4     4     3        3        4\n5     5     4        4        5\n\n\nLike our dplyr join functions the dense_rank and min_rank function actually takes inspiration from SQL. So in our example where the two functions differ is how they handle ties. So in dense_rank and min_rank both id 2 and 3 get assigned the same rank where they differ is dense_rank will assign id 4 the rank of 3 and min_rank will assign id 4 the rank of 4.\nSo how would we do this in SQL\n\ncon7 = src_memdb()\n\nteam_rankings = copy_to(con7, example)\n\nteam_rankings |&gt;\n    mutate(rank_one = dense_rank(col1)) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT\n  `example`.*,\n  CASE\nWHEN (NOT((`col1` IS NULL))) THEN DENSE_RANK() OVER (PARTITION BY (CASE WHEN ((`col1` IS NULL)) THEN 1 ELSE 0 END) ORDER BY `col1`)\nEND AS `rank_one`\nFROM `example`\n\n\nThis is deceptively a bit more complex. So we are going to window over col1\n\ntbl(con7, sql(\"\nSELECT\nexample .*,\n    CASE \nWHEN (NOT((col1 is NULL))) THEN DENSE_RANK() OVER (PARTITiON BY (CASE WHEN ((col1 is NULL)) THEN 1 ELSE 0 END) ORDER BY col1)\nEND AS rank_one\nFROM example\n\"))\n\n# Source:   SQL [5 x 3]\n# Database: sqlite 3.46.0 [:memory:]\n     id  col1 rank_one\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt;\n1     1     1        1\n2     2     2        2\n3     3     2        2\n4     4     3        3\n5     5     4        4\n\n\nThis was a little confusing. So basically the PARTITION BY bit is used to divide the data into groups before we rank them. The CASE WHEN handles when we have missing values."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#ranking",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#ranking",
    "title": "Tidyverse to SQL",
    "section": "Ranking",
    "text": "Ranking\nThere are lots of different ways to rank things in R if we want to return the min/max you can do\n\npengs |&gt;\n    slice_max(bill_length_mm, n = 3)\n\n# Source:   SQL [3 x 8]\n# Database: sqlite 3.46.0 [:memory:]\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo    Biscoe           59.6          17                 230        6050\n2 Chinstrap Dream            58            17.8               181        3700\n3 Gentoo    Biscoe           55.9          17                 228        5600\n# ‚Ñπ 2 more variables: sex &lt;chr&gt;, year &lt;int&gt;\n\n\nThere are also various ranking functions.\n\nexample = tribble(~id, ~col1,\n                   1, 1,\n                   2, 2,\n                   3, 2,\n                   4, 3,\n                   5, 4)\n\nexample |&gt;\n    mutate(rank_one = dense_rank(col1),\n           rank_two = min_rank(col1))\n\n# A tibble: 5 √ó 4\n     id  col1 rank_one rank_two\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;\n1     1     1        1        1\n2     2     2        2        2\n3     3     2        2        2\n4     4     3        3        4\n5     5     4        4        5\n\n\nLike our dplyr join functions the dense_rank and min_rank function actually takes inspiration from SQL. So in our example where the two functions differ is how they handle ties. So in dense_rank and min_rank both id 2 and 3 get assigned the same rank where they differ is dense_rank will assign id 4 the rank of 3 and min_rank will assign id 4 the rank of 4.\nSo how would we do this in SQL\n\ncon7 = src_memdb()\n\nteam_rankings = copy_to(con7, example)\n\nteam_rankings |&gt;\n    mutate(rank_one = dense_rank(col1)) |&gt;\n    show_query()\n\n&lt;SQL&gt;\nSELECT\n  `example`.*,\n  CASE\nWHEN (NOT((`col1` IS NULL))) THEN DENSE_RANK() OVER (PARTITION BY (CASE WHEN ((`col1` IS NULL)) THEN 1 ELSE 0 END) ORDER BY `col1`)\nEND AS `rank_one`\nFROM `example`\n\n\nThis is deceptively a bit more complex. So lets break it down.\n\ntbl(con7, sql(\"\nSELECT\nexample .*,\n    CASE \nWHEN (NOT((col1 is NULL))) THEN DENSE_RANK() OVER (PARTITION BY (CASE WHEN ((col1 is NULL)) THEN 1 ELSE 0 END) ORDER BY col1)\nEND AS rank_one\nFROM example\n\"))\n\n# Source:   SQL [5 x 3]\n# Database: sqlite 3.46.0 [:memory:]\n     id  col1 rank_one\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt;\n1     1     1        1\n2     2     2        2\n3     3     2        2\n4     4     3        3\n5     5     4        4\n\n\nSo basically the PARTITION BY bit is used to divide the data into groups before we rank them. The CASE WHEN handles when we have missing values. Then the window function is applying dense rank over these partions. This was a somewhat silly example so lets do something a bit more realistic. Lets say we actually want to rank the penguins by average bill length and then return the penguins in the top 3.\n\ntbl(con, sql(\n    \"\n    SELECT\n    ranked_pengs .*,\n    CASE\n    WHEN (NOT((avg_bill_length is NULL))) THEN DENSE_RANK() OVER (PARTITION BY (CASE WHEN ((avg_bill_length is NULL)) THEN 1 ELSE 0 END) ORDER BY avg_bill_length)\n    END AS rank\n    FROM( \n     SELECT pengs .*, AVG(bill_length_mm) OVER () AS avg_bill_length\n     FROM pengs)\n     AS ranked_pengs \n     LIMIT 3\n    \"\n))\n\n# Source:   SQL [3 x 10]\n# Database: sqlite 3.46.0 [:memory:]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ‚Ñπ 4 more variables: sex &lt;chr&gt;, year &lt;int&gt;, avg_bill_length &lt;dbl&gt;, rank &lt;int&gt;\n\n\nWe could also do this by groups by just inserting a group by statement before the limit bit\n\ntbl(con, sql(\n    \"\n    SELECT\n    ranked_pengs .*,\n    CASE\n    WHEN (NOT((avg_bill_length is NULL))) THEN DENSE_RANK() OVER (PARTITION BY (CASE WHEN ((avg_bill_length is NULL)) THEN 1 ELSE 0 END) ORDER BY avg_bill_length)\n    END AS rank\n    FROM( \n     SELECT pengs .*, AVG(bill_length_mm) OVER () AS avg_bill_length\n     FROM pengs)\n     AS ranked_pengs \n     GROUP BY species\n     LIMIT 3\n    \"\n))\n\n# Source:   SQL [3 x 10]\n# Database: sqlite 3.46.0 [:memory:]\n  species   island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie    Torgersen           39.1          18.7               181        3750\n2 Chinstrap Dream               46.5          17.9               192        3500\n3 Gentoo    Biscoe              46.1          13.2               211        4500\n# ‚Ñπ 4 more variables: sex &lt;chr&gt;, year &lt;int&gt;, avg_bill_length &lt;dbl&gt;, rank &lt;int&gt;"
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#the-endfor-now",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#the-endfor-now",
    "title": "Tidyverse to SQL",
    "section": "The End‚Ä¶for now",
    "text": "The End‚Ä¶for now\nI am sure this will end up growing as I think of more than things in R that I need to be able to do in SQL."
  },
  {
    "objectID": "blog/2024/translating-tidyverse-to-sql/index.html#distinct-values",
    "href": "blog/2024/translating-tidyverse-to-sql/index.html#distinct-values",
    "title": "Tidyverse to SQL",
    "section": "Distinct Values",
    "text": "Distinct Values\nDuplicates are a fact of life but depending on your question or what information you are trying to show repeated records may not be desirable. We handle these with the same function but kind of like mutate we have to let select handle these. If we wanted one row per column without having to specify every column in our dataset than we could do something like this\n\ntbl(con, sql(\"SELECT *\n            FROM(\n            SELECT pengs .*,\n            ROW_NUMBER() OVER (PARTITION BY species ORDER BY species) AS id \n            FROM PENGS) AS small_pengs\n            WHERE id = 1\"))\n\n# Source:   SQL [3 x 9]\n# Database: sqlite 3.46.0 [:memory:]\n  species   island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie    Torgersen           39.1          18.7               181        3750\n2 Chinstrap Dream               46.5          17.9               192        3500\n3 Gentoo    Biscoe              46.1          13.2               211        4500\n# ‚Ñπ 3 more variables: sex &lt;chr&gt;, year &lt;int&gt;, id &lt;int&gt;\n\n\nHowever if we have a slightly less complex query than we can feed distinct multiple columns\n\ntbl(con, sql(\"SELECT DISTINCT species, island\n            FROM pengs\"))\n\n# Source:   SQL [5 x 2]\n# Database: sqlite 3.46.0 [:memory:]\n  species   island   \n  &lt;chr&gt;     &lt;chr&gt;    \n1 Adelie    Torgersen\n2 Adelie    Biscoe   \n3 Adelie    Dream    \n4 Gentoo    Biscoe   \n5 Chinstrap Dream"
  }
]